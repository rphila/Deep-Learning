{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7: Build a Live Camera App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rita Philavanh\n",
    "\n",
    "20170905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Street View House Number (SVHN) training/test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download train.tar.gz and test.tar.gz files from http://ufldl.stanford.edu/housenumbers/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset from compressed tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train already present - Skipping extraction of train.tar.gz.\n",
      "[]\n",
      "test already present - Skipping extraction of test.tar.gz.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 0\n",
    "np.random.seed(133)\n",
    "data_root = '.'\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract('train.tar.gz')\n",
    "test_folders = maybe_extract('test.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels from .mat file \n",
    "\n",
    "(used digiStruct.py code found here: https://github.com/prijip/Py-Gsvhn-DigitStruct-Reader/blob/360a03909a22a28e2e814e83d6915ee5f915e5da/digitStruct.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 256.67s\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Bounding Box\n",
    "#\n",
    "class BBox:\n",
    "    def __init__(self):\n",
    "        self.label = \"\"     # Digit\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "\n",
    "class DigitStruct:\n",
    "    def __init__(self):\n",
    "        self.name = None    # Image file name\n",
    "        self.bboxList = None # List of BBox structs\n",
    "\n",
    "# Function for debugging\n",
    "def printHDFObj(theObj, theObjName):\n",
    "    isFile = isinstance(theObj, h5py.File)\n",
    "    isGroup = isinstance(theObj, h5py.Group)\n",
    "    isDataSet = isinstance(theObj, h5py.Dataset)\n",
    "    isReference = isinstance(theObj, h5py.Reference)\n",
    "    print(\"{}\".format(theObjName))\n",
    "    print(\"    type(): {}\".format(type(theObj)))\n",
    "    if isFile or isGroup or isDataSet:\n",
    "        # if theObj.name != None:\n",
    "        #    print \"    name: {}\".format(theObj.name)\n",
    "        print(\"    id: {}\".format(theObj.id))\n",
    "    if isFile or isGroup:\n",
    "        print(\"    keys: {}\".format(theObj.keys()))\n",
    "    if not isReference:\n",
    "        print(\"    Len: {}\".format(len(theObj)))\n",
    "\n",
    "    if not (isFile or isGroup or isDataSet or isReference):\n",
    "        print(theObj)\n",
    "\n",
    "def readDigitStructGroup(dsFile):\n",
    "    dsGroup = dsFile[\"digitStruct\"]\n",
    "    return dsGroup\n",
    "\n",
    "#\n",
    "# Reads a string from the file using its reference\n",
    "#\n",
    "def readString(strRef, dsFile):\n",
    "    strObj = dsFile[strRef]\n",
    "    str = ''.join(chr(i) for i in strObj)\n",
    "    return str\n",
    "\n",
    "#\n",
    "# Reads an integer value from the file\n",
    "#\n",
    "def readInt(intArray, dsFile):\n",
    "    intRef = intArray[0]\n",
    "    isReference = isinstance(intRef, h5py.Reference)\n",
    "    intVal = 0\n",
    "    if isReference:\n",
    "        intObj = dsFile[intRef]\n",
    "        intVal = int(intObj[0])\n",
    "    else: # Assuming value type\n",
    "        intVal = int(intRef)\n",
    "    return intVal\n",
    "\n",
    "def yieldNextInt(intDataset, dsFile):\n",
    "    for intData in intDataset:\n",
    "        intVal = readInt(intData, dsFile)\n",
    "        yield intVal \n",
    "\n",
    "def yieldNextBBox(bboxDataset, dsFile):\n",
    "    for bboxArray in bboxDataset:\n",
    "        bboxGroupRef = bboxArray[0]\n",
    "        bboxGroup = dsFile[bboxGroupRef]\n",
    "        labelDataset = bboxGroup[\"label\"]\n",
    "        leftDataset = bboxGroup[\"left\"]\n",
    "        topDataset = bboxGroup[\"top\"]\n",
    "        widthDataset = bboxGroup[\"width\"]\n",
    "        heightDataset = bboxGroup[\"height\"]\n",
    "\n",
    "        left = yieldNextInt(leftDataset, dsFile)\n",
    "        top = yieldNextInt(topDataset, dsFile)\n",
    "        width = yieldNextInt(widthDataset, dsFile)\n",
    "        height = yieldNextInt(heightDataset, dsFile)\n",
    "\n",
    "        bboxList = []\n",
    "\n",
    "        for label in yieldNextInt(labelDataset, dsFile):\n",
    "            bbox = BBox()\n",
    "            bbox.label = label\n",
    "            bbox.left = next(left)\n",
    "            bbox.top = next(top)\n",
    "            bbox.width = next(width)\n",
    "            bbox.height = next(height)\n",
    "            bboxList.append(bbox)\n",
    "\n",
    "        yield bboxList\n",
    "\n",
    "def yieldNextFileName(nameDataset, dsFile):\n",
    "    for nameArray in nameDataset:\n",
    "        nameRef = nameArray[0]\n",
    "        name = readString(nameRef, dsFile)\n",
    "        yield name\n",
    "\n",
    "# dsFile = h5py.File('train/digitStruct.mat', 'r')\n",
    "def yieldNextDigitStruct(dsFileName):\n",
    "    dsFile = h5py.File(dsFileName, 'r')\n",
    "    dsGroup = readDigitStructGroup(dsFile)\n",
    "    nameDataset = dsGroup[\"name\"]\n",
    "    bboxDataset = dsGroup[\"bbox\"]\n",
    "\n",
    "    bboxListIter = yieldNextBBox(bboxDataset, dsFile)\n",
    "    for name in yieldNextFileName(nameDataset, dsFile):\n",
    "        bboxList = next(bboxListIter)\n",
    "        obj = DigitStruct()\n",
    "        obj.name = name\n",
    "        obj.bboxList = bboxList\n",
    "        yield obj\n",
    "\n",
    "# Declare variables to store labels\n",
    "L = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "y4 = []\n",
    "y5 = []\n",
    "\n",
    "#Declare variables to store overall bounding box\n",
    "left = []\n",
    "top = []\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "def testMain():\n",
    "    i = 0\n",
    "    dsFileName = 'train/digitStruct.mat'\n",
    "    testCounter = 0\n",
    "\n",
    "    for dsObj in yieldNextDigitStruct(dsFileName):\n",
    "        # testCounter += 1\n",
    "       # print(dsObj.name)\n",
    "      #  print(len(dsObj.bboxList))\n",
    "        L.append(len(dsObj.bboxList))\n",
    "        \n",
    "        cnty = 0\n",
    "        width_sum = 0\n",
    "        height_max = 0\n",
    "        for bbox in dsObj.bboxList:\n",
    "         #   print(\"    {}:{},{},{},{}\".format(\n",
    "         #       bbox.label, bbox.left, bbox.top, bbox.width, bbox.height))\n",
    "            \n",
    "            width_sum = width_sum + bbox.width\n",
    "            height_max = max(height_max, bbox.height)\n",
    "                \n",
    "            if cnty == 0: \n",
    "                y1.append(bbox.label)\n",
    "                left.append(bbox.left)\n",
    "                top.append(bbox.top)\n",
    "            elif cnty == 1: y2.append(bbox.label) \n",
    "            elif cnty == 2: y3.append(bbox.label)\n",
    "            elif cnty == 3: y4.append(bbox.label)\n",
    "            elif cnty == 4: y5.append(bbox.label)\n",
    "            \n",
    "            cnty += 1\n",
    "            \n",
    "        width.append(width_sum)\n",
    "        height.append(height_max)\n",
    "\n",
    "        # assign None to empty digits\n",
    "        if cnty < 5:\n",
    "            if len(dsObj.bboxList) < 1: y1.append(None)\n",
    "            if len(dsObj.bboxList) < 2: y2.append(None) \n",
    "            if len(dsObj.bboxList) < 3: y3.append(None)\n",
    "            if len(dsObj.bboxList) < 4: y4.append(None)\n",
    "            if len(dsObj.bboxList) < 5: y5.append(None)\n",
    "        if testCounter >= 5:\n",
    "            break\n",
    "        i +=1\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    t1 = time.time()\n",
    "    testMain()\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Check Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert\n",
      "33402\n",
      "[2 3 2 3 2 3 2 2 3 3]\n",
      "[4 2 2 2 1 3 2 4 8 1]\n",
      "[2 5 9 0 0 2 4 6 1 0]\n",
      "[10 1 10 4 10 7 10 10 7 3]\n",
      "[10 10 10 10 10 10 10 10 10 10]\n",
      "[10 10 10 10 10 10 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "L = np.asarray(L)\n",
    "y1 = np.asarray(y1)\n",
    "y2 = np.asarray(y2)\n",
    "y3 = np.asarray(y3)\n",
    "y4 = np.asarray(y4)\n",
    "y5 = np.asarray(y5)\n",
    "\n",
    "\n",
    "if len(y3[y3==None]) != 0:\n",
    "  print(\"convert\")\n",
    "# Convert 10 to actual 0 label\n",
    "  y1[y1 == 10] = 0\n",
    "  y2[y2 == 10] = 0\n",
    "  y3[y3 == 10] = 0\n",
    "  y4[y4 == 10] = 0\n",
    "  y5[y5 == 10] = 0\n",
    "# Replace None with 10 label\n",
    "  y1[y1 == None] = 10\n",
    "  y2[y2 == None] = 10\n",
    "  y3[y3 == None] = 10\n",
    "  y4[y4 == None] = 10\n",
    "  y5[y5 == None] = 10\n",
    "    \n",
    "\n",
    "print(len(L))\n",
    "print(L[40:50]) # length of digits\n",
    "print(y1[40:50]) # 1st digit\n",
    "print(y2[40:50]) # 2nd digit\n",
    "print(y3[40:50]) # ...etc (If no digit, then 'None')\n",
    "print(y4[40:50])\n",
    "print(y5[40:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset to cropped 32x32 pixels grayscale matrix fitting outer bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 459.72s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "X = []\n",
    "pic_num = 1\n",
    "#print(len(os.listdir('./train')))\n",
    "num_files = len([f for f in os.listdir('./train') if f.endswith('.png') and os.path.isfile(os.path.join('./train', f))])\n",
    "for i in range(num_files): \n",
    "    #print(top[i], height[i], left[i], width[i])\n",
    "    img = cv2.imread(\"./train/\"+str(pic_num) +\".png\",cv2.IMREAD_GRAYSCALE)\n",
    "    #print(img.shape)\n",
    "    #print(img[top[i]:(top[i]+height[i]), left[i]:(left[i]+width[i])].shape)\n",
    "    crop_img = img[max(0,top[i]):(max(0,top[i])+max(0,height[i])), max(0,left[i]):(max(0,left[i])+max(0,width[i]))]\n",
    "    resized_image = cv2.resize(crop_img, (32, 32))\n",
    "    X.append(resized_image)\n",
    "   # print(pic_num)\n",
    "    pic_num +=1\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33402 13402 20000\n",
      "33402 13402 20000\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:20000]\n",
    "L_train = L[:20000] \n",
    "\n",
    "y1_train = y1[:20000]\n",
    "y2_train = y2[:20000]\n",
    "y3_train = y3[:20000]\n",
    "y4_train = y4[:20000]\n",
    "y5_train = y5[:20000]\n",
    "\n",
    "X_valid = X[20000:]\n",
    "L_valid = L[20000:] \n",
    "y1_valid = y1[20000:]\n",
    "y2_valid = y2[20000:]\n",
    "y3_valid = y3[20000:]\n",
    "y4_valid = y4[20000:]\n",
    "y5_valid = y5[20000:]\n",
    "\n",
    "print(len(X), len(X_valid), len(X_train))\n",
    "print(len(L), len(L_valid), len(L_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 3 3 2]\n",
      "[1 2 2 9 3 3 2 7 1 1]\n",
      "[9 3 5 3 1 3 8 4 2 6]\n",
      "[10 10 10 10 10 10 10 4 8 10]\n",
      "[10 10 10 10 10 10 10 4 8 10]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[3 1 2 3 3 3 3 2 3 3]\n",
      "[1 7 5 1 2 6 1 4 7 1]\n",
      "[3 10 0 6 6 9 3 1 5 2]\n",
      "[6 10 10 9 7 6 5 10 1 4]\n",
      "[6 10 10 9 7 6 5 10 1 4]\n",
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "Training set (20000, 32, 32, 1) (20000, 6) (20000, 11)\n",
      "Validation set (13402, 32, 32, 1) (13402, 6) (13402, 11)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32 # 32 x 32 pixel\n",
    "num_channels = 1 # grayscale\n",
    "num_labels = 11 # 0-9 + 10 (for missing value)\n",
    "num_digits = 6 #max 5 digit for housenumber\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, label0, label1, label2, label3, label4, label5):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  print((label0[:10]))\n",
    "  print((label1[:10]))\n",
    "  print((label2[:10]))\n",
    "  print((label3[:10]))\n",
    "  print(label3[:10])\n",
    "  label0 = (np.arange(num_digits) == label0[:,None]).astype(np.float32)\n",
    "  label1 = (np.arange(num_labels) == label1[:,None]).astype(np.float32)\n",
    "  label2 = (np.arange(num_labels) == label2[:,None]).astype(np.float32)\n",
    "  label3 = (np.arange(num_labels) == label3[:,None]).astype(np.float32)\n",
    "  label4 = (np.arange(num_labels) == label4[:,None]).astype(np.float32)\n",
    "  label5 = (np.arange(num_labels) == label5[:,None]).astype(np.float32)\n",
    "\n",
    "  print(label3[:10])\n",
    "  return dataset, label0, label1, label2, label3, label4, label5\n",
    "train_dataset, train_label0, train_label1, train_label2, train_label3, train_label4, train_label5 = reformat(np.asarray(X_train), L_train, y1_train, y2_train, y3_train, y4_train, y5_train)\n",
    "valid_dataset, valid_label0, valid_label1, valid_label2, valid_label3, valid_label4, valid_label5 = reformat(np.asarray(X_valid), L_valid, y1_valid, y2_valid, y3_valid, y4_valid, y5_valid)\n",
    "#test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "#normalize to 0 mean and unit variance\n",
    "train_dataset_norm = (train_dataset - np.mean( train_dataset))/np.std( train_dataset)\n",
    "\n",
    "# Check values\n",
    "print('Training set', train_dataset.shape, train_label0.shape, train_label1.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_label0.shape, valid_label1.shape)\n",
    "#print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot house number image\n",
    "\n",
    "#### Reference: https://github.com/llSourcell/How_to_make_a_tensorflow_image_classifier_LIVE/blob/master/demonotes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19', '23', '25', '93', '31', '33', '28', '744', '128']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133a4bc49b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    #assert len(images) == len(cls_true) \n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(image_size, image_size), cmap='binary')\n",
    "        \n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "# Get the first images from the test-set.\n",
    "images = train_dataset_norm[0:9]\n",
    "    \n",
    "# Get the true classes for those images.\n",
    "cls_true = [\"{}{}{}{}{}\".format(str(a_).replace('10',''), str(b_).replace('10',''), str(c_).replace('10',''), str(d_).replace('10',''), str(e_).replace('10','')) \n",
    "       for a_, b_, c_, d_, e_ in zip(y1_train[0:9], y2_train[0:9], y3_train[0:9], y4_train[0:9], y5_train[0:9])]\n",
    "\n",
    "print([\"{}{}{}{}{}\".format(str(a_).replace('10',''), str(b_).replace('10',''), str(c_).replace('10',''), str(d_).replace('10',''), str(e_).replace('10','')) \n",
    "       for a_, b_, c_, d_, e_ in zip(y1_train[0:9], y2_train[0:9], y3_train[0:9], y4_train[0:9], y5_train[0:9])])\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "valid_dataset_batch = valid_dataset[:batch_size]\n",
    "\n",
    "num_conv_layers = 3\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36        # There are 36 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size3 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters3 = 64        # There are 64 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 1024         # Number of neurons in fully-connected hidden layer\n",
    "num_fc_layers = 3\n",
    "drop_rate1 = 0.4 \n",
    "drop_rate2 = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare variables to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    #with tf.device('/gpu:0'):\n",
    "    \n",
    "  def weight_variable(w_id, shape, stdev_num):\n",
    "    #return (tf.Variable(tf.truncated_normal(shape,stddev=np.sqrt(2.0/(stdev_num)))))\n",
    "    return (tf.get_variable(w_id,  initializer = tf.truncated_normal(shape,stddev=np.sqrt(2.0/(stdev_num)))))\n",
    "\n",
    "  def bias_variable(b_id, shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    #return tf.Variable(initial)\n",
    "    return tf.get_variable(b_id, initializer = initial)\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels0 = tf.placeholder(tf.float32, shape=(batch_size, num_digits))\n",
    "  tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels5 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset =  tf.constant(valid_dataset_batch) \n",
    " # tf_test_dataset = tf.constant(test_dataset) \n",
    "\n",
    "  def conv_layers(layer_num, data, weights, biases, input_size,filter_size, num_filters, valid=False, use_pooling=True): \n",
    "   # ########\n",
    "   # # Conv with leaky relu and 2x2 max pooling\n",
    "   # ########\n",
    "\n",
    "    if not valid:\n",
    "    # create filter-weights and bias during training\n",
    "        shape = [filter_size, filter_size, input_size, num_filters]\n",
    "        stdev_n = (filter_size*filter_size*input_size)\n",
    "        weights.append(weight_variable(\"cvw0_\"+layer_num, shape, stdev_n))\n",
    "        biases.append(bias_variable(\"cvb0_\"+layer_num, [num_filters]))\n",
    "\n",
    "    hidden=[]\n",
    "    y0 =  tf.nn.conv2d(input=data,filter=weights[0],strides=[1, 1, 1, 1],padding='SAME')\n",
    "    hidden.append(tf.maximum((y0 + biases[0]), 0.01*(y0+biases[0])))\n",
    "    \n",
    "    for L in range(1,num_conv_layers+1):   \n",
    "        if not valid:\n",
    "            shape = [filter_size, filter_size, num_filters, num_filters]\n",
    "            stdev_n = filter_size*filter_size*num_filters\n",
    "                \n",
    "            weights.append(weight_variable(\"cvw\"+str(L)+\"_\"+layer_num, shape, stdev_n))\n",
    "            biases.append(bias_variable(\"cvb\"+str(L)+\"_\"+layer_num, [num_filters]))   \n",
    "\n",
    "        y = tf.nn.conv2d(input=hidden[L-1],filter=weights[L],strides=[1, 1, 1, 1],padding='SAME')\n",
    "        hidden.append(tf.maximum((y + biases[L]), 0.01*(y+biases[L])))\n",
    "\n",
    "    layer = tf.nn.max_pool(value=hidden[num_conv_layers], ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    return layer, weights, biases\n",
    "    \n",
    "  def fc_layers(layer_num, weights, biases, out_weights, out_biases, data, label_count, valid = False):\n",
    "   #  #####\n",
    "   #  # FC Layers - with leaky relu and dropout\n",
    "   #  #####\n",
    "\n",
    "    out_size = data.get_shape().as_list()[1]\n",
    "    if not valid:\n",
    "        #create weights and biases during training\n",
    "        weights.append(weight_variable(\"fcw0_\"+layer_num, [out_size, fc_size], fc_size*fc_size)) # w = 1024 depth * 1024 FC hidden node layer\n",
    "        biases.append(bias_variable(\"fcb0_\"+layer_num, [fc_size])) #  # b = 1024 FC hidden node layers1024\n",
    "\n",
    "    hidden=[]\n",
    "    y0 = (tf.matmul(data, weights[0]) + biases[0])\n",
    "    hidden.append(tf.nn.dropout(tf.maximum(y0, 0.01*y0), drop_rate1))\n",
    "    \n",
    "    for L in range(1,num_fc_layers+1):   \n",
    "        if not valid:\n",
    "            weights.append(weight_variable(\"fcw\"+str(L)+\"_\"+layer_num,[fc_size, fc_size], fc_size*fc_size))\n",
    "            biases.append(bias_variable(\"fcb\"+str(L)+\"_\"+layer_num,[fc_size]))   \n",
    "        y = ((tf.matmul(hidden[L-1], weights[L]) + biases[L])) \n",
    "        hidden.append(tf.nn.dropout(tf.maximum(y, 0.01*y), drop_rate2))\n",
    "        \n",
    "      #Definitive output  after relu layer's:  \n",
    "    if not valid:\n",
    "        out_weights = weight_variable(\"rlw_\"+layer_num,[fc_size, label_count], fc_size*label_count)\n",
    "        out_biases = bias_variable(\"rlb_\"+layer_num,[label_count])      \n",
    "    logits = tf.matmul(hidden[num_fc_layers], out_weights) + out_biases\n",
    "        \n",
    "    return logits, weights, biases, out_weights, out_biases\n",
    "    \n",
    "  wc1, wc2, wc3 = [], [], []\n",
    "  bc1, bc2, bc3 = [], [], []\n",
    "  convpool1, wc1, bc1 = conv_layers(\"1\", tf_train_dataset, wc1, bc1, num_channels, filter_size1, num_filters1)\n",
    "  convpool2, wc2, bc2 = conv_layers(\"2\", convpool1, wc2, bc2, num_filters1, filter_size2, num_filters2)\n",
    "  convpool3, wc3, bc3 = conv_layers(\"3\", convpool2, wc3, bc3, num_filters2, filter_size3, num_filters3)\n",
    "\n",
    "  shape = convpool3.get_shape().as_list()\n",
    "  conv_layers_reshape = tf.reshape(convpool3, [shape[0], shape[1] * shape[2] * shape[3]]) #[256, 4, 4, 64]\n",
    "\n",
    "  w0, w1, w2, w3, w4, w5 = [], [], [], [], [], []\n",
    "  b0, b1, b2, b3, b4, b5 = [], [], [], [], [], []\n",
    "  \n",
    " # Training computation.\n",
    "  logits0, w0, b0, out_w0, out_b0 = fc_layers(\"1\", w0, b0, None, None, conv_layers_reshape, num_digits)  \n",
    "  logits1, w1, b1, out_w1, out_b1 = fc_layers(\"2\", w1, b1, None, None, conv_layers_reshape, num_labels) \n",
    "  logits2, w2, b2, out_w2, out_b2 = fc_layers(\"3\", w2, b2, None, None, conv_layers_reshape, num_labels) \n",
    "  logits3, w3, b3, out_w3, out_b3 = fc_layers(\"4\", w3, b3, None, None, conv_layers_reshape, num_labels) \n",
    "  logits4, w4, b4, out_w4, out_b4 = fc_layers(\"5\", w4, b4, None, None, conv_layers_reshape, num_labels) \n",
    "  logits5, w5, b5, out_w5, out_b5 = fc_layers(\"6\", w5, b5, None, None, conv_layers_reshape, num_labels)   \n",
    "\n",
    "  loss0 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels0, logits=logits0) \n",
    "  loss1 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels1, logits=logits1)\n",
    "  loss2 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels2, logits=logits2)\n",
    "  loss3 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels3, logits=logits3)\n",
    "  loss4 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels4, logits=logits4)\n",
    "  loss5 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels5, logits=logits5)\n",
    "  loss= tf.reduce_mean(loss0) + tf.reduce_mean(loss1) + tf.reduce_mean(loss2) + tf.reduce_mean(loss3) + tf.reduce_mean(loss4) + tf.reduce_mean(loss5)\n",
    "    \n",
    " # Optimizer.\n",
    " # optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  global_step = tf.Variable(0) #, trainable=False)  # count the number of steps taken.\n",
    " # learning_rate = tf.train.exponential_decay(0.1, global_step, 100000, 0.96, staircase=True)\n",
    "#  learning_rate = tf.train.exponential_decay(0.05, global_step, 100, 0.95) #, staircase=True)\n",
    " # optimizer = tf.train.GradientDescentOptimizer(1e-6).minimize(loss) #, global_step=global_step)\n",
    "  optimizer =tf.train.AdamOptimizer(0.001).minimize(loss, global_step=global_step) \n",
    "\n",
    "  # Validation computation.\n",
    "  convpool1v, _, _ = conv_layers(\"1\", tf_valid_dataset, wc1, bc1, num_channels, filter_size1, num_filters1, True)\n",
    "  convpool2v, _, _ = conv_layers(\"2\", convpool1v, wc2, bc2, num_filters1, filter_size2, num_filters2, True)\n",
    "  convpool3v, _, _ = conv_layers(\"3\", convpool2v, wc3, bc3, num_filters2, filter_size3, num_filters3, True)\n",
    "  shapev = convpool3v.get_shape().as_list()\n",
    "  conv_layers_reshape_valid = tf.reshape(convpool3v, [shapev[0], shapev[1] * shapev[2] * shapev[3]]) #[256, 4, 4, 64]\n",
    "\n",
    "  logits0_valid, _, _, _, _ = fc_layers(\"1\", w0, b0, out_w0, out_b0, conv_layers_reshape_valid, num_digits, True) \n",
    "  logits1_valid, _, _, _, _ = fc_layers(\"2\", w1, b1, out_w1, out_b1, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits2_valid, _, _, _, _ = fc_layers(\"3\", w2, b2, out_w2, out_b2, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits3_valid, _, _, _, _ = fc_layers(\"4\", w3, b3, out_w3, out_b3, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits4_valid, _, _, _, _ = fc_layers(\"5\", w4, b4, out_w4, out_b4, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits5_valid, _, _, _, _ = fc_layers(\"6\", w5, b5, out_w5, out_b5, conv_layers_reshape_valid, num_labels, True) \n",
    "\n",
    " # Predictions for the training, validation, and test data.\n",
    "  train_prediction0 = tf.nn.softmax(logits0)\n",
    "  valid_prediction0 = tf.nn.softmax(logits0_valid)\n",
    "  train_prediction1 = tf.nn.softmax(logits1)\n",
    "  valid_prediction1 = tf.nn.softmax(logits1_valid)\n",
    "  train_prediction2 = tf.nn.softmax(logits2)\n",
    "  valid_prediction2 = tf.nn.softmax(logits2_valid)\n",
    "  train_prediction3 = tf.nn.softmax(logits3)\n",
    "  valid_prediction3 = tf.nn.softmax(logits3_valid)\n",
    "  train_prediction4 = tf.nn.softmax(logits4)\n",
    "  valid_prediction4 = tf.nn.softmax(logits4_valid)\n",
    "  train_prediction5 = tf.nn.softmax(logits5)\n",
    "  valid_prediction5 = tf.nn.softmax(logits5_valid)\n",
    "\n",
    "  #test_prediction = tf.nn.softmax(model(tf_test_dataset)) \n",
    "\n",
    "  # Add ops to save and restore all the variables.\n",
    "  saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch training loss at step 0: 13.777848\n",
      "Training accuracy - digit count: 3.1%; digits 1-5: 6.6%, 6.2%, 4.3%, 2.0%, 2.0%\n",
      "Training avg accuracy: 4.0%\n",
      "Validation accuracy - digit count: 3.1%; digits 1-5: 11.3%, 8.6%, 4.7%, 2.0%, 1.6%\n",
      "Validation avg accuracy: 5.2%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 50: 7.124750\n",
      "Training accuracy - digit count: 49.6%; digits 1-5: 25.0%, 19.1%, 68.8%, 96.9%, 100.0%\n",
      "Training avg accuracy: 59.9%\n",
      "Validation accuracy - digit count: 48.8%; digits 1-5: 27.3%, 18.4%, 67.2%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 59.6%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 100: 6.987835\n",
      "Training accuracy - digit count: 53.9%; digits 1-5: 27.7%, 19.1%, 73.0%, 96.1%, 100.0%\n",
      "Training avg accuracy: 61.7%\n",
      "Validation accuracy - digit count: 48.8%; digits 1-5: 27.3%, 18.4%, 67.2%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 59.6%\n",
      "Minibatch training loss at step 150: 6.644724\n",
      "Training accuracy - digit count: 59.8%; digits 1-5: 30.9%, 18.8%, 72.7%, 94.9%, 100.0%\n",
      "Training avg accuracy: 62.8%\n",
      "Validation accuracy - digit count: 61.3%; digits 1-5: 32.0%, 25.0%, 67.2%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 63.6%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 200: 5.910306\n",
      "Training accuracy - digit count: 71.9%; digits 1-5: 39.8%, 23.0%, 73.0%, 96.9%, 100.0%\n",
      "Training avg accuracy: 67.4%\n",
      "Validation accuracy - digit count: 75.4%; digits 1-5: 37.1%, 27.3%, 67.6%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 67.3%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 250: 5.790462\n",
      "Training accuracy - digit count: 71.1%; digits 1-5: 42.2%, 30.5%, 70.3%, 95.3%, 100.0%\n",
      "Training avg accuracy: 68.2%\n",
      "Validation accuracy - digit count: 76.2%; digits 1-5: 40.2%, 26.2%, 68.0%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 67.8%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 300: 4.849355\n",
      "Training accuracy - digit count: 84.0%; digits 1-5: 51.2%, 32.8%, 68.4%, 96.5%, 100.0%\n",
      "Training avg accuracy: 72.1%\n",
      "Validation accuracy - digit count: 85.9%; digits 1-5: 50.0%, 37.1%, 69.1%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 73.0%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 350: 4.274024\n",
      "Training accuracy - digit count: 89.5%; digits 1-5: 59.8%, 33.6%, 76.6%, 96.1%, 100.0%\n",
      "Training avg accuracy: 75.9%\n",
      "Validation accuracy - digit count: 88.7%; digits 1-5: 56.2%, 41.4%, 70.3%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 75.5%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 400: 4.035082\n",
      "Training accuracy - digit count: 87.9%; digits 1-5: 62.1%, 44.1%, 70.7%, 94.1%, 100.0%\n",
      "Training avg accuracy: 76.5%\n",
      "Validation accuracy - digit count: 89.1%; digits 1-5: 60.2%, 45.3%, 68.8%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 76.6%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 450: 3.577110\n",
      "Training accuracy - digit count: 87.9%; digits 1-5: 69.9%, 48.4%, 72.3%, 96.9%, 100.0%\n",
      "Training avg accuracy: 79.2%\n",
      "Validation accuracy - digit count: 88.3%; digits 1-5: 66.0%, 54.7%, 70.7%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 79.3%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 500: 3.571562\n",
      "Training accuracy - digit count: 82.0%; digits 1-5: 73.4%, 52.0%, 76.2%, 94.1%, 100.0%\n",
      "Training avg accuracy: 79.6%\n",
      "Validation accuracy - digit count: 87.5%; digits 1-5: 72.3%, 56.2%, 69.9%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 80.3%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 550: 3.386100\n",
      "Training accuracy - digit count: 92.2%; digits 1-5: 76.6%, 60.5%, 69.1%, 95.7%, 100.0%\n",
      "Training avg accuracy: 82.4%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 72.3%, 60.5%, 70.3%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 81.5%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 600: 2.600194\n",
      "Training accuracy - digit count: 94.1%; digits 1-5: 79.3%, 65.2%, 77.0%, 96.1%, 100.0%\n",
      "Training avg accuracy: 85.3%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 77.0%, 64.8%, 71.1%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 83.1%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 650: 2.612749\n",
      "Training accuracy - digit count: 90.6%; digits 1-5: 81.2%, 71.9%, 72.3%, 96.9%, 100.0%\n",
      "Training avg accuracy: 85.5%\n",
      "Validation accuracy - digit count: 90.2%; digits 1-5: 77.7%, 71.1%, 71.1%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 84.4%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 700: 2.477888\n",
      "Training accuracy - digit count: 93.8%; digits 1-5: 84.0%, 74.2%, 70.7%, 94.9%, 100.0%\n",
      "Training avg accuracy: 86.3%\n",
      "Validation accuracy - digit count: 93.0%; digits 1-5: 81.6%, 69.5%, 69.1%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 84.9%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 750: 2.386771\n",
      "Training accuracy - digit count: 92.6%; digits 1-5: 87.5%, 78.9%, 76.6%, 94.9%, 100.0%\n",
      "Training avg accuracy: 88.4%\n",
      "Validation accuracy - digit count: 87.5%; digits 1-5: 81.2%, 75.4%, 71.1%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 85.2%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 800: 2.503408\n",
      "Training accuracy - digit count: 91.8%; digits 1-5: 85.2%, 73.4%, 75.4%, 94.5%, 100.0%\n",
      "Training avg accuracy: 86.7%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 82.0%, 78.1%, 70.3%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 86.3%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 850: 2.117370\n",
      "Training accuracy - digit count: 93.4%; digits 1-5: 91.0%, 80.5%, 73.8%, 95.3%, 100.0%\n",
      "Training avg accuracy: 89.0%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 83.6%, 77.7%, 72.7%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.0%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 900: 1.835537\n",
      "Training accuracy - digit count: 97.3%; digits 1-5: 90.2%, 78.9%, 77.3%, 96.1%, 100.0%\n",
      "Training avg accuracy: 90.0%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 84.4%, 73.8%, 73.0%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 86.3%\n",
      "Minibatch training loss at step 950: 2.098379\n",
      "Training accuracy - digit count: 94.1%; digits 1-5: 89.1%, 80.9%, 71.9%, 94.9%, 100.0%\n",
      "Training avg accuracy: 88.5%\n",
      "Validation accuracy - digit count: 92.2%; digits 1-5: 82.8%, 76.2%, 73.0%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 86.8%\n",
      "Minibatch training loss at step 1000: 1.998744\n",
      "Training accuracy - digit count: 93.4%; digits 1-5: 88.3%, 82.0%, 76.6%, 96.5%, 100.0%\n",
      "Training avg accuracy: 89.5%\n",
      "Validation accuracy - digit count: 91.8%; digits 1-5: 86.3%, 76.6%, 75.0%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.7%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 1050: 1.711851\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 93.4%, 83.2%, 76.2%, 94.1%, 100.0%\n",
      "Training avg accuracy: 90.5%\n",
      "Validation accuracy - digit count: 92.2%; digits 1-5: 85.9%, 78.9%, 71.5%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.5%\n",
      "Minibatch training loss at step 1100: 1.643280\n",
      "Training accuracy - digit count: 95.3%; digits 1-5: 93.0%, 81.6%, 83.2%, 97.3%, 100.0%\n",
      "Training avg accuracy: 91.7%\n",
      "Validation accuracy - digit count: 91.0%; digits 1-5: 86.7%, 74.6%, 71.5%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 86.7%\n",
      "Minibatch training loss at step 1150: 1.672349\n",
      "Training accuracy - digit count: 96.9%; digits 1-5: 88.7%, 82.4%, 78.9%, 97.3%, 100.0%\n",
      "Training avg accuracy: 90.7%\n",
      "Validation accuracy - digit count: 93.4%; digits 1-5: 84.8%, 81.2%, 75.8%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 1200: 1.618898\n",
      "Training accuracy - digit count: 97.3%; digits 1-5: 93.0%, 81.6%, 80.1%, 94.5%, 100.0%\n",
      "Training avg accuracy: 91.1%\n",
      "Validation accuracy - digit count: 91.8%; digits 1-5: 85.2%, 79.3%, 74.2%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 87.8%\n",
      "Minibatch training loss at step 1250: 1.384715\n",
      "Training accuracy - digit count: 98.0%; digits 1-5: 92.2%, 87.9%, 82.8%, 96.5%, 99.6%\n",
      "Training avg accuracy: 92.8%\n",
      "Validation accuracy - digit count: 93.4%; digits 1-5: 87.9%, 78.5%, 73.4%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.3%\n",
      "Minibatch training loss at step 1300: 1.507797\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 94.5%, 87.9%, 78.9%, 96.1%, 100.0%\n",
      "Training avg accuracy: 92.3%\n",
      "Validation accuracy - digit count: 91.8%; digits 1-5: 87.9%, 78.5%, 72.3%, 94.5%, 100.0%\n",
      "Validation avg accuracy: 87.5%\n",
      "Minibatch training loss at step 1350: 1.628713\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 94.1%, 82.4%, 82.0%, 93.8%, 100.0%\n",
      "Training avg accuracy: 91.4%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 82.4%, 78.5%, 74.2%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 86.7%\n",
      "Minibatch training loss at step 1400: 1.658967\n",
      "Training accuracy - digit count: 96.5%; digits 1-5: 87.1%, 85.5%, 82.4%, 97.7%, 100.0%\n",
      "Training avg accuracy: 91.5%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 81.2%, 77.7%, 73.8%, 94.9%, 100.0%\n",
      "Validation avg accuracy: 86.2%\n",
      "Minibatch training loss at step 1450: 1.603331\n",
      "Training accuracy - digit count: 97.3%; digits 1-5: 94.5%, 86.3%, 81.2%, 94.1%, 99.6%\n",
      "Training avg accuracy: 92.2%\n",
      "Validation accuracy - digit count: 92.2%; digits 1-5: 86.7%, 81.2%, 77.0%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.8%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 1500: 1.642603\n",
      "Training accuracy - digit count: 96.9%; digits 1-5: 90.6%, 85.9%, 79.7%, 93.4%, 100.0%\n",
      "Training avg accuracy: 91.1%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 84.4%, 79.7%, 77.0%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 87.7%\n",
      "Minibatch training loss at step 1550: 1.463758\n",
      "Training accuracy - digit count: 94.5%; digits 1-5: 92.2%, 85.5%, 83.6%, 95.3%, 100.0%\n",
      "Training avg accuracy: 91.9%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 83.6%, 76.2%, 74.6%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 86.7%\n",
      "Minibatch training loss at step 1600: 1.562174\n",
      "Training accuracy - digit count: 96.9%; digits 1-5: 92.6%, 87.1%, 79.3%, 94.5%, 100.0%\n",
      "Training avg accuracy: 91.7%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 85.5%, 78.9%, 76.2%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 88.0%\n",
      "Minibatch training loss at step 1650: 1.268782\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 94.1%, 88.7%, 83.6%, 98.4%, 100.0%\n",
      "Training avg accuracy: 93.9%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 85.9%, 80.5%, 77.7%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.2%\n",
      "Minibatch training loss at step 1700: 1.144115\n",
      "Training accuracy - digit count: 97.7%; digits 1-5: 94.9%, 88.7%, 84.8%, 96.1%, 100.0%\n",
      "Training avg accuracy: 93.7%\n",
      "Validation accuracy - digit count: 91.0%; digits 1-5: 85.2%, 79.7%, 77.3%, 94.9%, 100.0%\n",
      "Validation avg accuracy: 88.0%\n",
      "Minibatch training loss at step 1750: 1.077328\n",
      "Training accuracy - digit count: 99.2%; digits 1-5: 94.1%, 85.2%, 89.5%, 96.9%, 100.0%\n",
      "Training avg accuracy: 94.1%\n",
      "Validation accuracy - digit count: 91.0%; digits 1-5: 85.2%, 79.7%, 75.8%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 87.9%\n",
      "Minibatch training loss at step 1800: 1.094386\n",
      "Training accuracy - digit count: 98.4%; digits 1-5: 94.1%, 91.0%, 89.5%, 94.5%, 99.6%\n",
      "Training avg accuracy: 94.5%\n",
      "Validation accuracy - digit count: 90.2%; digits 1-5: 83.6%, 80.1%, 77.3%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 87.9%\n",
      "Minibatch training loss at step 1850: 1.111690\n",
      "Training accuracy - digit count: 98.0%; digits 1-5: 92.6%, 87.5%, 84.8%, 98.0%, 100.0%\n",
      "Training avg accuracy: 93.5%\n",
      "Validation accuracy - digit count: 91.0%; digits 1-5: 84.4%, 80.1%, 77.0%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.0%\n",
      "Minibatch training loss at step 1900: 0.975410\n",
      "Training accuracy - digit count: 97.7%; digits 1-5: 93.4%, 90.2%, 89.8%, 96.9%, 100.0%\n",
      "Training avg accuracy: 94.7%\n",
      "Validation accuracy - digit count: 92.2%; digits 1-5: 83.6%, 82.0%, 77.0%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.5%\n",
      "Minibatch training loss at step 1950: 1.174774\n",
      "Training accuracy - digit count: 97.3%; digits 1-5: 94.1%, 88.7%, 83.2%, 97.3%, 100.0%\n",
      "Training avg accuracy: 93.4%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 84.4%, 78.5%, 78.1%, 93.8%, 100.0%\n",
      "Validation avg accuracy: 87.6%\n",
      "Minibatch training loss at step 2000: 1.193291\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 95.3%, 87.1%, 87.9%, 94.5%, 100.0%\n",
      "Training avg accuracy: 93.5%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 86.3%, 76.2%, 76.6%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.8%\n",
      "Minibatch training loss at step 2050: 0.980094\n",
      "Training accuracy - digit count: 98.4%; digits 1-5: 94.1%, 91.8%, 90.6%, 97.7%, 100.0%\n",
      "Training avg accuracy: 95.4%\n",
      "Validation accuracy - digit count: 90.2%; digits 1-5: 85.5%, 76.6%, 78.1%, 94.1%, 100.0%\n",
      "Validation avg accuracy: 87.4%\n",
      "Minibatch training loss at step 2100: 1.103884\n",
      "Training accuracy - digit count: 97.3%; digits 1-5: 94.9%, 90.2%, 87.9%, 93.8%, 100.0%\n",
      "Training avg accuracy: 94.0%\n",
      "Validation accuracy - digit count: 91.0%; digits 1-5: 86.7%, 79.7%, 81.2%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 89.0%\n",
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 2150: 1.022787\n",
      "Training accuracy - digit count: 97.7%; digits 1-5: 94.1%, 92.6%, 89.1%, 98.0%, 100.0%\n",
      "Training avg accuracy: 95.2%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 86.3%, 80.9%, 76.6%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 88.2%\n",
      "Minibatch training loss at step 2200: 1.220722\n",
      "Training accuracy - digit count: 96.5%; digits 1-5: 93.4%, 87.9%, 88.3%, 94.9%, 100.0%\n",
      "Training avg accuracy: 93.5%\n",
      "Validation accuracy - digit count: 88.3%; digits 1-5: 85.2%, 78.9%, 79.7%, 94.5%, 100.0%\n",
      "Validation avg accuracy: 87.8%\n",
      "Minibatch training loss at step 2250: 0.862025\n",
      "Training accuracy - digit count: 99.2%; digits 1-5: 93.0%, 90.2%, 93.0%, 95.7%, 100.0%\n",
      "Training avg accuracy: 95.2%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 83.6%, 79.7%, 79.7%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.5%\n",
      "Minibatch training loss at step 2300: 0.980636\n",
      "Training accuracy - digit count: 98.0%; digits 1-5: 94.1%, 92.2%, 85.9%, 97.3%, 100.0%\n",
      "Training avg accuracy: 94.6%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 84.0%, 79.3%, 78.5%, 94.9%, 100.0%\n",
      "Validation avg accuracy: 87.8%\n",
      "Minibatch training loss at step 2350: 1.127935\n",
      "Training accuracy - digit count: 97.7%; digits 1-5: 93.8%, 91.0%, 89.1%, 95.3%, 100.0%\n",
      "Training avg accuracy: 94.5%\n",
      "Validation accuracy - digit count: 92.6%; digits 1-5: 85.5%, 78.9%, 78.5%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.5%\n",
      "Minibatch training loss at step 2400: 0.868729\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 94.9%, 91.0%, 92.2%, 95.7%, 100.0%\n",
      "Training avg accuracy: 95.4%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 83.6%, 80.5%, 82.0%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 88.7%\n",
      "Minibatch training loss at step 2450: 1.048962\n",
      "Training accuracy - digit count: 98.4%; digits 1-5: 95.7%, 91.4%, 88.3%, 96.5%, 100.0%\n",
      "Training avg accuracy: 95.1%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 83.6%, 81.6%, 78.5%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 88.4%\n",
      "Minibatch training loss at step 2500: 0.890118\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 94.5%, 91.8%, 92.2%, 97.7%, 100.0%\n",
      "Training avg accuracy: 95.4%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 84.4%, 81.2%, 80.9%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 88.7%\n",
      "Minibatch training loss at step 2550: 1.007670\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 94.5%, 92.6%, 90.2%, 93.8%, 100.0%\n",
      "Training avg accuracy: 95.0%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 86.7%, 81.2%, 81.6%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 89.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Minibatch training loss at step 2600: 0.752590\n",
      "Training accuracy - digit count: 99.2%; digits 1-5: 96.5%, 89.5%, 93.0%, 97.7%, 100.0%\n",
      "Training avg accuracy: 96.0%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 83.6%, 77.7%, 81.2%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.0%\n",
      "Minibatch training loss at step 2650: 0.811610\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 94.9%, 92.6%, 93.4%, 96.1%, 100.0%\n",
      "Training avg accuracy: 96.0%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 85.2%, 81.2%, 80.5%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 88.8%\n",
      "Minibatch training loss at step 2700: 0.842172\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 96.1%, 89.5%, 90.2%, 97.3%, 100.0%\n",
      "Training avg accuracy: 95.3%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 84.8%, 80.1%, 80.9%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 88.9%\n",
      "Minibatch training loss at step 2750: 0.670006\n",
      "Training accuracy - digit count: 99.6%; digits 1-5: 94.9%, 93.4%, 92.6%, 97.7%, 100.0%\n",
      "Training avg accuracy: 96.4%\n",
      "Validation accuracy - digit count: 89.1%; digits 1-5: 85.5%, 82.4%, 81.2%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 88.9%\n",
      "Minibatch training loss at step 2800: 0.644953\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 98.0%, 94.9%, 93.0%, 96.1%, 100.0%\n",
      "Training avg accuracy: 96.8%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 84.4%, 79.7%, 81.6%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.8%\n",
      "Minibatch training loss at step 2850: 0.820977\n",
      "Training accuracy - digit count: 98.4%; digits 1-5: 95.3%, 92.2%, 90.6%, 96.5%, 99.6%\n",
      "Training avg accuracy: 95.4%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 84.4%, 80.1%, 81.6%, 94.1%, 100.0%\n",
      "Validation avg accuracy: 88.3%\n",
      "Minibatch training loss at step 2900: 0.681599\n",
      "Training accuracy - digit count: 99.6%; digits 1-5: 96.1%, 91.8%, 92.2%, 99.2%, 100.0%\n",
      "Training avg accuracy: 96.5%\n",
      "Validation accuracy - digit count: 91.8%; digits 1-5: 83.2%, 77.7%, 81.6%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 88.3%\n",
      "Minibatch training loss at step 2950: 0.789870\n",
      "Training accuracy - digit count: 98.8%; digits 1-5: 95.3%, 91.4%, 91.4%, 95.3%, 100.0%\n",
      "Training avg accuracy: 95.4%\n",
      "Validation accuracy - digit count: 90.2%; digits 1-5: 84.8%, 81.6%, 80.5%, 94.9%, 100.0%\n",
      "Validation avg accuracy: 88.7%\n",
      "Minibatch training loss at step 3000: 0.947978\n",
      "Training accuracy - digit count: 96.9%; digits 1-5: 94.9%, 93.4%, 93.0%, 96.1%, 100.0%\n",
      "Training avg accuracy: 95.7%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 84.0%, 80.1%, 79.7%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 88.5%\n",
      "Time: 30936.89s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#def eval_accuracy(eval_l_preds, eval_preds, l_labels, labels, masks):\n",
    "#    concatted = np.concatenate((np.reshape((eval_l_preds == l_labels), [-1, 1]), \n",
    "#                                (eval_preds * masks) == labels), axis=1)\n",
    "#    return 100.0 * (np.sum([np.all(row) for row in concatted])) / len(labels)\n",
    "#\n",
    "\n",
    "num_steps = 3001\n",
    "max_acc = 0\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run() # sess.run(tf.global_variables_initializer())\n",
    "  #session.run(init_op)\n",
    "  print('Initialized')\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (np.asarray(y1_train).shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "    \n",
    "    #normalize data to mean 0 and unit variance\n",
    "   # batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "\n",
    "  #  batch_data_valid = valid_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "\n",
    "    batch_labels0 =  np.asarray(train_label0)[offset:(offset + batch_size), :]\n",
    "    batch_labels1 =  np.asarray(train_label1)[offset:(offset + batch_size), :]\n",
    "    batch_labels2 =  np.asarray(train_label2)[offset:(offset + batch_size), :]\n",
    "    batch_labels3 =  np.asarray(train_label3)[offset:(offset + batch_size), :]\n",
    "    batch_labels4 =  np.asarray(train_label4)[offset:(offset + batch_size), :]\n",
    "    batch_labels5 =  np.asarray(train_label5)[offset:(offset + batch_size), :]    \n",
    "   # print(batch_labels1.shape)\n",
    "    feed_dict = {tf_train_dataset : batch_data\n",
    "              #  , tf_valid_dataset : batch_data_valid\n",
    "                , tf_train_labels0 : batch_labels0\n",
    "                , tf_train_labels1 : batch_labels1\n",
    "                , tf_train_labels2 : batch_labels2\n",
    "                , tf_train_labels3 : batch_labels3\n",
    "                , tf_train_labels4 : batch_labels4\n",
    "                , tf_train_labels5 : batch_labels5\n",
    "                }\n",
    "\n",
    "    _, l, pred_train0, pred_train1, pred_train2, pred_train3, pred_train4, pred_train5  \\\n",
    "        , pred_valid0, pred_valid1, pred_valid2, pred_valid3, pred_valid4, pred_valid5  \\\n",
    "        = session.run([optimizer, loss, train_prediction0, train_prediction1, train_prediction2  \\\n",
    "                       , train_prediction3, train_prediction4, train_prediction5, valid_prediction0  \\\n",
    "                       , valid_prediction1, valid_prediction2, valid_prediction3 , valid_prediction4, valid_prediction5]  \\\n",
    "                      , feed_dict=feed_dict)\n",
    "     \n",
    "    #normalize data to mean 0 and unit variance\n",
    "  #  batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "   # batch_valid_labels0 =  np.asarray(valid_label0)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels1 =  np.asarray(valid_label1)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels2 =  np.asarray(valid_label2)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels3 =  np.asarray(valid_label3)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels4 =  np.asarray(valid_label4)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels5 =  np.asarray(valid_label5)[offset:(offset + batch_size), :]  \n",
    "    \n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch training loss at step %d: %f' % (step, l))\n",
    "      print(\"Training accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_train0, batch_labels0),accuracy(pred_train1, batch_labels1)  \\\n",
    "        ,accuracy(pred_train2, batch_labels2), accuracy(pred_train3, batch_labels3)  \\\n",
    "        ,accuracy(pred_train4, batch_labels4), accuracy(pred_train5, batch_labels5)))\n",
    "        \n",
    "      avg_acc_train = (accuracy(pred_train0, batch_labels0) + accuracy(pred_train1, batch_labels1)\n",
    "        + accuracy(pred_train2, batch_labels2) + accuracy(pred_train3, batch_labels3)\n",
    "        + accuracy(pred_train4, batch_labels4) + accuracy(pred_train5, batch_labels5))/6\n",
    "      print('Training avg accuracy: %.1f%%' % avg_acc_train)\n",
    "        \n",
    "      print(\"Validation accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_valid0, valid_label0[:batch_size]),accuracy(pred_valid1, valid_label1[:batch_size])  \\\n",
    "        ,accuracy(pred_valid2, valid_label2[:batch_size]), accuracy(pred_valid3, valid_label3[:batch_size])  \\\n",
    "        ,accuracy(pred_valid4, valid_label4[:batch_size]), accuracy(pred_valid5, valid_label5[:batch_size])))\n",
    "    \n",
    "      avg_acc_valid = (accuracy(pred_valid0, valid_label0[:batch_size]) + accuracy(pred_valid1, valid_label1[:batch_size])\n",
    "        + accuracy(pred_valid2, valid_label2[:batch_size]) + accuracy(pred_valid3, valid_label3[:batch_size])\n",
    "        + accuracy(pred_valid4, valid_label4[:batch_size]) + accuracy(pred_valid5, valid_label5[:batch_size]))/6\n",
    "      print('Validation avg accuracy: %.1f%%' % avg_acc_valid)\n",
    "    \n",
    "    if avg_acc_valid > max_acc:\n",
    "        max_acc = avg_acc_valid\n",
    "        # Save the variables to disk.\n",
    "        save_path = saver.save(session, \"C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\")\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # print(\"w1 mean: {} std: {}\".format(np.mean(w), np.std(w)))\n",
    "     # print(\"wy1 mean: {} std: {}\".format(np.mean(w1), np.std(w1)))\n",
    "      #print(\"label: \", batch_labels1)\n",
    "    #  print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), L_valid))\n",
    "  #print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Restore model to predict on test data\n",
    "## Create graph for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size=9\n",
    "#graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    #with tf.device('/gpu:0'):\n",
    "    \n",
    "  def weight_variable(w_id, shape, stdev_num):\n",
    "    #return (tf.Variable(tf.truncated_normal(shape,stddev=np.sqrt(2.0/(stdev_num)))))\n",
    "    return (tf.get_variable(w_id,  initializer = tf.truncated_normal(shape,stddev=np.sqrt(2.0/(stdev_num)))))\n",
    "\n",
    "  def bias_variable(b_id, shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    #return tf.Variable(initial)\n",
    "    return tf.get_variable(b_id, initializer = initial)\n",
    "    \n",
    "  tf_test_dataset = tf.placeholder(tf.float32, shape=[test_batch_size, image_size, image_size, 1]) \n",
    "\n",
    "  def conv_layers(layer_num, data, weights, biases, input_size,filter_size, num_filters, valid=False, use_pooling=True): \n",
    "   # ########\n",
    "   # # Conv with leaky relu and 2x2 max pooling\n",
    "   # ########\n",
    "\n",
    "    if not valid:\n",
    "    # create filter-weights and bias during training\n",
    "        shape = [filter_size, filter_size, input_size, num_filters]\n",
    "        stdev_n = (filter_size*filter_size*input_size)\n",
    "        weights.append(weight_variable(\"cvw0_\"+layer_num, shape, stdev_n))\n",
    "        biases.append(bias_variable(\"cvb0_\"+layer_num, [num_filters]))\n",
    "\n",
    "    hidden=[]\n",
    "    y0 =  tf.nn.conv2d(input=data,filter=weights[0],strides=[1, 1, 1, 1],padding='SAME')\n",
    "    hidden.append(tf.maximum((y0 + biases[0]), 0.01*(y0+biases[0])))\n",
    "    \n",
    "    for L in range(1,num_conv_layers+1):   \n",
    "        if not valid:\n",
    "            shape = [filter_size, filter_size, num_filters, num_filters]\n",
    "            stdev_n = filter_size*filter_size*num_filters\n",
    "                \n",
    "            weights.append(weight_variable(\"cvw\"+str(L)+\"_\"+layer_num, shape, stdev_n))\n",
    "            biases.append(bias_variable(\"cvb\"+str(L)+\"_\"+layer_num, [num_filters]))   \n",
    "\n",
    "        y = tf.nn.conv2d(input=hidden[L-1],filter=weights[L],strides=[1, 1, 1, 1],padding='SAME')\n",
    "        hidden.append(tf.maximum((y + biases[L]), 0.01*(y+biases[L])))\n",
    "\n",
    "    layer = tf.nn.max_pool(value=hidden[num_conv_layers], ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    return layer, weights, biases\n",
    "    \n",
    "  def fc_layers(layer_num, weights, biases, out_weights, out_biases, data, label_count, valid = False):\n",
    "   #  #####\n",
    "   #  # FC Layers - with leaky relu and dropout\n",
    "   #  #####\n",
    "\n",
    "    out_size = data.get_shape().as_list()[1]\n",
    "    if not valid:\n",
    "        #create weights and biases during training\n",
    "        weights.append(weight_variable(\"fcw0_\"+layer_num, [out_size, fc_size], fc_size*fc_size)) # w = 1024 depth * 1024 FC hidden node layer\n",
    "        biases.append(bias_variable(\"fcb0_\"+layer_num, [fc_size])) #  # b = 1024 FC hidden node layers1024\n",
    "\n",
    "    hidden=[]\n",
    "    y0 = (tf.matmul(data, weights[0]) + biases[0])\n",
    "    hidden.append(tf.nn.dropout(tf.maximum(y0, 0.01*y0), drop_rate1))\n",
    "    \n",
    "    for L in range(1,num_fc_layers+1):   \n",
    "        if not valid:\n",
    "            weights.append(weight_variable(\"fcw\"+str(L)+\"_\"+layer_num,[fc_size, fc_size], fc_size*fc_size))\n",
    "            biases.append(bias_variable(\"fcb\"+str(L)+\"_\"+layer_num,[fc_size]))   \n",
    "        y = ((tf.matmul(hidden[L-1], weights[L]) + biases[L])) \n",
    "        hidden.append(tf.nn.dropout(tf.maximum(y, 0.01*y), drop_rate2))\n",
    "        \n",
    "      #Definitive output  after relu layer's:  \n",
    "    if not valid:\n",
    "        out_weights = weight_variable(\"rlw_\"+layer_num,[fc_size, label_count], fc_size*label_count)\n",
    "        out_biases = bias_variable(\"rlb_\"+layer_num,[label_count])      \n",
    "    logits = tf.matmul(hidden[num_fc_layers], out_weights) + out_biases\n",
    "        \n",
    "    return logits, weights, biases, out_weights, out_biases\n",
    "    \n",
    "  \n",
    "  # Test data computation.\n",
    "  convpool1v, _, _ = conv_layers(\"1\", tf_test_dataset, wc1, bc1, num_channels, filter_size1, num_filters1, True)\n",
    "  convpool2v, _, _ = conv_layers(\"2\", convpool1v, wc2, bc2, num_filters1, filter_size2, num_filters2, True)\n",
    "  convpool3v, _, _ = conv_layers(\"3\", convpool2v, wc3, bc3, num_filters2, filter_size3, num_filters3, True)\n",
    "  shapev = convpool3v.get_shape().as_list()\n",
    "  conv_layers_reshape_valid = tf.reshape(convpool3v, [shapev[0], shapev[1] * shapev[2] * shapev[3]]) #[256, 4, 4, 64]\n",
    "\n",
    "  logits0_test, _, _, _, _ = fc_layers(\"1\", w0, b0, out_w0, out_b0, conv_layers_reshape_valid, num_digits, True) \n",
    "  logits1_test, _, _, _, _ = fc_layers(\"2\", w1, b1, out_w1, out_b1, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits2_test, _, _, _, _ = fc_layers(\"3\", w2, b2, out_w2, out_b2, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits3_test, _, _, _, _ = fc_layers(\"4\", w3, b3, out_w3, out_b3, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits4_test, _, _, _, _ = fc_layers(\"5\", w4, b4, out_w4, out_b4, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits5_test, _, _, _, _ = fc_layers(\"6\", w5, b5, out_w5, out_b5, conv_layers_reshape_valid, num_labels, True) \n",
    "\n",
    " # Predictions test data.\n",
    "  test_prediction0 = tf.nn.softmax(logits0_test)\n",
    "  test_prediction1 = tf.nn.softmax(logits1_test)\n",
    "  test_prediction2 = tf.nn.softmax(logits2_test)\n",
    "  test_prediction3 = tf.nn.softmax(logits3_test)\n",
    "  test_prediction4 = tf.nn.softmax(logits4_test)\n",
    "  test_prediction5 = tf.nn.softmax(logits5_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 32, 32, 1)\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\n",
      "Model restored.\n",
      "prediction 155\n",
      "prediction 7\n",
      "prediction 50\n",
      "prediction 169\n",
      "prediction 29\n",
      "prediction 646\n",
      "prediction 121\n",
      "prediction 41\n",
      "prediction 151\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "test_data = valid_dataset[0:test_batch_size]\n",
    "print(test_data.shape)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  saver.restore(session, \"C:/Users/rphila/Documents/Online Courses/DeepLearning/model/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "\n",
    "  feed_dict = {tf_test_dataset : test_data}\n",
    "                 \n",
    "  pred0, pred1, pred2, pred3, pred4, pred5  \\\n",
    "        = session.run([test_prediction0, test_prediction1, test_prediction2, test_prediction3\n",
    "                       , test_prediction4, test_prediction5] , feed_dict=feed_dict)\n",
    "\n",
    "  predict_lbl = []\n",
    "  for k in range(0, test_batch_size):\n",
    "    pred = []\n",
    "    pred.append(pred1[k].tolist().index(max(pred1[k])))\n",
    "    pred.append(pred2[k].tolist().index(max(pred2[k])))\n",
    "    pred.append(pred3[k].tolist().index(max(pred3[k])))\n",
    "    pred.append(pred4[k].tolist().index(max(pred4[k])))\n",
    "    pred.append(pred5[k].tolist().index(max(pred5[k])))\n",
    "  \n",
    "    predict_tmp = ''\n",
    "    for i in range(0, pred0[k].tolist().index(max(pred0[k]))):\n",
    "      predict_tmp = predict_tmp + str(pred[i])\n",
    "    print(\"prediction \" + predict_tmp)\n",
    "    predict_lbl.append(predict_tmp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGTocDocknwwdDodDkvT/A3wV3JjZlhGuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133afa552b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(images=test_data, cls_true=predict_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
