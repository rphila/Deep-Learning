{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7: Build a Live Camera App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rita Philavanh\n",
    "\n",
    "20170905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Street View House Number (SVHN) training/test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download train.tar.gz and test.tar.gz files from http://ufldl.stanford.edu/housenumbers/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset from compressed tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train already present - Skipping extraction of train.tar.gz.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9474a4f6589f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mtrain_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mtest_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9474a4f6589f>\u001b[0m in \u001b[0;36mmaybe_extract\u001b[1;34m(filename, force)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m   data_folders = [\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     if os.path.isdir(os.path.join(root, d))]\n\u001b[0;32m     24\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folders\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9474a4f6589f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m   data_folders = [\n\u001b[0;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     if os.path.isdir(os.path.join(root, d))]\n\u001b[0m\u001b[0;32m     24\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folders\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     raise Exception(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 0\n",
    "np.random.seed(133)\n",
    "data_root = '.'\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract('train.tar.gz')\n",
    "test_folders = maybe_extract('test.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels from .mat file \n",
    "\n",
    "(used digiStruct.py code found here: https://github.com/prijip/Py-Gsvhn-DigitStruct-Reader/blob/360a03909a22a28e2e814e83d6915ee5f915e5da/digitStruct.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 262.64s\n"
     ]
    }
   ],
   "source": [
    "#import h5py\n",
    "#import numpy as np\n",
    "#digitStruct = h5py.File('train/digitStruct.mat')\n",
    "#digitStruct.keys()\n",
    "#mat = {}\n",
    "#for k, v in digitStruct.items():\n",
    "#    print(k,v)\n",
    "#    mat[k] = np.array(v)\n",
    "\n",
    "#print(mat)\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Bounding Box\n",
    "#\n",
    "class BBox:\n",
    "    def __init__(self):\n",
    "        self.label = \"\"     # Digit\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "\n",
    "class DigitStruct:\n",
    "    def __init__(self):\n",
    "        self.name = None    # Image file name\n",
    "        self.bboxList = None # List of BBox structs\n",
    "\n",
    "# Function for debugging\n",
    "def printHDFObj(theObj, theObjName):\n",
    "    isFile = isinstance(theObj, h5py.File)\n",
    "    isGroup = isinstance(theObj, h5py.Group)\n",
    "    isDataSet = isinstance(theObj, h5py.Dataset)\n",
    "    isReference = isinstance(theObj, h5py.Reference)\n",
    "    print(\"{}\".format(theObjName))\n",
    "    print(\"    type(): {}\".format(type(theObj)))\n",
    "    if isFile or isGroup or isDataSet:\n",
    "        # if theObj.name != None:\n",
    "        #    print \"    name: {}\".format(theObj.name)\n",
    "        print(\"    id: {}\".format(theObj.id))\n",
    "    if isFile or isGroup:\n",
    "        print(\"    keys: {}\".format(theObj.keys()))\n",
    "    if not isReference:\n",
    "        print(\"    Len: {}\".format(len(theObj)))\n",
    "\n",
    "    if not (isFile or isGroup or isDataSet or isReference):\n",
    "        print(theObj)\n",
    "\n",
    "def readDigitStructGroup(dsFile):\n",
    "    dsGroup = dsFile[\"digitStruct\"]\n",
    "    return dsGroup\n",
    "\n",
    "#\n",
    "# Reads a string from the file using its reference\n",
    "#\n",
    "def readString(strRef, dsFile):\n",
    "    strObj = dsFile[strRef]\n",
    "    str = ''.join(chr(i) for i in strObj)\n",
    "    return str\n",
    "\n",
    "#\n",
    "# Reads an integer value from the file\n",
    "#\n",
    "def readInt(intArray, dsFile):\n",
    "    intRef = intArray[0]\n",
    "    isReference = isinstance(intRef, h5py.Reference)\n",
    "    intVal = 0\n",
    "    if isReference:\n",
    "        intObj = dsFile[intRef]\n",
    "        intVal = int(intObj[0])\n",
    "    else: # Assuming value type\n",
    "        intVal = int(intRef)\n",
    "    return intVal\n",
    "\n",
    "def yieldNextInt(intDataset, dsFile):\n",
    "    for intData in intDataset:\n",
    "        intVal = readInt(intData, dsFile)\n",
    "        yield intVal \n",
    "\n",
    "def yieldNextBBox(bboxDataset, dsFile):\n",
    "    for bboxArray in bboxDataset:\n",
    "        bboxGroupRef = bboxArray[0]\n",
    "        bboxGroup = dsFile[bboxGroupRef]\n",
    "        labelDataset = bboxGroup[\"label\"]\n",
    "        leftDataset = bboxGroup[\"left\"]\n",
    "        topDataset = bboxGroup[\"top\"]\n",
    "        widthDataset = bboxGroup[\"width\"]\n",
    "        heightDataset = bboxGroup[\"height\"]\n",
    "\n",
    "        left = yieldNextInt(leftDataset, dsFile)\n",
    "        top = yieldNextInt(topDataset, dsFile)\n",
    "        width = yieldNextInt(widthDataset, dsFile)\n",
    "        height = yieldNextInt(heightDataset, dsFile)\n",
    "\n",
    "        bboxList = []\n",
    "\n",
    "        for label in yieldNextInt(labelDataset, dsFile):\n",
    "            bbox = BBox()\n",
    "            bbox.label = label\n",
    "            bbox.left = next(left)\n",
    "            bbox.top = next(top)\n",
    "            bbox.width = next(width)\n",
    "            bbox.height = next(height)\n",
    "            bboxList.append(bbox)\n",
    "\n",
    "        yield bboxList\n",
    "\n",
    "def yieldNextFileName(nameDataset, dsFile):\n",
    "    for nameArray in nameDataset:\n",
    "        nameRef = nameArray[0]\n",
    "        name = readString(nameRef, dsFile)\n",
    "        yield name\n",
    "\n",
    "# dsFile = h5py.File('train/digitStruct.mat', 'r')\n",
    "def yieldNextDigitStruct(dsFileName):\n",
    "    dsFile = h5py.File(dsFileName, 'r')\n",
    "    dsGroup = readDigitStructGroup(dsFile)\n",
    "    nameDataset = dsGroup[\"name\"]\n",
    "    bboxDataset = dsGroup[\"bbox\"]\n",
    "\n",
    "    bboxListIter = yieldNextBBox(bboxDataset, dsFile)\n",
    "    for name in yieldNextFileName(nameDataset, dsFile):\n",
    "        bboxList = next(bboxListIter)\n",
    "        obj = DigitStruct()\n",
    "        obj.name = name\n",
    "        obj.bboxList = bboxList\n",
    "        yield obj\n",
    "\n",
    "L = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "y4 = []\n",
    "y5 = []\n",
    "def testMain():\n",
    "    i = 0\n",
    "    dsFileName = 'train/digitStruct.mat'\n",
    "    testCounter = 0\n",
    "\n",
    "    for dsObj in yieldNextDigitStruct(dsFileName):\n",
    "        # testCounter += 1\n",
    "       # print(dsObj.name)\n",
    "      #  print(len(dsObj.bboxList))\n",
    "        L.append(len(dsObj.bboxList))\n",
    "        \n",
    "        cnty = 0\n",
    "        for bbox in dsObj.bboxList:\n",
    "         #   print(\"    {}:{},{},{},{}\".format(\n",
    "         #       bbox.label, bbox.left, bbox.top, bbox.width, bbox.height))\n",
    "            \n",
    "            if cnty == 0: y1.append(bbox.label)\n",
    "            elif cnty == 1: y2.append(bbox.label) \n",
    "            elif cnty == 2: y3.append(bbox.label)\n",
    "            elif cnty == 3: y4.append(bbox.label)\n",
    "            elif cnty == 4: y5.append(bbox.label)\n",
    "            \n",
    "            cnty += 1\n",
    "            \n",
    "        if cnty < 5:\n",
    "            if len(dsObj.bboxList) < 1: y1.append(10)\n",
    "            if len(dsObj.bboxList) < 2: y2.append(10) \n",
    "            if len(dsObj.bboxList) < 3: y3.append(10)\n",
    "            if len(dsObj.bboxList) < 4: y4.append(10)\n",
    "            if len(dsObj.bboxList) < 5: y5.append(10)\n",
    "        if testCounter >= 5:\n",
    "            break\n",
    "        i +=1\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    t1 = time.time()\n",
    "    testMain()\n",
    "    t2 = time.time()\n",
    "    print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33402\n",
      "[2, 2, 2, 2, 2, 2, 2, 3, 3, 2]\n",
      "[1, 2, 2, 9, 3, 3, 2, 7, 1, 1]\n",
      "[9, 3, 5, 3, 1, 3, 8, 4, 2, 6]\n",
      "[10, 10, 10, 10, 10, 10, 10, 4, 8, 10]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "print(len(L))\n",
    "print(L[:10]) # length of digits\n",
    "print(y1[:10]) # 1st digit\n",
    "print(y2[:10]) # 2nd digit\n",
    "print(y3[:10]) # ...etc (If no digit, then 'None')\n",
    "print(y4[:10])\n",
    "print(y5[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset to 32x32 pixels grayscale matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c96f13a69250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./train/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic_num\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mresized_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpic_num\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "X = []\n",
    "pic_num = 1\n",
    "#print(len(os.listdir('./train')))\n",
    "for i in range(len(os.listdir('./train'))): \n",
    "    img = cv2.imread(\"./train/\"+str(pic_num) +\".png\",cv2.IMREAD_GRAYSCALE)\n",
    "    resized_image = cv2.resize(img, (32, 32))\n",
    "    X.append(resized_image)\n",
    "    pic_num +=1\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33402 10000 23402\n",
      "33402 10000 23402\n"
     ]
    }
   ],
   "source": [
    "X_valid = X[:10000]\n",
    "X_train = X[10000:]\n",
    "\n",
    "print(len(X), len(X_valid), len(X_train))\n",
    "\n",
    "L_valid = L[:10000] \n",
    "L_train = L[10000:] \n",
    "y1_valid = y1[:10000]\n",
    "y2_valid = y2[:10000]\n",
    "y3_valid = y3[:10000]\n",
    "y4_valid = y4[:10000]\n",
    "y5_valid = y5[:10000]\n",
    "\n",
    "y1_train = y1[10000:]\n",
    "y2_train = y2[10000:]\n",
    "y3_train = y3[10000:]\n",
    "y4_train = y4[10000:]\n",
    "y5_train = y5[10000:]\n",
    "\n",
    "print(len(L), len(L_valid), len(L_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 2, 4, 2, 2, 2, 1, 2]\n",
      "[4, 2, 5, 8, 1, 4, 1, 9, 6, 1]\n",
      "[1, 1, 9, 8, 10, 2, 6, 2, 10, 3]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[10 10 10 10 10 10 10 10 10 10]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[2, 2, 2, 2, 2, 2, 2, 3, 3, 2]\n",
      "[1, 2, 2, 9, 3, 3, 2, 7, 1, 1]\n",
      "[9, 3, 5, 3, 1, 3, 8, 4, 2, 6]\n",
      "[10, 10, 10, 10, 10, 10, 10, 4, 8, 10]\n",
      "[10 10 10 10 10 10 10  4  8 10]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Training set (23402, 32, 32, 1) (23402, 6) (23402, 11)\n",
      "Validation set (10000, 32, 32, 1) (10000, 6) (10000, 11)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32 # 32 x 32 pixel\n",
    "num_channels = 1 # grayscale\n",
    "num_labels = 11 # 0-9 + 10 (for missing value)\n",
    "num_digits = 6 #max 5 digit for housenumber\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, label0, label1, label2, label3, label4, label5):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  print((label0[:10]))\n",
    "  print((label1[:10]))\n",
    "  print((label2[:10]))\n",
    "  print((label3[:10]))\n",
    "  print(np.asarray(label3[:10]))\n",
    "  label0 = (np.arange(num_digits) == np.asarray(label0)[:,None]).astype(np.float32)\n",
    "  label1 = (np.arange(num_labels) == np.asarray(label1)[:,None]).astype(np.float32)\n",
    "  label2 = (np.arange(num_labels) == np.asarray(label2)[:,None]).astype(np.float32)\n",
    "  label3 = (np.arange(num_labels) == np.asarray(label3)[:,None]).astype(np.float32)\n",
    "  label4 = (np.arange(num_labels) == np.asarray(label4)[:,None]).astype(np.float32)\n",
    "  label5 = (np.arange(num_labels) == np.asarray(label5)[:,None]).astype(np.float32)\n",
    "\n",
    "  print(np.asarray(label3[:10]))\n",
    "  return dataset, label0, label1, label2, label3, label4, label5\n",
    "train_dataset, train_label0, train_label1, train_label2, train_label3, train_label4, train_label5 = reformat(np.asarray(X_train), L_train, y1_train, y2_train, y3_train, y4_train, y5_train)\n",
    "valid_dataset, valid_label0, valid_label1, valid_label2, valid_label3, valid_label4, valid_label5 = reformat(np.asarray(X_valid), L_valid, y1_valid, y2_valid, y3_valid, y4_valid, y5_valid)\n",
    "#test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_label0.shape, train_label1.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_label0.shape, valid_label1.shape)\n",
    "#print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36        # There are 36 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size3 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters3 = 64        # There are 64 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 1024         # Number of neurons in fully-connected hidden layer\n",
    "\n",
    "drop_rate = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare variables to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "#with tf.device('/gpu:0'):\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels0 = tf.placeholder(tf.float32, shape=(batch_size, num_digits))\n",
    "  tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels5 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset =  tf.constant(valid_dataset[:batch_size]) #tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels)) #\n",
    " # tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # Variables.\n",
    "  #w1 = tf.get_variable(\"w1\", shape=[filter_size1, filter_size1, num_channels, num_filters1], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "  #w1 = tf.Variable(tf.truncated_normal([filter_size1, filter_size1, num_channels, num_filters1], stddev=0.1)) # 5, 5, 1, 16\n",
    "  w1cv1 = tf.Variable(tf.truncated_normal([filter_size1,filter_size1, num_channels, num_filters1], stddev=np.sqrt(1/(filter_size1*filter_size1*num_channels)))) # 5, 5, 1, 16\n",
    "  b1cv1 = tf.Variable(tf.zeros([num_filters1])) #16\n",
    "\n",
    "  w1cv2 = tf.Variable(tf.truncated_normal([filter_size1,filter_size1, num_filters1, num_filters1], stddev=np.sqrt(1/(filter_size1*filter_size1*num_filters1)))) # 5, 5, 16, 16\n",
    "  b1cv2 = tf.Variable(tf.constant(0.1, shape=[num_filters1])) #16\n",
    "    \n",
    "  w1cv3 = tf.Variable(tf.truncated_normal([filter_size1,filter_size1, num_filters1, num_filters1], stddev=np.sqrt(1/(filter_size1*filter_size1*num_filters1)))) # 5, 5, 16, 16\n",
    "  b1cv3 = tf.Variable(tf.constant(0.1, shape=[num_filters1])) #16\n",
    "\n",
    "#pool 16\n",
    "\n",
    "  w2cv1 = tf.Variable(tf.truncated_normal([filter_size2,filter_size2, num_filters1, num_filters2], stddev=np.sqrt(1/(filter_size1*filter_size2*num_filters1)))) # 5, 5, 16, 36\n",
    "  b2cv1 = tf.Variable(tf.constant(0.1, shape=[num_filters2])) #36\n",
    "\n",
    "  w2cv2 = tf.Variable(tf.truncated_normal([filter_size2,filter_size2, num_filters2, num_filters2], stddev=np.sqrt(1/(filter_size1*filter_size2*num_filters2)))) # 5, 5, 36, 36\n",
    "  b2cv2 = tf.Variable(tf.constant(0.1, shape=[num_filters2])) #36\n",
    "\n",
    "  w2cv3 = tf.Variable(tf.truncated_normal([filter_size2,filter_size2, num_filters2, num_filters2], stddev=np.sqrt(1/(filter_size1*filter_size2*num_filters2)))) # 5, 5, 36, 36\n",
    "  b2cv3 = tf.Variable(tf.constant(0.1, shape=[num_filters2])) #36\n",
    "  \n",
    "#pool 16\n",
    "\n",
    "  w3cv1 = tf.Variable(tf.truncated_normal([filter_size3,filter_size3, num_filters2, num_filters3], stddev=np.sqrt(1/(filter_size3*filter_size3*num_filters2)))) # 5, 5, 16, 64\n",
    "  b3cv1 = tf.Variable(tf.constant(0.1, shape=[num_filters3])) #64\n",
    "\n",
    "  w3cv2 = tf.Variable(tf.truncated_normal([filter_size3,filter_size3, num_filters3, num_filters3], stddev=np.sqrt(1/(filter_size3*filter_size3*num_filters3)))) # 5, 5, 64, 64\n",
    "  b3cv2 = tf.Variable(tf.constant(0.1, shape=[num_filters3])) #64\n",
    "  \n",
    "  w3cv3 = tf.Variable(tf.truncated_normal([filter_size3,filter_size3, num_filters3, num_filters3], stddev=np.sqrt(1/(filter_size3*filter_size3*num_filters3)))) # 5, 5, 64, 64\n",
    "  b3cv3 = tf.Variable(tf.constant(0.1, shape=[num_filters3])) #64\n",
    "    \n",
    " #pool 8\n",
    "\n",
    "  #wfcin = image_size // 2*2*2 * image_size // 2*2*2 *num_filters3 #(3 max pool @ stride 2)\n",
    "  wfc = tf.Variable(tf.truncated_normal([fc_size, batch_size], stddev=np.sqrt(2/(fc_size + batch_size)))) #4*4*64=1024,256 \n",
    "  bfc = tf.Variable(tf.constant(0.1, shape=[batch_size])) #256\n",
    "    \n",
    "  w0fc = tf.Variable(tf.truncated_normal([batch_size, num_digits], stddev=np.sqrt(2/(batch_size + num_digits)))) #256, 6\n",
    "  b0fc = tf.Variable(tf.constant(0.1, shape=[num_digits])) #6\n",
    "    \n",
    "  w1fc = tf.Variable(tf.truncated_normal([batch_size, num_labels], stddev=np.sqrt(2/(batch_size + num_labels)))) #256, 11\n",
    "  b1fc = tf.Variable(tf.constant(0.1, shape=[num_labels])) #11\n",
    "  w2fc = tf.Variable(tf.truncated_normal([batch_size, num_labels], stddev=np.sqrt(2/(batch_size + num_labels)))) #256, 11\n",
    "  b2fc = tf.Variable(tf.constant(0.1, shape=[num_labels])) #11\n",
    "  w3fc = tf.Variable(tf.truncated_normal([batch_size, num_labels], stddev=np.sqrt(2/(batch_size + num_labels)))) #256, 11\n",
    "  b3fc = tf.Variable(tf.constant(0.1, shape=[num_labels])) #11\n",
    "  w4fc = tf.Variable(tf.truncated_normal([batch_size, num_labels], stddev=np.sqrt(2/(batch_size + num_labels)))) #256, 11\n",
    "  b4fc = tf.Variable(tf.constant(0.1, shape=[num_labels])) #11\n",
    "  w5fc = tf.Variable(tf.truncated_normal([batch_size, num_labels], stddev=np.sqrt(2/(batch_size + num_labels)))) #256, 11\n",
    "  b5fc = tf.Variable(tf.constant(0.1, shape=[num_labels])) #11\n",
    "\n",
    "#init = tf.contrib.layers.xaviar_initializer()\n",
    "#h = tf.layers.dense(inputs=x, units=image_size, activation=tf.nn.relu, kernel_initializer=init)\n",
    "#y_pred = tf.layers.dense(inputs=h, units = 1000, kernel_initializer=init)\n",
    "\n",
    "# Model.\n",
    "  def model(data):\n",
    "    ######\n",
    "    # CNN\n",
    "    ######\n",
    "    # x = 32x32 pixel * 1 channel* 256 batch samples\n",
    "    # w = 5x5 filter * 1 channel * 16 filters/depth\n",
    "    # b1= 16 depth\n",
    "    # conv/hidden = 32x32 pixel * 16 depth * 256 batch samples  (32-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv1a = tf.nn.conv2d(data, w1cv1, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1a =tf.maximum((conv1a + b1cv1), 0.01 * (conv1a + b1cv1)) # tf.nn.relu(conv1 + b1) #\n",
    "    \n",
    "    # hidden = 32x32 pixel * 16 channel* 256 batch samples\n",
    "    # w = 5x5 filter * 16 channel * 16 filters/depth\n",
    "    # b = 16 depth\n",
    "    # conv/hidden = 32x32 pixel * 16 depth * 256 batch samples  (32-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv2a = tf.nn.conv2d(hidden1a, w1cv2, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden2a =tf.maximum((conv2a + b1cv2), 0.01 * (conv2a + b1cv2)) #tf.nn.relu(conv2 + b2)# \n",
    "    \n",
    "    conv3a = tf.nn.conv2d(hidden2a, w1cv3, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3a =tf.maximum((conv3a + b1cv3), 0.01 * (conv3a + b1cv3)) #tf.nn.relu(conv3 + b3)# \n",
    "    \n",
    "    # pool = 16x16 pixel * 16 depth * 256 batch samples\n",
    "    pool1a = tf.nn.max_pool(hidden3a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    # pool = 8x8 pixel * 36 channel* 256 batch samples\n",
    "    # w = 5x5 filter * 36 channel * 36 filters/depth\n",
    "    # b = 36 depth\n",
    "    # conv/hidden = 8x8 pixel * 36 depth * 256 batch samples  (8-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv1b = tf.nn.conv2d(pool1a, w2cv1, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1b = tf.maximum((conv1b + b2cv1), 0.01 * (conv1b + b2cv1)) #tf.nn.relu(conv1b + b1b)#\n",
    "    \n",
    "    # hidden = 8x8 pixel * 36 depth * 256 batch samples \n",
    "    # w = 5x5 filter * 36 channel * 36 filters/depth\n",
    "    # b = 64 depth\n",
    "    # conv/hidden = 8x8 pixel * 64 depth * 256 batch samples  (8-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv2b = tf.nn.conv2d(hidden1b, w2cv2, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden2b =tf.maximum((conv2b + b2cv2), 0.01 * (conv2b + b2cv2)) #tf.nn.relu(conv2b + b2b)# \n",
    "    #print(w.get_shape())\n",
    "    #print(b.get_shape())\n",
    "    #print(hidden.get_shape())\n",
    "    \n",
    "    conv3b = tf.nn.conv2d(hidden2b, w2cv3, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3b =tf.maximum((conv3b + b2cv3), 0.01 * (conv3b + b2cv3)) #tf.nn.relu(conv3 + b3)# \n",
    "    \n",
    "    # pool = 4x4 pixel * 36 depth * 256 batch samples\n",
    "    pool1b = tf.nn.max_pool(hidden3b, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #print(pool.get_shape())\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    # pool = 4x4 pixel * 36 channel* 256 batch samples\n",
    "    # w = 5x5 filter * 36 channel * 64 filters/depth\n",
    "    # b = 64 depth\n",
    "    # conv/hidden = 4x4 pixel * 64 depth * 256 batch samples  (4-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv1c = tf.nn.conv2d(pool1b, w3cv1, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1c = tf.maximum((conv1c + b3cv1), 0.01 * (conv1c + b3cv1)) #tf.nn.relu(conv1b + b1b)#\n",
    "    \n",
    "    # hidden = 4x4 pixel * 64 depth * 256 batch samples \n",
    "    # w = 5x5 filter * 64 channel * 64 filters/depth\n",
    "    # b = 64 depth\n",
    "    # conv/hidden = 4x4 pixel * 64 depth * 256 batch samples  (4-5+(2*2)[padding to be same output])/1[stride]+1\n",
    "    conv2c = tf.nn.conv2d(hidden1c, w3cv2, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden2c =tf.maximum((conv2c + b3cv2), 0.01 * (conv2c + b3cv2)) #tf.nn.relu(conv2b + b2b)# \n",
    "    #print(w.get_shape())\n",
    "    #print(b.get_shape())\n",
    "    #print(hidden.get_shape())\n",
    "    \n",
    "    conv3c = tf.nn.conv2d(hidden2c, w3cv3, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden3c =tf.maximum((conv3c + b3cv3), 0.01 * (conv3c + b3cv3)) #tf.nn.relu(conv3 + b3)# \n",
    "    \n",
    "    # pool = 8x8 pixel * 64 depth * 256 batch samples\n",
    "    pool1c = tf.nn.max_pool(hidden3c, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #print(pool.get_shape())\n",
    "        \n",
    "    #####\n",
    "    # FC Layers\n",
    "    #####\n",
    "    shape = pool1c.get_shape().as_list()\n",
    "   # print(shape)\n",
    "    reshape = tf.reshape(pool1c, [shape[0], shape[1] * shape[2] * shape[3]]) #[256, 4, 4, 64]\n",
    "   # print(reshape) #256 * 4*4*64=1024\n",
    "   # print(wfc.get_shape())\n",
    "   # print(bfc.get_shape())\n",
    "    # w = 1024 depth * 1024 FC hidden node layer\n",
    "    # b = 1024 FC hidden node layers\n",
    "    y = tf.maximum((tf.matmul(reshape, wfc) + bfc), 0.01 * tf.matmul(reshape, wfc) + bfc) #tf.nn.relu(tf.matmul(reshape, w3) + b3)\n",
    "    y = tf.nn.dropout(y, drop_rate)  # Dropout\n",
    "    \n",
    "\n",
    "    return y #tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "  # Training computation.\n",
    "  # w4 = 1024 batch sample * 6 classifier\n",
    "  # b4 = 6 classifier\n",
    "  # 1024 batch sample x 6 classifier\n",
    "  logits =  tf.matmul(model(tf_train_dataset), w0fc) + b0fc\n",
    "    \n",
    "  # w4b = 1024 batch sample * 11 classifier\n",
    "  # b4b = 11 classifier\n",
    "  # 1024 batch sample x 11 classifier\n",
    "  logits1 = tf.matmul(model(tf_train_dataset), w1fc) + b1fc\n",
    "  logits2 = tf.matmul(model(tf_train_dataset), w2fc) + b2fc\n",
    "  logits3 = tf.matmul(model(tf_train_dataset), w3fc) + b3fc\n",
    "  logits4 = tf.matmul(model(tf_train_dataset), w4fc) + b4fc\n",
    "  logits5 = tf.matmul(model(tf_train_dataset), w5fc) + b5fc\n",
    "    \n",
    "  loss0 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels0, logits=logits)\n",
    "  loss1 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels1, logits=logits1)\n",
    "  loss2 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels2, logits=logits2)\n",
    "  loss3 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels3, logits=logits3)\n",
    "  loss4 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels4, logits=logits4)\n",
    "  loss5 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels5, logits=logits5)\n",
    " # loss =  tf.reduce_mean(loss0 + loss1 + loss2 + loss3 + loss4 + loss5)\n",
    "\n",
    "  loss= tf.reduce_mean(loss0) + tf.reduce_mean(loss1) + tf.reduce_mean(loss2) + tf.reduce_mean(loss3) + tf.reduce_mean(loss4) + tf.reduce_mean(loss5)\n",
    "    \n",
    " # Optimizer.\n",
    " # optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  global_step = tf.Variable(0) #, trainable=False)  # count the number of steps taken.\n",
    " # learning_rate = tf.train.exponential_decay(0.1, global_step, 100000, 0.96, staircase=True)\n",
    " # learning_rate = tf.train.exponential_decay(0.1, global_step, 200, 0.7) #, staircase=True)\n",
    " # optimizer = tf.train.GradientDescentOptimizer(1e-6).minimize(loss) #, global_step=global_step)\n",
    "  optimizer =tf.train.AdamOptimizer(0.001).minimize(loss) #, global_step=global_step) \n",
    "\n",
    "\n",
    "  # Validation computation.\n",
    "  logits_valid =  tf.matmul(model(tf_valid_dataset), w0fc) + b0fc\n",
    "    \n",
    "  # w4b = 1024 batch sample * 11 classifier\n",
    "  # b4b = 11 classifier\n",
    "  # 256 batch sample x 11 classifier\n",
    "  logits1_valid = tf.matmul(model(tf_valid_dataset), w1fc) + b1fc\n",
    "  logits2_valid = tf.matmul(model(tf_valid_dataset), w2fc) + b2fc\n",
    "  logits3_valid = tf.matmul(model(tf_valid_dataset), w3fc) + b3fc\n",
    "  logits4_valid = tf.matmul(model(tf_valid_dataset), w4fc) + b4fc\n",
    "  logits5_valid = tf.matmul(model(tf_valid_dataset), w5fc) + b5fc\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    " # digit 1-5 prediction\n",
    "  train_prediction1 = tf.nn.softmax(logits1)\n",
    "  valid_prediction1 = tf.nn.softmax(logits1_valid)\n",
    "  train_prediction2 = tf.nn.softmax(logits2)\n",
    "  valid_prediction2 = tf.nn.softmax(logits2_valid)\n",
    "  train_prediction3 = tf.nn.softmax(logits3)\n",
    "  valid_prediction3 = tf.nn.softmax(logits3_valid)\n",
    "  train_prediction4 = tf.nn.softmax(logits4)\n",
    "  valid_prediction4 = tf.nn.softmax(logits4_valid)\n",
    "  train_prediction5 = tf.nn.softmax(logits5)\n",
    "  valid_prediction5 = tf.nn.softmax(logits5_valid)\n",
    "  #Length of sequence prediction\n",
    "  train_prediction0 = tf.nn.softmax(logits)\n",
    "  valid_prediction0 = tf.nn.softmax(logits_valid)\n",
    "    \n",
    "  #test_prediction = tf.nn.softmax(model(tf_test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch training loss at step 0: 13.936771\n",
      "Training accuracy - digit count: 27.7%; digits 1-5: 27.3%, 8.6%, 3.9%, 44.9%, 0.0%\n",
      "Training avg accuracy: 18.9%\n",
      "Validation accuracy - digit count: 19.9%; digits 1-5: 25.4%, 8.2%, 7.4%, 2.0%, 0.0%\n",
      "Validation avg accuracy: 18.9%\n",
      "Minibatch training loss at step 50: 6.926579\n",
      "Training accuracy - digit count: 52.7%; digits 1-5: 24.6%, 23.8%, 75.4%, 94.9%, 100.0%\n",
      "Training avg accuracy: 61.8%\n",
      "Validation accuracy - digit count: 55.9%; digits 1-5: 30.9%, 23.8%, 75.8%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 61.8%\n",
      "Minibatch training loss at step 100: 6.548984\n",
      "Training accuracy - digit count: 55.9%; digits 1-5: 27.3%, 24.6%, 77.3%, 97.7%, 100.0%\n",
      "Training avg accuracy: 63.7%\n",
      "Validation accuracy - digit count: 47.7%; digits 1-5: 31.2%, 24.2%, 75.8%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 63.7%\n",
      "Minibatch training loss at step 150: 6.491438\n",
      "Training accuracy - digit count: 57.8%; digits 1-5: 23.8%, 26.6%, 70.7%, 96.9%, 100.0%\n",
      "Training avg accuracy: 63.2%\n",
      "Validation accuracy - digit count: 51.2%; digits 1-5: 27.7%, 23.8%, 75.8%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 63.2%\n",
      "Minibatch training loss at step 200: 6.340409\n",
      "Training accuracy - digit count: 64.5%; digits 1-5: 19.5%, 23.0%, 73.0%, 97.3%, 100.0%\n",
      "Training avg accuracy: 63.5%\n",
      "Validation accuracy - digit count: 51.6%; digits 1-5: 23.4%, 25.0%, 75.4%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 63.5%\n",
      "Minibatch training loss at step 250: 6.167418\n",
      "Training accuracy - digit count: 66.0%; digits 1-5: 14.8%, 24.6%, 78.9%, 95.3%, 100.0%\n",
      "Training avg accuracy: 65.0%\n",
      "Validation accuracy - digit count: 55.1%; digits 1-5: 28.1%, 23.4%, 75.8%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 65.0%\n",
      "Minibatch training loss at step 300: 6.179930\n",
      "Training accuracy - digit count: 64.8%; digits 1-5: 22.7%, 24.2%, 71.1%, 97.7%, 100.0%\n",
      "Training avg accuracy: 64.5%\n",
      "Validation accuracy - digit count: 58.6%; digits 1-5: 29.3%, 23.8%, 71.5%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 64.5%\n",
      "Minibatch training loss at step 350: 6.282630\n",
      "Training accuracy - digit count: 67.2%; digits 1-5: 22.7%, 25.4%, 69.1%, 94.9%, 100.0%\n",
      "Training avg accuracy: 64.8%\n",
      "Validation accuracy - digit count: 45.3%; digits 1-5: 33.2%, 18.8%, 50.0%, 94.5%, 100.0%\n",
      "Validation avg accuracy: 64.8%\n",
      "Minibatch training loss at step 400: 6.326273\n",
      "Training accuracy - digit count: 61.7%; digits 1-5: 24.2%, 22.7%, 67.6%, 94.9%, 100.0%\n",
      "Training avg accuracy: 63.3%\n",
      "Validation accuracy - digit count: 60.9%; digits 1-5: 34.4%, 25.0%, 64.5%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 63.3%\n",
      "Minibatch training loss at step 450: 5.564641\n",
      "Training accuracy - digit count: 75.0%; digits 1-5: 23.8%, 27.7%, 72.7%, 97.7%, 100.0%\n",
      "Training avg accuracy: 67.5%\n",
      "Validation accuracy - digit count: 68.8%; digits 1-5: 31.6%, 27.0%, 73.4%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 67.5%\n",
      "Minibatch training loss at step 500: 5.464529\n",
      "Training accuracy - digit count: 77.0%; digits 1-5: 18.0%, 35.9%, 70.7%, 95.3%, 100.0%\n",
      "Training avg accuracy: 69.3%\n",
      "Validation accuracy - digit count: 65.6%; digits 1-5: 36.7%, 25.4%, 69.9%, 94.5%, 100.0%\n",
      "Validation avg accuracy: 69.3%\n",
      "Minibatch training loss at step 550: 5.078834\n",
      "Training accuracy - digit count: 78.1%; digits 1-5: 16.8%, 31.6%, 71.9%, 98.8%, 100.0%\n",
      "Training avg accuracy: 71.4%\n",
      "Validation accuracy - digit count: 67.6%; digits 1-5: 34.0%, 31.2%, 72.7%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 71.4%\n",
      "Minibatch training loss at step 600: 4.849911\n",
      "Training accuracy - digit count: 74.6%; digits 1-5: 14.1%, 42.2%, 72.7%, 94.5%, 100.0%\n",
      "Training avg accuracy: 72.5%\n",
      "Validation accuracy - digit count: 70.7%; digits 1-5: 49.6%, 34.8%, 68.4%, 94.1%, 100.0%\n",
      "Validation avg accuracy: 72.5%\n",
      "Minibatch training loss at step 650: 4.104352\n",
      "Training accuracy - digit count: 83.2%; digits 1-5: 13.7%, 53.1%, 78.9%, 98.4%, 100.0%\n",
      "Training avg accuracy: 77.9%\n",
      "Validation accuracy - digit count: 74.6%; digits 1-5: 54.3%, 42.6%, 72.7%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 77.9%\n",
      "Minibatch training loss at step 700: 4.066936\n",
      "Training accuracy - digit count: 80.1%; digits 1-5: 11.7%, 46.1%, 77.3%, 96.9%, 100.0%\n",
      "Training avg accuracy: 76.9%\n",
      "Validation accuracy - digit count: 77.3%; digits 1-5: 58.2%, 48.0%, 70.3%, 93.8%, 100.0%\n",
      "Validation avg accuracy: 76.9%\n",
      "Minibatch training loss at step 750: 3.945820\n",
      "Training accuracy - digit count: 82.4%; digits 1-5: 14.8%, 53.1%, 73.8%, 94.9%, 100.0%\n",
      "Training avg accuracy: 77.7%\n",
      "Validation accuracy - digit count: 78.9%; digits 1-5: 57.0%, 49.2%, 72.3%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 77.7%\n",
      "Minibatch training loss at step 800: 3.698863\n",
      "Training accuracy - digit count: 80.5%; digits 1-5: 16.4%, 57.8%, 78.9%, 94.9%, 100.0%\n",
      "Training avg accuracy: 79.3%\n",
      "Validation accuracy - digit count: 81.6%; digits 1-5: 59.4%, 50.8%, 73.0%, 95.7%, 100.0%\n",
      "Validation avg accuracy: 79.3%\n",
      "Minibatch training loss at step 850: 3.311986\n",
      "Training accuracy - digit count: 86.7%; digits 1-5: 16.0%, 63.3%, 79.3%, 96.1%, 100.0%\n",
      "Training avg accuracy: 82.0%\n",
      "Validation accuracy - digit count: 80.5%; digits 1-5: 63.3%, 54.7%, 74.2%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 82.0%\n",
      "Minibatch training loss at step 900: 3.113022\n",
      "Training accuracy - digit count: 84.4%; digits 1-5: 16.0%, 60.9%, 84.0%, 98.0%, 100.0%\n",
      "Training avg accuracy: 82.4%\n",
      "Validation accuracy - digit count: 80.5%; digits 1-5: 62.5%, 50.8%, 76.2%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 82.4%\n",
      "Minibatch training loss at step 950: 3.237599\n",
      "Training accuracy - digit count: 88.3%; digits 1-5: 14.5%, 58.6%, 78.1%, 96.5%, 100.0%\n",
      "Training avg accuracy: 82.1%\n",
      "Validation accuracy - digit count: 81.2%; digits 1-5: 59.4%, 50.0%, 74.6%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 82.1%\n",
      "Minibatch training loss at step 1000: 3.353089\n",
      "Training accuracy - digit count: 83.6%; digits 1-5: 16.4%, 64.1%, 78.9%, 98.0%, 100.0%\n",
      "Training avg accuracy: 82.4%\n",
      "Validation accuracy - digit count: 82.0%; digits 1-5: 60.2%, 52.3%, 75.4%, 96.9%, 100.0%\n",
      "Validation avg accuracy: 82.4%\n",
      "Minibatch training loss at step 1050: 2.849353\n",
      "Training accuracy - digit count: 87.1%; digits 1-5: 14.8%, 62.5%, 85.2%, 97.3%, 100.0%\n",
      "Training avg accuracy: 83.7%\n",
      "Validation accuracy - digit count: 81.6%; digits 1-5: 62.5%, 52.3%, 77.3%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 83.7%\n",
      "Minibatch training loss at step 1100: 3.197888\n",
      "Training accuracy - digit count: 83.2%; digits 1-5: 14.1%, 63.3%, 78.1%, 96.1%, 100.0%\n",
      "Training avg accuracy: 82.2%\n",
      "Validation accuracy - digit count: 78.9%; digits 1-5: 60.9%, 50.8%, 73.8%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 82.2%\n",
      "Minibatch training loss at step 1150: 3.163337\n",
      "Training accuracy - digit count: 84.4%; digits 1-5: 13.3%, 62.1%, 80.9%, 96.5%, 99.6%\n",
      "Training avg accuracy: 82.2%\n",
      "Validation accuracy - digit count: 82.4%; digits 1-5: 66.4%, 54.3%, 78.1%, 97.7%, 100.0%\n",
      "Validation avg accuracy: 82.2%\n",
      "Minibatch training loss at step 1200: 2.513138\n",
      "Training accuracy - digit count: 89.8%; digits 1-5: 15.6%, 71.5%, 85.2%, 98.0%, 100.0%\n",
      "Training avg accuracy: 86.2%\n",
      "Validation accuracy - digit count: 80.1%; digits 1-5: 59.8%, 52.7%, 76.6%, 96.1%, 100.0%\n",
      "Validation avg accuracy: 86.2%\n",
      "Minibatch training loss at step 1250: 3.120734\n",
      "Training accuracy - digit count: 87.5%; digits 1-5: 16.8%, 56.6%, 85.5%, 96.1%, 100.0%\n",
      "Training avg accuracy: 83.4%\n",
      "Validation accuracy - digit count: 77.7%; digits 1-5: 64.8%, 52.3%, 76.6%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 83.4%\n",
      "Minibatch training loss at step 1300: 2.743911\n",
      "Training accuracy - digit count: 84.0%; digits 1-5: 14.5%, 69.9%, 83.6%, 96.9%, 99.6%\n",
      "Training avg accuracy: 85.0%\n",
      "Validation accuracy - digit count: 82.4%; digits 1-5: 66.0%, 55.5%, 76.6%, 96.9%, 100.0%\n",
      "Validation avg accuracy: 85.0%\n",
      "Minibatch training loss at step 1350: 2.694832\n",
      "Training accuracy - digit count: 89.1%; digits 1-5: 13.7%, 66.8%, 82.4%, 96.5%, 100.0%\n",
      "Training avg accuracy: 85.2%\n",
      "Validation accuracy - digit count: 78.5%; digits 1-5: 64.5%, 57.0%, 75.4%, 95.3%, 100.0%\n",
      "Validation avg accuracy: 85.2%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#def eval_accuracy(eval_l_preds, eval_preds, l_labels, labels, masks):\n",
    "#    concatted = np.concatenate((np.reshape((eval_l_preds == l_labels), [-1, 1]), \n",
    "#                                (eval_preds * masks) == labels), axis=1)\n",
    "#    return 100.0 * (np.sum([np.all(row) for row in concatted])) / len(labels)\n",
    "#\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run() # sess.run(tf.global_variables_initializer())\n",
    "  print('Initialized')\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (np.asarray(y1_train).shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "    \n",
    "    #normalize data to mean 0 and unit variance\n",
    "    batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "\n",
    "  #  batch_data_valid = valid_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "    \n",
    "    batch_labels0 =  np.asarray(train_label0)[offset:(offset + batch_size), :]\n",
    "    batch_labels1 =  np.asarray(train_label1)[offset:(offset + batch_size), :]\n",
    "    batch_labels2 =  np.asarray(train_label2)[offset:(offset + batch_size), :]\n",
    "    batch_labels3 =  np.asarray(train_label3)[offset:(offset + batch_size), :]\n",
    "    batch_labels4 =  np.asarray(train_label4)[offset:(offset + batch_size), :]\n",
    "    batch_labels5 =  np.asarray(train_label5)[offset:(offset + batch_size), :]    \n",
    "   # print(batch_labels1.shape)\n",
    "    feed_dict = {tf_train_dataset : batch_data\n",
    "              #  , tf_valid_dataset : batch_data_valid\n",
    "                , tf_train_labels0 : batch_labels0\n",
    "                , tf_train_labels1 : batch_labels1\n",
    "                , tf_train_labels2 : batch_labels2\n",
    "                , tf_train_labels3 : batch_labels3\n",
    "                , tf_train_labels4 : batch_labels4\n",
    "                , tf_train_labels5 : batch_labels5\n",
    "                }\n",
    "    _, l, pred_train0, pred_train1, pred_train2, pred_train3, pred_train4, pred_train5  \\\n",
    "        , pred_valid0, pred_valid1, pred_valid2, pred_valid3, pred_valid4, pred_valid5  \\\n",
    "        = session.run([optimizer, loss, train_prediction0, train_prediction1, train_prediction2  \\\n",
    "                       , train_prediction3, train_prediction4, train_prediction5, valid_prediction0  \\\n",
    "                       , valid_prediction1, valid_prediction2, valid_prediction3 , valid_prediction4, valid_prediction5]  \\\n",
    "                      , feed_dict=feed_dict)\n",
    "     \n",
    "    #normalize data to mean 0 and unit variance\n",
    "    batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "   # batch_valid_labels0 =  np.asarray(valid_label0)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels1 =  np.asarray(valid_label1)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels2 =  np.asarray(valid_label2)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels3 =  np.asarray(valid_label3)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels4 =  np.asarray(valid_label4)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels5 =  np.asarray(valid_label5)[offset:(offset + batch_size), :]  \n",
    "    \n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch training loss at step %d: %f' % (step, l))\n",
    "      print(\"Training accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_train0, batch_labels0),accuracy(pred_valid1, batch_labels1)  \\\n",
    "        ,accuracy(pred_train2, batch_labels2), accuracy(pred_train3, batch_labels3)  \\\n",
    "        ,accuracy(pred_train4, batch_labels4), accuracy(pred_train5, batch_labels5)))\n",
    "      avg_acc_train = (accuracy(pred_train0, batch_labels0) + accuracy(pred_train1, batch_labels1)\n",
    "        + accuracy(pred_train2, batch_labels2) + accuracy(pred_train3, batch_labels3)\n",
    "        + accuracy(pred_train4, batch_labels4) + accuracy(pred_train5, batch_labels5))/6\n",
    "      print('Training avg accuracy: %.1f%%' % avg_acc_train)\n",
    "        \n",
    "      print(\"Validation accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_valid0, valid_label0[:batch_size]),accuracy(pred_valid1, valid_label1[:batch_size])  \\\n",
    "        ,accuracy(pred_valid2, valid_label2[:batch_size]), accuracy(pred_valid3, valid_label3[:batch_size])  \\\n",
    "        ,accuracy(pred_valid4, valid_label4[:batch_size]), accuracy(pred_valid5, valid_label5[:batch_size])))\n",
    "      avg_acc_valid = (accuracy(pred_valid0, valid_label0[:batch_size]) + accuracy(pred_valid1, valid_label1[:batch_size])\n",
    "        + accuracy(pred_valid2, valid_label2[:batch_size]) + accuracy(pred_valid3, valid_label3[:batch_size])\n",
    "        + accuracy(pred_valid4, valid_label4[:batch_size]) + accuracy(pred_valid5, valid_label5[:batch_size]))/6\n",
    "      print('Validation avg accuracy: %.1f%%' % avg_acc_train)\n",
    "     # print(\"w1 mean: {} std: {}\".format(np.mean(w), np.std(w)))\n",
    "     # print(\"wy1 mean: {} std: {}\".format(np.mean(w1), np.std(w1)))\n",
    "      #print(\"label: \", batch_labels1)\n",
    "    #  print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), L_valid))\n",
    "  #print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
