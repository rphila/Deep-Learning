{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7: Build a Live Camera App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rita Philavanh\n",
    "\n",
    "20170905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Street View House Number (SVHN) training/test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download train.tar.gz and test.tar.gz files from http://ufldl.stanford.edu/housenumbers/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dataset from compressed tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 0\n",
    "np.random.seed(133)\n",
    "data_root = '.'\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract('train.tar.gz')\n",
    "test_folders = maybe_extract('test.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels from .mat file \n",
    "\n",
    "(used digiStruct.py code found here: https://github.com/prijip/Py-Gsvhn-DigitStruct-Reader/blob/360a03909a22a28e2e814e83d6915ee5f915e5da/digitStruct.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 268.70s\n"
     ]
    }
   ],
   "source": [
    "#import h5py\n",
    "#import numpy as np\n",
    "#digitStruct = h5py.File('train/digitStruct.mat')\n",
    "#digitStruct.keys()\n",
    "#mat = {}\n",
    "#for k, v in digitStruct.items():\n",
    "#    print(k,v)\n",
    "#    mat[k] = np.array(v)\n",
    "\n",
    "#print(mat)\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Bounding Box\n",
    "#\n",
    "class BBox:\n",
    "    def __init__(self):\n",
    "        self.label = \"\"     # Digit\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "\n",
    "class DigitStruct:\n",
    "    def __init__(self):\n",
    "        self.name = None    # Image file name\n",
    "        self.bboxList = None # List of BBox structs\n",
    "\n",
    "# Function for debugging\n",
    "def printHDFObj(theObj, theObjName):\n",
    "    isFile = isinstance(theObj, h5py.File)\n",
    "    isGroup = isinstance(theObj, h5py.Group)\n",
    "    isDataSet = isinstance(theObj, h5py.Dataset)\n",
    "    isReference = isinstance(theObj, h5py.Reference)\n",
    "    print(\"{}\".format(theObjName))\n",
    "    print(\"    type(): {}\".format(type(theObj)))\n",
    "    if isFile or isGroup or isDataSet:\n",
    "        # if theObj.name != None:\n",
    "        #    print \"    name: {}\".format(theObj.name)\n",
    "        print(\"    id: {}\".format(theObj.id))\n",
    "    if isFile or isGroup:\n",
    "        print(\"    keys: {}\".format(theObj.keys()))\n",
    "    if not isReference:\n",
    "        print(\"    Len: {}\".format(len(theObj)))\n",
    "\n",
    "    if not (isFile or isGroup or isDataSet or isReference):\n",
    "        print(theObj)\n",
    "\n",
    "def readDigitStructGroup(dsFile):\n",
    "    dsGroup = dsFile[\"digitStruct\"]\n",
    "    return dsGroup\n",
    "\n",
    "#\n",
    "# Reads a string from the file using its reference\n",
    "#\n",
    "def readString(strRef, dsFile):\n",
    "    strObj = dsFile[strRef]\n",
    "    str = ''.join(chr(i) for i in strObj)\n",
    "    return str\n",
    "\n",
    "#\n",
    "# Reads an integer value from the file\n",
    "#\n",
    "def readInt(intArray, dsFile):\n",
    "    intRef = intArray[0]\n",
    "    isReference = isinstance(intRef, h5py.Reference)\n",
    "    intVal = 0\n",
    "    if isReference:\n",
    "        intObj = dsFile[intRef]\n",
    "        intVal = int(intObj[0])\n",
    "    else: # Assuming value type\n",
    "        intVal = int(intRef)\n",
    "    return intVal\n",
    "\n",
    "def yieldNextInt(intDataset, dsFile):\n",
    "    for intData in intDataset:\n",
    "        intVal = readInt(intData, dsFile)\n",
    "        yield intVal \n",
    "\n",
    "def yieldNextBBox(bboxDataset, dsFile):\n",
    "    for bboxArray in bboxDataset:\n",
    "        bboxGroupRef = bboxArray[0]\n",
    "        bboxGroup = dsFile[bboxGroupRef]\n",
    "        labelDataset = bboxGroup[\"label\"]\n",
    "        leftDataset = bboxGroup[\"left\"]\n",
    "        topDataset = bboxGroup[\"top\"]\n",
    "        widthDataset = bboxGroup[\"width\"]\n",
    "        heightDataset = bboxGroup[\"height\"]\n",
    "\n",
    "        left = yieldNextInt(leftDataset, dsFile)\n",
    "        top = yieldNextInt(topDataset, dsFile)\n",
    "        width = yieldNextInt(widthDataset, dsFile)\n",
    "        height = yieldNextInt(heightDataset, dsFile)\n",
    "\n",
    "        bboxList = []\n",
    "\n",
    "        for label in yieldNextInt(labelDataset, dsFile):\n",
    "            bbox = BBox()\n",
    "            bbox.label = label\n",
    "            bbox.left = next(left)\n",
    "            bbox.top = next(top)\n",
    "            bbox.width = next(width)\n",
    "            bbox.height = next(height)\n",
    "            bboxList.append(bbox)\n",
    "\n",
    "        yield bboxList\n",
    "\n",
    "def yieldNextFileName(nameDataset, dsFile):\n",
    "    for nameArray in nameDataset:\n",
    "        nameRef = nameArray[0]\n",
    "        name = readString(nameRef, dsFile)\n",
    "        yield name\n",
    "\n",
    "# dsFile = h5py.File('train/digitStruct.mat', 'r')\n",
    "def yieldNextDigitStruct(dsFileName):\n",
    "    dsFile = h5py.File(dsFileName, 'r')\n",
    "    dsGroup = readDigitStructGroup(dsFile)\n",
    "    nameDataset = dsGroup[\"name\"]\n",
    "    bboxDataset = dsGroup[\"bbox\"]\n",
    "\n",
    "    bboxListIter = yieldNextBBox(bboxDataset, dsFile)\n",
    "    for name in yieldNextFileName(nameDataset, dsFile):\n",
    "        bboxList = next(bboxListIter)\n",
    "        obj = DigitStruct()\n",
    "        obj.name = name\n",
    "        obj.bboxList = bboxList\n",
    "        yield obj\n",
    "\n",
    "# Declare variables to store labels\n",
    "L = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "y4 = []\n",
    "y5 = []\n",
    "\n",
    "#Declare variables to store overall bounding box\n",
    "left = []\n",
    "top = []\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "def testMain():\n",
    "    i = 0\n",
    "    dsFileName = 'train/digitStruct.mat'\n",
    "    testCounter = 0\n",
    "\n",
    "    for dsObj in yieldNextDigitStruct(dsFileName):\n",
    "        # testCounter += 1\n",
    "       # print(dsObj.name)\n",
    "      #  print(len(dsObj.bboxList))\n",
    "        L.append(len(dsObj.bboxList))\n",
    "        \n",
    "        cnty = 0\n",
    "        width_sum = 0\n",
    "        height_max = 0\n",
    "        for bbox in dsObj.bboxList:\n",
    "         #   print(\"    {}:{},{},{},{}\".format(\n",
    "         #       bbox.label, bbox.left, bbox.top, bbox.width, bbox.height))\n",
    "            \n",
    "            width_sum = width_sum + bbox.width\n",
    "            height_max = max(height_max, bbox.height)\n",
    "                \n",
    "            if cnty == 0: \n",
    "                y1.append(bbox.label)\n",
    "                left.append(bbox.left)\n",
    "                top.append(bbox.top)\n",
    "            elif cnty == 1: y2.append(bbox.label) \n",
    "            elif cnty == 2: y3.append(bbox.label)\n",
    "            elif cnty == 3: y4.append(bbox.label)\n",
    "            elif cnty == 4: y5.append(bbox.label)\n",
    "            \n",
    "            cnty += 1\n",
    "            \n",
    "        width.append(width_sum)\n",
    "        height.append(height_max)\n",
    "        \n",
    "        # assign 10 to empty digits\n",
    "        if cnty < 5:\n",
    "            if len(dsObj.bboxList) < 1: y1.append(10)\n",
    "            if len(dsObj.bboxList) < 2: y2.append(10) \n",
    "            if len(dsObj.bboxList) < 3: y3.append(10)\n",
    "            if len(dsObj.bboxList) < 4: y4.append(10)\n",
    "            if len(dsObj.bboxList) < 5: y5.append(10)\n",
    "        if testCounter >= 5:\n",
    "            break\n",
    "        i +=1\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    t1 = time.time()\n",
    "    testMain()\n",
    "    t2 = time.time()\n",
    "    print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33402\n",
      "[2, 2, 2, 2, 2, 2, 2, 3, 3, 2]\n",
      "[1, 2, 2, 9, 3, 3, 2, 7, 1, 1]\n",
      "[9, 3, 5, 3, 1, 3, 8, 4, 2, 6]\n",
      "[10, 10, 10, 10, 10, 10, 10, 4, 8, 10]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "print(len(L))\n",
    "print(L[:10]) # length of digits\n",
    "print(y1[:10]) # 1st digit\n",
    "print(y2[:10]) # 2nd digit\n",
    "print(y3[:10]) # ...etc (If no digit, then 'None')\n",
    "print(y4[:10])\n",
    "print(y5[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset to cropped 32x32 pixels grayscale matrix fitting outer bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "X = []\n",
    "pic_num = 1\n",
    "#print(len(os.listdir('./train')))\n",
    "num_files = len([f for f in os.listdir('./train') if f.endswith('.png') and os.path.isfile(os.path.join('./train', f))])\n",
    "for i in range(num_files): \n",
    "    #print(top[i], height[i], left[i], width[i])\n",
    "    img = cv2.imread(\"./train/\"+str(pic_num) +\".png\",cv2.IMREAD_GRAYSCALE)\n",
    "    #print(img.shape)\n",
    "    #print(img[top[i]:(top[i]+height[i]), left[i]:(left[i]+width[i])].shape)\n",
    "    crop_img = img[max(0,top[i]):(max(0,top[i])+max(0,height[i])), max(0,left[i]):(max(0,left[i])+max(0,width[i]))]\n",
    "    resized_image = cv2.resize(crop_img, (32, 32))\n",
    "    X.append(resized_image)\n",
    "   # print(pic_num)\n",
    "    pic_num +=1\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33402 13402 20000\n",
      "33402 13402 20000\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:20000]\n",
    "L_train = L[:20000] \n",
    "\n",
    "y1_train = y1[:20000]\n",
    "y2_train = y2[:20000]\n",
    "y3_train = y3[:20000]\n",
    "y4_train = y4[:20000]\n",
    "y5_train = y5[:20000]\n",
    "\n",
    "X_valid = X[20000:]\n",
    "L_valid = L[20000:] \n",
    "y1_valid = y1[20000:]\n",
    "y2_valid = y2[20000:]\n",
    "y3_valid = y3[20000:]\n",
    "y4_valid = y4[20000:]\n",
    "y5_valid = y5[20000:]\n",
    "\n",
    "print(len(X), len(X_valid), len(X_train))\n",
    "print(len(L), len(L_valid), len(L_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 3, 3, 2]\n",
      "[1, 2, 2, 9, 3, 3, 2, 7, 1, 1]\n",
      "[9, 3, 5, 3, 1, 3, 8, 4, 2, 6]\n",
      "[10, 10, 10, 10, 10, 10, 10, 4, 8, 10]\n",
      "[10 10 10 10 10 10 10  4  8 10]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[3, 1, 2, 3, 3, 3, 3, 2, 3, 3]\n",
      "[1, 7, 5, 1, 2, 6, 1, 4, 7, 1]\n",
      "[3, 10, 10, 6, 6, 9, 3, 1, 5, 2]\n",
      "[6, 10, 10, 9, 7, 6, 5, 10, 1, 4]\n",
      "[ 6 10 10  9  7  6  5 10  1  4]\n",
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "Training set (20000, 32, 32, 1) (20000, 6) (20000, 11)\n",
      "Validation set (13402, 32, 32, 1) (13402, 6) (13402, 11)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32 # 32 x 32 pixel\n",
    "num_channels = 1 # grayscale\n",
    "num_labels = 11 # 0-9 + 10 (for missing value)\n",
    "num_digits = 6 #max 5 digit for housenumber\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, label0, label1, label2, label3, label4, label5):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  print((label0[:10]))\n",
    "  print((label1[:10]))\n",
    "  print((label2[:10]))\n",
    "  print((label3[:10]))\n",
    "  print(np.asarray(label3[:10]))\n",
    "  label0 = (np.arange(num_digits) == np.asarray(label0)[:,None]).astype(np.float32)\n",
    "  label1 = (np.arange(num_labels) == np.asarray(label1)[:,None]).astype(np.float32)\n",
    "  label2 = (np.arange(num_labels) == np.asarray(label2)[:,None]).astype(np.float32)\n",
    "  label3 = (np.arange(num_labels) == np.asarray(label3)[:,None]).astype(np.float32)\n",
    "  label4 = (np.arange(num_labels) == np.asarray(label4)[:,None]).astype(np.float32)\n",
    "  label5 = (np.arange(num_labels) == np.asarray(label5)[:,None]).astype(np.float32)\n",
    "\n",
    "  print(np.asarray(label3[:10]))\n",
    "  return dataset, label0, label1, label2, label3, label4, label5\n",
    "train_dataset, train_label0, train_label1, train_label2, train_label3, train_label4, train_label5 = reformat(np.asarray(X_train), L_train, y1_train, y2_train, y3_train, y4_train, y5_train)\n",
    "valid_dataset, valid_label0, valid_label1, valid_label2, valid_label3, valid_label4, valid_label5 = reformat(np.asarray(X_valid), L_valid, y1_valid, y2_valid, y3_valid, y4_valid, y5_valid)\n",
    "#test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "#normalize to 0 mean and unit variance\n",
    "train_dataset_norm = (train_dataset - np.mean( train_dataset))/np.std( train_dataset)\n",
    "\n",
    "# Check values\n",
    "print('Training set', train_dataset.shape, train_label0.shape, train_label1.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_label0.shape, valid_label1.shape)\n",
    "#print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot house number image\n",
    "\n",
    "#### Reference: https://github.com/llSourcell/How_to_make_a_tensorflow_image_classifier_LIVE/blob/master/demonotes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19', '23', '25', '93', '31', '33', '28', '744', '128']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvXmQZddd5/k97+VWlZlVWauWUkmFFstawpawsGhMgIaR\nmyYgaAyDwz3DEIYGZsKG6RlHhyGY6R4TvRHQ3dPtie6gG0c0dNMx9DD2GA/jAcYGgwOPJYQty5Ks\nxaWlJJWkWrKyKivXt5z5I/Nz33nf+25mvqzKKrnu+UZk3Lzbuffd31m+53d+S4gxKiMjI6PuaFzt\nF8jIyMh4KyB3hhkZGRnKnWFGRkaGpNwZZmRkZEjKnWFGRkaGpNwZZmRkZEjKnWFGRkaGpNwZZmRk\nZEjKnWFGRkaGJGlkmIsnJibi9PS08FoJIUiS3IslhKBut9t3DWg01vrf3bt3S5L2798vSVpdXZWk\n4r7Tp08X+9zT6XT6ykifJ0nNZnPtR42M9JXFdmVlpbifYw6ONxoNLS4uamVlJQy88BrFwYMH4y23\n3FLsI9tWqyWpX07Igy3f7uLFi5KkdrstSRodHZUk7dq1S5I0NjbWd32MsSRjnrO4uNi3T5mD6pzU\nqwMTExPas2ePpF598Gsl6cyZM5qfn6+VjEdGRuL4+HjxHfj2fFNkMOgc21R2g+DXp2UhI4BMXYb+\nfoDjIYTi/43eZ3l5Wa1Wa1MZD9UZTk9P60d+5EeKikml9kYxNjampaWlvmvAxMSEJOnbv/3bJUkf\n+MAHJEknTpyQpOK+3/zN35S01rBoRDQyL5Pze/fulSTNzMxI6nV+8/PzkqQXX3xR0lpHTCNzLCws\nSJImJyf1p3/6pxt+j2sRt9xyi770pS8V+3SCp06dktST0/z8fCGP8+fPS+rJ7s///M8lSXNzc5Kk\n66+/XpJ0zz33SJKOHj3ad3273S7qBbJ66aWXJElPPPFE3/7Zs2cl9TpHKv/4+LiknuzvvPNOfd/3\nfZ8k6fDhw33X0jlL0sc+9rGtfZhrCOPj47r77ruLQQJiwjdFns1ms5ALHRZtanl5uW/fQb1JO1ae\ng4w4d+bMGUk9udCOkSnvQCfJdnR0tPgN1CXviyTp8ccf3+SLrGGozrDb7Wppaal4GX8Bjq+urmpq\naqrvHB3Wj/7oj0qS7r///r6y+QDPP/983/WUJ5U73wceeECS9JM/+ZN9ZfFebF999VVJ0he+8AVJ\na50iwgLeoV68eLGSPV7riDEWlZ/BgY6NinvhwoWCvX/zm9+UJL388suSep0ho/b09LSkXof60EMP\nSZIOHjwoaa3SU/FPnjwpSXrmmWf6trOzs33v6IyARvnmm28W+8j03e9+tyTppptu6ru3rgghaGRk\npOhI0sFBWiMC0hqj9jZX1TEBn71VdZYpkD31hDaYvke6pez0vTlHJz2oM94MWWeYkZGRoSGZYafT\n0cWLF0usj9GBUWRsbEzf/d3fLak3HUY3yL0O2B9sgxGl0+mUptw/9VM/JUn6ru/6Lkk9Bsh7MLKw\n5dlcNzs7W0zHGEk4B1ZWVir1IXUAzJDvxPSU46dOndKTTz4pqTeVfeWVVyT1RmVGa1QSr732miSV\n5NlsNotrYILPPvuspB4jrdIVAhgibGFubq54Lxjh7bff3vd+dQXM0HXssD4Y2vj4eHHMvxnyciZG\nO0aFwswiZYjcQ19AOz1w4ICkXnvl2TDHjcDUnuexbbfbJZ1jFTIzzMjIyNCQzDCEUKyySr0e2xli\np9PR2972Nkm9Xh/GR6/PPqODK28Zac6fP19cg74RXSGjD0wDfSM6LJ71jne8Q5L09re/vbjvj//4\nj/ueB/PhN42MjNRStxRC0MTERMHI3njjDUk9XSELKMePH9fXvvY1Sb3vDXzFkfqBzNH/pavW6BOR\nIfJwva1bMqR1TurVo2azWTyHd3YLhzoz/2azWdL3UffR1U1MTBT/Axg639sXUphJwPphnRcvXizp\n7yj7xhtvlCRdd911fVvudWZIOe12u3i+WwykTHar7Tgzw4yMjAwNyQyB6w/ouVNd0Gc/+9m+Y+gh\nPvrRj0oqr/LA8mAEae//4IMPSpJ+4Ad+QFKPYXAPDOAP/uAPJPXYHmVgUoOu8e1vf3vxXp/+9Kf7\nrmWE24qe4lpEt9vV/Px8wf5hhF//+tclrTFCaY0RbLZS6DKGmSGflJmdO3eu73mM+JThLM7l4wyy\n2+0W9RSWS71BN1VnZrgRUkbmzNAZmJvcoKtD34cOd2RkpMTimLkxizxy5Iiknnx8xdrNZs6fP1/S\nTQLqw9LS0patQjIzzMjIyNA27Azp3aVer+9sam5ursQK0CXA4tAp0LNzntEbHDhwQD/zMz8jqae/\nomzYHfo/7NwYeRhRWKHk/kOHDunQoUNF+SlgE/Pz87W0M8TGkJXhr3zlK5JUGKBjxzcxMaEbbrhB\nUs+IGgbOvT6SU3fQD6bfF/YGa2QFkC16n5tvvllSz0YReaEXpP6EEArm58bhMJI6I22fsDu+Jfup\nLaKv7FYxRBia6yNbrVapXSJDdMfIlnUGfwb1J2WBaX+U/q5Ut7nVGcDQCyhjY2Ml1zn3CJHK5i7Q\nbae8AMNoKiyLJvfff3+hoKcDo1P76le/KqnX2TEV5zzP5P3wrPihH/oh3XrrrUX5Um+KnXbsW12S\nv5bQarV06tSpovPju7CwQad077336tu+7dsk9TwK8PTAcLpqisuASCfV6XSKaTKVGLBPA7n33nsl\nSceOHes7z3vR0abPpb6C1OWyjsBEjs4GObl5TKfTKX1/N4CmkwQcp8OiPU9PTxeEx4286dDcfIuy\nvKNN1WPcwyDN89guLy/naXJGRkbGMBiKGcYYtbq6WmJ1sMBUWQpgZe6P6C59Fy5ckFQO3PDjP/7j\nRS/PiMC5F154oe+4j/SMdDwjdeuDecI2Ae++srJSy2nyysqKnn/+eX3xi1+UJD333HOSeqNz6l/q\nRu0gdaRP4c77bJvNZp8BttSTJfLgWfg5w0Kpc8weuC+VnZc5KIhAnRBj1PLycvHtnIkN8tvnHO2G\nWZdPm30myPW+wJGCc84EHW4Gd/bs2WKWwTHvKzIzzMjIyBgSQy+gzM/Pl3SE6AJgf+fPny96d5Ts\nd9xxR3FO6jEy9tH1sI8hZqfTKdgAQCcIG+B9uBe4rgjH/WazWSzjcwx2g+5yGAfvawlLS0t6+umn\nC9btOjkwNTVVyBAjWQ+mAAbdK/XYW6vVKo5Rh1hQQbYYzFOfuB727xFpVldXi+d6cIGq8HJ1Qbfb\n1eLiYmkmxbdL3fRgazA99Hub6RDdYNp1iylcV5i60qXPdPY3NzdX/M/MEp1/GqhhqzOAzAwzMjIy\ntM3VZHp9Rm96f0aalDn66jAMzHWHXMe9MMN09ZprMaFBt+EmAV4229T1z/WPKWuU6huoodVq6Y03\n3ih+u5s3IOs777yzMI3w0blKRwMTg1GmjvqE2YKdwAK4B0boOmZMaWCyKXj3ffv29T2P9/PfVhd0\nOh3Nz8+XVnXdHCY9BhOkjbmescq1b1CwBb82XflN72Gf88w86HcWFhb6dINSjxny2xqNRmaGGRkZ\nGcNg6NXkTqdTii4LGC3Gx8eL3h99IjpDN5iGAbixNQaYFy9eLNgkhrWMEIzwHorIR3xGC8oZGxsr\nnseq5KAy6qhTajabmp6eLuwwPZAGutbdu3cXMmSkhp3x3VwOfGPsQRnVY4yFrpDnIisYOzL8q7/6\nK0m92YG72qWsFHYAM+QZsIg6Mn9pTT6jo6NbCmXmNojsOyN0nSBMMo2M7c4ZHmqPuuazRbY8gxno\nxMREya7R2S6/dyvIzDAjIyNDQzLDRqPRlz+EkdZ1dSk4xopwmidF6q0Mu91h6qniOj934at6Jvcx\nEsFOV1dXi/d56qmnit+W/pZB+pM6oNFoaGJiQt/zPd8jSSV9LXaGk5OTBSsjxwQeQc64YGvoCtE1\nUgdCCAXzYPRHPpQF8yNsGB4rvB+MIF0pJpgrcqfsKs+YugMZ8C23YlHhbQzQVmGDabgtzjEr81kI\noH5haeIzjYWFhUKmzDAHebjl4K4ZGRkZQ2BbdoYe3NXZQ+rTiH4IFsAIzz7XuZdIGtCBe9wCHZbi\no4GvcnM+TTIFeJ4zjXa7nZmDymlX+canTp3S008/LakX9h8W4ClaYRrUBWYU2K51u92SPSNb7qW+\nVHmROIsZGxsr9I7oDGE+g7xU6gz31a5K9iSVbf88GMdGMyrX6cMEsVNFdwjSILMp2J+bmyv6CfoC\nrAzoK3LY/4yMjIwhsS1DK3ph91clMOfu3buLEYLVR/cGYdTmHgd6wXS0SPO5pltCRnn+V9gE70BZ\nqZ0hLNe9V+oKLAbcFg9WBUt//vnni4RQRAzxe5ADIzx6QBgBI3y32y3d62H9N7Nd9Geurq4W78VM\nAh1V3fXCMcahk2INCo0llUN2weRhjr5NQfv0VWXgXiye53l2draYZXAvMufa+fn5zAwzMjIyhsHQ\ndobtdrtPryb1emFWCVOdoevpYISsIjNq+yoyK5MXL14seYncc889knpJ4RkpqkAiKVJVTk1NFcyw\nKqlVXZPII2MPqgoD+MY3viFpLQ1AlS+yx7nEm4ggnikjlNZYJ0zF5cHzOZ76v6cYlEqUYLPoNlm1\nrGscQ4fXb1idb6XezAC9sLcfjzRD3UjjDHqKAGYMREYi0HJVUFeQrjpXecDwrEajseUZQK4VGRkZ\nGdqmzhDAyBgl0tGBFSJsvGAJjPgeh4zeGxaYpgEgojL3wAqIZALjoywYJO8Hk+R4uvJIsnIftRqN\nRi09UEgH64yQaD4wwzNnzhTMgu+M/tVnCnfddZekXl2AEfCM1dXVQt7OCKkX2Ch+x3d8hyRpz549\nknr6Yk8lMDY2VsiSc9StjSKo1AUbzXpS5ky78OTwblfokWaIdp4yQ9gl6wS0Y65x3aH7NbtecnR0\ntKgH3n55z/S+zTD0NDn9iL5QkS6oMO314KnuwgcFpix+DD/gt37rt/SRj3yk7x46R+7xTpB7yc0x\nKLsWqQK41wNazs7OVgaZrAP4VlRqvhcLKI1Go6gL3gny3TF6vvPOOyX1Okc3hzl16lShFnHzjptu\nukmSdN9990lSEdCBwA10zrjpvf7665LW6gZlUcdojHTedZ8u8/vpXNLAvVK/u5uH10qDIEv9AU6k\ncmeYBnel3VJvUJnxXKbL7qbnnWUaEKYqZFjqtLHp99jSVRkZGRnXOLYV9t9HVHrelF3RUzM1cmU7\njMwz2sEWmDYdP368yH730EMPSZLe8Y539F0L24QVwBpYOGEk4rqpqanCMBuDYZ4P85menq6l6QVm\nF3x/gi8wHYVdjY2NlVgcwTXe9a53SeoxQ2YHMEKYGvXlhRde0COPPCKpxyAoG1bJ4gusgdkBDID6\nxZQ4ZfU8h+di/F3XYBxSz+1S6jEtN1ORevJ2JjgovL7U+9YwQtrZ4uJiqT150FZkyJbFVmTu4cPG\nx8dLgRo2y+W9ETIzzMjIyNA2AjVMTEyU9HyM4oy4nU6n0D8wsjOCMDrQ+zPHp0dni2J0aWmpSPEJ\nYIawBWeK6A6rArh2Op1CiZvmevZr6ghMa2BYLE6l4bbYojPEmJqFEkxpWEQDnoqS+9vtdsHaYRbU\nKdwkkRdshvdgMcbNqyYnJwsZUqd4Rt11hYTwou67Ti4NwOyJnJydAQ+35dt2u91nCC2VdbnUMV+M\nAYMCDTtjdTOcYWZ39a4VGRkZGesYihm2222dOXOmZEhN75wGYfQlebZcQ6BW9AUOevSzZ88Wq0YY\nWbP6xAgGO4CZoqccFJhBWksmT+gumIezlmHChV9LIFkQq7ToYZFHasIAIySx+2233SaptzoJ23ZX\nTEyiUhZYlTgc+SBz9JI+o/BADwsLC31BQNPfkLr41VHGIYQNGVNqbE3bS1l8ugXs045gaIMsMlJj\n+3Tfy6py/UsNvakvPI9rPJDEVpCZYUZGRoa2oTPctWtXKewWOgCY2Pj4eLGi6yu+zjDYevrRlDHC\nIDxckDt68/z7779fUm9lmPPoKVdXV4tVUk8dAOrKGlqtll5//fWCiXkqzjQgK4wPg2xkzMjtrloe\n1DO1b/ME5jyPMkkLCxtFpsePH+/bpgyRMpkx8Pw6ynUQ+P4eWmtQCK9BgRbS41UBngclhvcgssDb\ntwd5oD7B/lIbQp8hpIElckKojIyMjCGwLXc8H0FgCPT4s7OzevDBB/uuQb+HpwFucB56yUML7dq1\nq2B09P6wRuyPYIAf+tCHinukckggdFiPPfZYqUxHXVeT0QvD9j0QKnJKQ/Wnrk/ptV5P8EBBbu98\n5zslrdm3ofeFGfrzsAdFhlyPpwOr3mlIfw/yABOBKdTVxtCBnGD96aqtuy667tBDe1XdlyaJc1c+\n9/7yWZr3CYNSvA5ioMMiM8OMjIwMbSPs/9LSUtFzwxoYpcHS0pIeeOABSb3VY19RHBTcYdB+38ta\nitKXXnpJkvTBD35QUs/u0MNxwRqwV3zqqadKIep5H9hDq9WqZQgvdIa+0udhuVqtVsGwPHyW64UB\n39xD+k9OThYzh9QuLX0u8mGVuyrpVMr2XKfsgWPrzgyRE98JNpeyuqr26AFyfRZA35DafyJvrnE7\nQ8C9m3mTNJvNkufapSAzw4yMjAxtU2foqz7OGqT+tJzpObc7rAKjxfz8fCnSDTrB97///ZJ6PsgA\nfSBsAj3lo48+KmlNx+jeCIxWabLsOq46djqdLaVACCGUkjJ5gjC+LfvuEYKuaHJysrA+YBUb+Thr\n8NVtTwuQ6pPQTVI2q8keJqxuGB0d1ZEjRwovLyID4TnEdmRkpBSthi16e7ae6J22txFjQ/7ukeQz\ni836io2QV5MzMjIyhsQl6QzRFXqodqmnp3H9HSu/m60Ywf5WV1dLq08kOP+Jn/gJST3W6YwGj5XP\nf/7zknoRWKampgrmwUjHb3EWUzfgm+ysyWNWSmVm5bHtGOkZmV3HzPGZmZnCewUrA1azucbL8tHe\n98fGxgpvFZjh5dQvfSsDZkgbhQnyvUiPkLJs9zX2tu/J3H0m2G63K71XPFJRlXfRIP1l1Spyek9m\nhhkZGRlDYGhmuLi4WKwQwebYsiL40EMPFcyOkQQm5vo/R5rOU1pjGdiWwQTRFXqZjPgwwS9+8YuS\nerH40uvRafCebjO3d+/eWuqU8Nzw3+4J4UdGRko2Zp5o3sG9MIDUvo3o2MeOHZPUY4Zuw1i1EgwT\n4Rk33XRTke4B+0a3Dggh1FLGY2NjuvHGG4u2BiNEBikzRLbODD19p9v+cR1ylLaWPlQq9yvud5xG\ntaGuUU9gk6mP8latQjIzzMjIyNA2fJPTBPHgwx/+sKReZON77rmnUjcIEyMasnsOkJicUeGBBx7Q\nT//0T0vqRUymTEYfdIHom7AnxA4x9WWU1vQbHvOQlcZ0xbGOq8mjo6M6evRowbQY2Z31NZvNSlbF\ntZ5jAx9h913udrvat2+fJOnuu++W1GPxpJF0hljlTQILvOOOO4roOMxYYC/pinQdZYw+1XWG2OnC\nDJvNZiHvzZghqNLdpSvClLlZInu3PvBkT+12uxTHkP203m6VGW4r7L8nXmIfU4Z0muQBVzG5wV0P\n0KH98i//ct/xZrNZ3PvYY49J6pnOkDKAcGDPP/+8pLJ5BiYEfKClpaVSQ3Wj6927d9dyCjU1NaUH\nH3ywpHoADCxpJfMt35lvSaMj2CudIg0rbVA0RII5ELj3y1/+sqRepXf5sUjCIJsuENDhYcpBI2w2\nm7XsDLvdrhYWFkqh9wjoy2LIINMaVFaeqdJDZg3q6LwuedoBD7kGeAd3ER2U19lzug/jPJGnyRkZ\nGRnaJjN00xqS+ZBOcmxsrJhmuXN2ajIj9Xp7Uj2SCpJFmkOHDhUMELYC8yN0FAFIL1y40Pe+PANn\n/r4fbiHIQR2TQKUYGRnRoUOHSu54sORBTCoNjiD1Rm43jGbEJ/FQCu7hOZSJUh82CQNx9uDJgyYn\nJ0tBQNJEQqCO7B/Dep/S+pRY6n0zn4bCFJlRVTHE1MTFQ4OhkvJQXu4I4VNtnjVoBjoI2bQmIyMj\nYwgM7Y7XaDRKQQ7Q99E7T09Pl3SFbnwNc/QlcRgio8DevXsLQ05PGk9I+DRFQPpM1xUw4rRarRJj\n9VBVi4uLtQzUIK2xJWdqbNPgqRzjW7IPi3ODaZgaZacMwN0hKYsZAgss7vpJvULvlDL7Kh3VoKAO\ndcLKyopOnDhR1H2YFouZqSFzVYgu369KGZqauLg8kJUn8wIwRg/2mrLNqkASqR466wwzMjIyhsDQ\nOsN0lciX29Nw/K4b9HSi6P/o2dH5sDLM/c8991zRs/Mcdw2jLHf4pkxWyRiBUpMBD9jAaJmGqKoj\nnL2BNFRTVfgm4AERXI+csk83xHamTr1LZZg+w6+LMZZ0VJ5agOvqhpWVFT377LMFU0Z3B1IG5mzO\n3e9cDl7GoBSe3APz8/QQVfq/QWH2fMYJ0nBhWWeYkZGRMQS2lRAKg2p6apL0pOG5PEgnozJ6Pu/R\n/fgguLF1+l5ST2/EeVadGcXSgJRVocXA6OhoLXVKJBivCoSADigNrAk88ZOvKgNnc2k4MF9Ndr2k\nszwvM32Ws1qfpdQ1YAOrye4W565tqSsb7M1Xgj2wc/oMqexal5bhqAqk4TaLKcusMtx2feNWkJlh\nRkZGhqQwjM4khHBa0ss79zpvOdwSYzx0tV/iSiLL+NpHlvFgDNUZZmRkZFyryNPkjIyMDOXOMCMj\nI0PSDnSGIYQDIYTH1//eCCG8luyPbV7Ctp/72yGE0yGEx+34/SGEL4cQvh5C+P0QwlRVGRlbw9WQ\ncQjhlhDCF0IIT4cQngoh/Hxy7h+HEJ4IIXwthPBHIYTrd+Id6oS3oIz/ob3D91/25++kzjCE8DFJ\nF2OM/9SOh/VnXzZ/txDC90pakvRvY4z3Jce/KunnY4x/EUL4OUk3xBh/5XI9t+64UjIOIdwo6XCM\n8fEQwh5JX5X0AzHG50IIe2KMF9av+4ikW2OMP79ReRlbx1tExv9Q0pkY47+4HM8ahCs2TQ4h3B5C\neDKE8BuSviLpaAhhLjn/gRDCJ9b/vy6E8KkQwmMhhEdDCN+5Wfkxxj+TNDvg1G0xxr9Y////lfRj\nl/5rMgZhJ2UcYzwZY3x8/f8Lkp6RdCTZB7sl5VXBHcLVkvGVwJXWGd4t6RMxxvslvbbBdR+X9Gsx\nxgckvV8SH/fBdSEMg2dCCD+0/v+PSzo65P0Zw2HHZRxCuFXSvZL+Mjn2qyGEV9fL+tgl/YKMzXBV\nZCzp76yrQz4RQth7Sb9gALaVRP4ScDzG+NgWrntY0p2JB8i+EMKuGOMjkh4Z8pkflPQvQwi/Iun3\nJW0cazzjUrGjMl6fPn1S0i/EGItcADHGX5L0SyGEvyfpQ5L+wXZ/QMamuBoy/l8l/c9aY/3/RNKv\nS/q5bb7/QFzpznAh+b8rKfV3S6N1BknvjjH2+8htAzHGpyW9V5JCCHdL+huXWmbGhtgxGa8r7j8l\n6d/FGD9Tcdl/XL8md4Y7hysu4xjjm8k1vynp/xj2pTfDVTOtWVe6ngsh3BFCaEh6X3L6c5I+zE4I\n4T6/f6sIIRxe3zYk/U+Shp1mZ2wTl1PG68r635L0eIzx43bujmT3b2pN15RxBXAFZXxDsvs+SU9e\n4quXcLXtDH9R0h9K+rykV5PjH5b0nnX9wNOSflbaWNcQQvg9SV+UdHcI4dUQwgfXT/3XIYRntdZA\nXpT0H3bkl2RU4XLJ+Hsl/S1J7x1gXvHr60r9JyQ9JOkjO/RbMgbjSsj4n4U187gnJL1H0t+93D8i\nu+NlZGRk6Oozw4yMjIy3BHJnmJGRkaHcGWZkZGRIyp1hRkZGhqTcGWZkZGRIGtLoet++ffGGG24o\nMl6lOVGlXr6BRqNRypjmeXjJreD5MDzHaYyxlB8jPZceZ+v5egflTfVV9EFlrKysqN1u1yoRysGD\nB+PNN99cfDO+06DvVZWX2uW0GQZZNHgZLp/Nrt/oXPqbTpw4oTNnztRKxiMjI3FsbGzTdtJoNLb8\n3b3tDdp6+VV1zJ9VVa86nU5xzK9J61Sn01G3291UxkN1hkeOHNEnP/lJPfvss5J6Cd+PHz8uqZdw\nZ9++fTpyZM2/mnSdt95669oDLV3jmTNnJPXSeXpS+ZWVFc3Ozvb94Pn5eUm9ZDAkq+Hjcp40oMCT\nU0nlzpoyFhYWit9ZJ9x44436zGc+UwxwfGP2+T6jo6PFOZLvkHjLk/GkaRvTbZqwyRsK91SlBuXZ\nnvCHctKyqxIQtVotPfzwwwPPXcsYGxvTnXfe2dfGpHKStvHx8aJteVpP4N+Wdu1lLy8vl9KGsl81\nqHpaUk8CRl+Rvt+gdLUkm9sMeZqckZGRoSGZYbfb1fz8fMHU6HE9defBgweL3nxmZkaSdPPNN0vq\npRhkFKIMymRkYeSfn58vUn6yheExcpDuM31PqcxUPD3ooHu4ZmVlpZapQtvttk6fPl2wa+TBdlDq\nRU8KztZZGvKA7aWjuV/jsvMR3xlrmj4ScC/yZp9ntVqtWiaRdzjrSxkZsnKWxj71AZbncoK9dTqd\n0rUOfz7P5pk+e2s2myVWC7aTBjYzw4yMjAxtgxkuLS0VrAFGCGtIGZf38ozcMMNdu3YVZUq9Xh/W\nx/HZ2dnif0YZdIGMaAcOHOgrk9GCZ5PknuOnT58uFn9gGDyX3zYoSXod0Ol0NDs7WzD1Ksae6uSq\nGKHDmSH76ShOUnLqyfT0dN9xQH26cGEtrqvrg0dGRkp6R2eb0uDFm7og/Q5S7zuxnZqa0p49eyT1\n5ODMkDZFPXHdbsoMgesdnZnyLK8DIJ1VUr7PXNLk8luVcWaGGRkZGRqSGTYaDe3ataukP6AHZ/Se\nmZnRvn37JK3pD6XeyE2PDYv0Ecb1Aik781GJEePGG2/sexZlsJJ90003SeqNQMePH9frr78uqccw\nYIqMcCMjIwN1i9c6YoxqtVqVOrmUGaYry+kWuPlUlX6v1WoV3x8ZI1vfApiAv1f6Lq5/pN5QTxuN\nRh+DqAvX/GjkAAAgAElEQVRCCH2ygs3BCPfuXQsivW/fvuJ/2hLfjm+J3LxPAKlFgbPGdNU6fS5b\nWKnrIQfpHNH1A+Ta7XYzM8zIyMgYBkMxwxij2u12aaWGUZvRY2Zmpk+nJPV6c3RyruOBXRYvtn58\n//79BcPAFpGynV1yvEqHxah211136brrrpMknT17VlKZGY6OjtaSGbZaLZ0+fbqkDwap/q1KB5iW\nJZVX9pwhpjZovorNNa4Tcls1txRoNBqllehBq5Jui1oHhBD6dOLO0Ggne/fu1eHDhyWpmOnB2nxG\n54zR2//Y2FhxjnqBPFImmm7pE6r0kCMjI6UVardsGQZDdYadTkdzc3MlZTodG0gp+CuvvCJJeuaZ\nteDD/gH42L5lartv376iwp44caLveXS+bGmUg6bYKVZXV0tTNQQFNT9w4EAtF1Da7bbOnDlTdEqA\nb8vANzMzU8iQSosZFaB+MNAA5Dk3t5ZUrdvtDjSpSve9U/aO1htMOgWuMhxfXV2t7TR5fHy80iwm\nNV3zqfOhQ4ck9doJYJGStsj19AWTk5PFYpd3hnR+qLtuuOGGvmf4lBxzvImJieJdXQ1H211ZWSnV\nnSrkaXJGRkaGtsEMFxYWipHdl7EZYVqtVtF7v/TSS5Kkz372s5J6owEjCMbYMME77lhLZ0HPPjk5\nWZpSM+pgUsM+1NzNZlJDammNdfj0yOn99PR0pRvXtQwM62FmfA8YAuzvyJEjhcslDA/XSjegZupa\nZTi9d+/e0gIIz0eNwTN8Ssf7oPZgupbOTmCElMm+K93rhE6nU7Qr2rGrM0ZGRkoG0HxfWBsyHuTq\nKvWbuXEvsmZGAds8duyYpB4zpI/gHVBhnT59unimq1Pc5KrZbG556pyZYUZGRoa2kSq02+2WjGoZ\nFRhpz507V7jOfe1rX5PUY4iMMLA3enZGfspKFbeuzPfnexQdFlrcBCc19HaXPUYpGMWePXtKSuC6\nYFAABdf/XbhwobTo4XpGd4Nzo+eUhfMcRna/x814YBmwB9gFs4Tp6eninWEUPpOpMg6/1tHtditd\n4qRqXbtUXoxy8xfar7fJZrNZtH3OITuY4O233y6pN0vkPGXzLN7v/PnzBQOkj6AOItth3Grr2doz\nMjIyDEMzw43YEj3+m2++Wczrn3vuub5r6N1hDTABdEMe0uvcuXOF0aTrJtmin3z55Zf7nknZjGKM\nMNPT0yVmwWjE8aWlpVq6anU6HZ0/f75g6lXG1/Pz86WQab5q7EbPbkCdBmxwsyiPc+lM0c15kG3K\nRj1Ah7uR1hUY1jv45im787bG1ldxvQwwSO/urrpuluNbynBToE6nU7wPs0bMbtiurq5ueQaQmWFG\nRkaGtsEM2+12yX7LgyycPXu2YGkwPubt6AIZtWEgbGGEJ0+elLRmp8hI4EEd2KYBGCTphRdekNRj\nAB79dmJioliFRF9BGdhLLS0tlUa9OqDb7Wp5ebn4ds4MYVezs7Ol1Xr/Xr6q7FYAsPJUZ+h1q2rF\n15mk14nU6NojOaerp3Vk/7jjue7U9X2pjR6s37cOdHhsmbVduHChdE+q+0vL5Jkww9RmMC17YWGh\npDNkP7VTzcwwIyMjYwgM7Y7XarVKYbYYjVN3GXpmRl6YGFbm3Jv28lJvJIEZHj58uGAUgBGD1eEq\nGydnhKmehOe5joPfUkcbQ5DaoFXpjAZZ9bubpNvzwdTQGXJ+fHy85FFC/XBrgzREl9TPVNPrl5eX\nC12UB+NIvV3qyAyBs3HXC6+srBSMy+0MaZPuxUIAFN+eOnWqtILNc1KbYqkc4ot9Zo1peDkPNM0+\ndsSZGWZkZGQMiaF1hqlFNz09voWM/KdPny7sDLkGTxNnc+xTJj17alvIiE5ZjFLcCxO56667JPV0\nVCSqevrppyX1GMrhw4d1//33S5Le/e53S+oxVnScb7zxxrZCh19rcOaUZkL0wAyeOgG4B4r7ES8u\nLpbSC7guqAquy0xZADpJ4OyzrjrDqtVkkAY9gJW57tB9+5GTt2Pa04ULF0qzCdcZur4Rplhlu7i4\nuFhKIHcpyMwwIyMjQ9sM++9+ve6DOjIyUsqJCjzkkq8eug7owoULJd2ke5aw9dVDRhzX/01OTha+\nrPjXss/zV1dXa8kaQggaGxsrZMo3gAmgh202m5W2Zh4qy+Xm1gGLi4uFThC5s+8MhLJ5D57tjCVl\nPp6wKtWV1VHGwFeTB622V6X3dJtE9292r7Tl5eWSLDezXWTr3i3+DKls/5xaG2zVBz0zw4yMjAxt\ngxkuLCyUmJoHWZ2cnCz0eow+sDRP7AN8BQn9wvnz5ws24P6xMFQPCe9swa3SO51O5WpxulpZx1Sh\nDtebDmJSvsLrXiJuX+iBfFdWVkrRRpCt+yo73JJgUAQWDwibxkiss3+yw3WqqU2xf1f3CnGvEfcW\nSTEoOs5G8PqVPstTOnjd6na7W45ZmZlhRkZGhrZhZ5jOv+mFGflhfYcOHSqiiDAKMNLje0wvz8ju\nngScbzQaRa/vEaxZTXa26e/D6JHqL1jlgi1yT+oLW0dm2G63NTs7W9htVa0AhhAK+buHicc+TD1N\npJ6sU39S1xuBzew+q1hFGj2bOsjsBH1kqo+uI9zOELmkujnajFt0eLh/Yg74SvCg9KxVEW6qtj5r\nTJki/3uKB/ZbrdaW2/G2jK6poPxgstLRGObm5gpTFQ+m4MpMXpSXp4NLO0X/wVzjuVfY5xmY9zz7\n7LOS+l283FSAzrrOAT+lcmoHvodPi0ZGRorKTOeHHFiMojNki0zduHdhYaFkiuGdlMvFp82eVbHV\napWmxR5QYmlpqdadIUgz2KX7KysrxbeibbnRvafeoDP0HMzj4+Mlkyo32HbzKp5dpVqTysF+B+1D\neDZDniZnZGRkaJvTZNicu+akwRpRlsPOCKLgdBvA9nzak7qGbRaUk5ENI3DCcvm7pCOeb1PTgTqa\nXZABESbm3zp16vcpCaoRth62HTl6+P3Z2dli6urT8jTb3UYYZFrB+7kCPTUhqaOMpbXv49/MQ+Sl\npjAe/syDLjgzdFXV+Ph4KaRalRsgz2DqXRUwZaMMf+k1Ww3SnJlhRkZGhraREOr8+fOV+htG8cnJ\nyUK5zrFbbrlFUm9UQEfkxrxcnwYATVMXSj32SFlvvvmmpJ7ZB7oIykCnySh19uzZYiEHXSZ6rcvh\n1vOtDJhh1YJFqmxHxrAE5OBpRd2Y1/NaS2UjXVCVuzoNJy+VFfWDAsaCdCGujotkMUatrKwU38FZ\nlbMrqScfmDsBGJgF+HVbgbte0hZhlVUBWNJnUD+4x/MnbzVNqJSZYUZGRoakba4mVwVZBWnPzShD\nEFVWbRmN0BWhM2Skgc3t2rWruIdenhVHwvvzfFgFZQ0KYy6tmXJ4yB/0immg0jrqk9rttt58882C\nsXuq0PTbIjtW61w+yBLWXeU2OTExUTKfcj0f+iMPJOuuZBsls3IdVR3lK5UTQjlTTwNqVOnbPBxa\nlZte6lJXVZYn6nK3O+CsM01l6uy2ykh/I2RmmJGRkaFtJoSi13V9CyPumTNnikCMwEN2oW+i92fO\nT6gv7BQ7nU4xYjCSszLN1oOIohtkVdnTA6QO6L6yOSjhUZ1A2H9GfE8Sngbp8NVarkFfg14Wu0NP\n9D4oRBrfPHWdTOH6o6owYt1ut8/IftC23W7XUsZYhbhe2C06RkdHS66VHuSVMjy81qDgyb624Anq\n6RO87I30kJdTfpkZZmRkZGibdoZuh+Q2RxcvXixWFl988UVJvURLjDSuO0QnhK4wXYmk93ddIMyQ\nZ8BEKOvWW2/te79U30SZsFvXZ9R1pRG4AzxIbQU9UId/Q/cAYYsukbInJiYK2cISgHuWIENPNcHx\n1LuhSmeYBh+oq94whadhpe3t3bu3mLExy3KPkyrvENhlGqyDtk5Z7PMM6gXtl7I9CEdV6LhLRWaG\nGRkZGdoGM0xHXMCoTo9/6NChkj8qqUPRC3APq7h4ixw9elRSb7Q4depUwewYjTz4A54lJ06c6CvT\nw/mAZrO5oU2VVN9ADSMjIzp06FBphRHdKtuVlZViBK+Ch39CD5kG0E2vk3osk2uqQka5jdygkFG+\nSuk6w263W2tm6CuwHnLt8OHDlYzQ2ZsHYk1ZP9dTvssqDfCSPsNZ50ZJ2ly3vNWwXSkyM8zIyMjQ\nNu0MAb0/IwkrwIuLi4XHCfZ86BA97JavNMLqUp9G1+txjrI47zoiX5Hk/PT0dPEcGCyMBBa6VX/G\naw1jY2O66aabSro79LGwuZWVlUrdjSeP99V+1zW2Wq2+kG1SjwW4R4rf68dBqmv251fdUxeQ2qGK\nEaYzPGdr7m/u9cSRsr8qTxfas7PONOKNVA7yKpXTEbgH2TB64XrWhoyMjAzD0MwwjWQBM6Mnx8sk\nxqh7771XUo+1vfbaa5LKgT+5521ve5ukHrtMR3F6dkYsj1vISrWnlYSVukX7DTfcUDBX7nUPiLoC\nnaGnUvDE8Ol38kQ/rkt0/c0gX2FYPH6qW41e44wSpDokt4NM37uOOkMCJqNTdwaWWhLA2nzr9oXI\nDf19mtCN6311uEpvX5X4aVDwV7dsGVQ/t4rMDDMyMjI0JDNst9uam5srRnZ6eNc1SL2E7hyDpbGP\nPSHMjC0MgJXhkydPViZ9gV2i12BUglXwTA8fft111+n222+X1EsV6mHn655G0j0P3NNjZmam0nsH\n1uDeCrBNL2t1dbXEDNn3lA2u/2VLvUlZ52YeKHVdTQ4hbOi7O8gzCLieGB07Nr9Es2EfOaaWHbTD\nqvSi7s0C3LtlcXGxxBarfNu3gswMMzIyMrSNVKGLi4vFyI+dH9s0twQ6HFaI7r77bknlRDG+Muw5\nSTqdTnEt18BEAWwCMCoRPcV1i7fffnspCjbXOvOoGzqdjs6ePVuwOFb5fTVxeXm5sBAgeg1MEcDW\nPL4hSFf9+f5ug+gskns8yjbXpbZonvuEbRrhpo62pB61hm+Gzj1dKfYo5c7W0A2+9NJLklTEJPBo\nNnv27Cna7WYeJe677uyTZ87OzhbP2SjJ/VbZ/9CBGrrdbvGjeMlHH31UknT8+HFJ/cl4aADQZBoT\nnSVlMMU9efKkpN7H5Yen19JRMuV+8MEHJfU6XKh5VaDQo0ePlkJ2eeKb6enpbYUB+lbHysqKXnzx\nxaLCekg15NdsNosOiGt8IQX4AEMFphN94403SmZQPmj6tBh4srA0pJO78KUJwdJn1A1uIufG8Wkw\nXs+C54sdtE+mx94ZUub+/ftLHaSrUdj6gg6gM6SvOHv2bNGBU6ZPj4dxq83T5IyMjAxtw7QmHZk9\n7D4jfaPRKDneVzlVUx5TGE8M1Gq1ihHCTSRcMe9O/b6ED9rtdskwm5EFhpEaidYJMEO+Id8O9pca\nzrpBrhtMpwmfpN7IjgE35lYnTpwozgFkRxluQuP5tWGQsP80568nFAO7d++upeE1AVc8Dawzt4WF\nhU3TdaKighGyaMl9fPuLFy8WszFfVHHj6ypja+pI+ize2WcMaYDazAwzMjIyhsC2FlDosWFzrhBN\nld7u6E+PTW/NKFFlprG6ulqU4SHD2DoDdD2S4+LFi0VZ6B8HuZTVUbkOYHNPPPGEpHLqx127dunY\nsWOSeiZOzuA9vSRlErQD3U+68EIdol6wrZoFVLH3NKAI9dEDd9SV/ZP0C7i+LTVX8WRs7iaJfGCE\nyJp2lQbJgMVRl9xtsyrYK8dp79Sj1LQmTVTmyMwwIyMjYwgMrTNcWloqeupURyj12FWMseR64yzA\nV5M9QZOvHEvlEcVXGDcyFk2vO3fuXCnJlI9kdTXI7Xa7WlhYKJgzMnbd3MTERGE94CYTjNZ8W08J\n6Tq8TqdTCjnP85Fp1eheFWh4eXm5eHd0lLAY0G63L3uA0G8FMMOrMkxO2xPf0wNjuMF0ldEz+xcu\nXCi1U0/zSrt2t0CYorPRlZWVSgsGMIxFSGaGGRkZGdqGznB5ebmUTMmZ2vj4eDHCM+KjS/AUjx7W\nyVeWms1myR7JdYPAk8gD9jmfrpKlIanS/aWlpVoaXjebTc3MzJRC9ruB7NLSUjFCw8CAG8JSRmoh\nIPXbBqJ3TFcBBz2XZ/pqMttU9+y6yjRoAKijjNPAGOxL5Xa8srJSWm2vYlpV16WMMU3Vm17jTJHr\nmK158IVBdsRVus1h3GozM8zIyMiQFIbRi4UQTkt6eede5y2HW2KMh672S1xJZBlf+8gyHoyhOsOM\njIyMaxV5mpyRkZGh3BlmZGRkSMqdYUZGRoakHegMQwgHQgiPr/+9EUJ4Ldkf27yEbT/3IyGEp9b/\nfiE5/o9DCE+EEL4WQvijEML1O/UOdcHVkHEIYTKE8Oj6M54OIfz95NzfCSEcDyHEEMLMTjy/bngL\nyvi319vw10MI/3sI4bLHX9vRBZQQwsckXYwx/lM7HtaffVmMvEII90n6bUnfKakt6Y8l/XSM8cUQ\nwp4Y44X16z4i6dYY489fjudmXFEZNyTtijEuhBBGJf1/kv7bGONjIYT7Jc1K+gtJ98YY5zYqK2M4\nvEVknLbjj0s64e9zqbhi0+QQwu0hhCdDCL8h6SuSjoYQ5pLzHwghfGL9/+tCCJ8KITy2PlJ85ybF\n3yXpyzHGpRhjS9KfS3qfJPEB17FbUl4+3yHspIxjjN0YI2GWxySNal2WMcavxhjrZCpy1XAVZUxH\n2JA0oR1ox1daZ3i3pE/EGO+X9NoG131c0q/FGB+Q9H5JfNwH14Xg+Lqk7w0h7F+nzz8g6SgnQwi/\nGkJ4db2sj12WX5JRhZ2SsUIIYyGExyW9KekPYox/dXlfPWOLuCoyDiH8e0lvSLpV0r++LL8kwdBh\n/y8Rx2OMj23huocl3Zk45+8LIeyKMT4i6RG/OMb4ZAjhn0v6nKSLkr4qqZOc/yVJvxRC+HuSPiTp\nH1zaz8jYADsiY0mKMa5Kui+EsE/S/xlCuCvG+I3L8tYZw+CqyDjG+JMhhKbWOsL/QtJ/uNQfkuJK\nM8M0m0xXUhqKJM38EyS9O8Z43/rfkRjjkjZAjPHfxhi/Pcb4PZLOS3puwGX/UdKPbfPdM7aGHZMx\niDGe05oq5Psv+W0ztoOrJuMYY0fSf9IOtOOrZlqzrnQ9F0K4Y10P8L7k9OckfZid9QWSDRFCOLy+\nPSbphyX97vr+Hcllf1PSM5f67hlbw+WUcQjhcAhh7/r/u7XGOrIsrzKuhIxDCI0Qwq3rx4PW2vdl\nl/3VtjP8RUl/KOnzkl5Njn9Y0nvCmknM05J+VtpY1yDp0+vXflprK1AsnPz6usL3CUkPSfrIDvyO\njGpcLhnfKOnPQghfk/SopP87xviH6/d8ZF0nfL2kp0II/2bnfk7GAOy0jJuSfieE8HVJT0jaL+kf\nXe4fkX2TMzIyMnT1mWFGRkbGWwK5M8zIyMhQ7gwzMjIyJOXOMCMjI0PSkEbXo6OjkRwDUjl3Lfth\nQCYzFmo4x77nLSHPwaCFHS+DbdVzud7L7Ha7W8qXu7y8rFarVavkyePj43FycrJSDqnMXZbscy95\nKchV4RnTQFqW50BxGXqGNX92er/XS7ZpXpdWq6V2u10rGR84cCAePXq0dBw5kavm4sWLRR6SqsyT\nyMPzoYM0A9+gfkHq5a8hAx8y9TxKe/bs6btuEDwXiySdOHFCZ86c2VTGQ3WG4+Pjuu+++4pKTqIm\nkvmQ2m90dLSU0GejpDNSL8mLp+zsdDqlxNWeYpCP4x/Jkz2RWGZlZaVIRr5Rp/jYY1sxsr+2MDk5\nqfe+973Ft/JUjCTlmpmZKSor9YF9GhOJmF588UVJvXSxJOPi+snJySKRD3Ih/Sj1hDJJ+ORpRymL\nujgzM1OUQT2lvvAe586d00svvTTE17k2cPToUf3Jn/xJ8e1ok6+88ook6Stf+Yok6Utf+pKefPJJ\nST1ZOmivyI1vDF59dc3SZmRkpNTWeO6BAweK95J6MuX4O97xDknSww8/LEm65ZZbius8KRxJptLj\n73nPewa+u2Nod7xOp1M8iJ760KG19AJTU1OS1ioyHZNnuAL8YCo1cMaYgobIB2fE4Dgfgnu9ox2G\nsdYVIQSl7B9QkelY9uzZUxqFuYb6wYCGnLxOpMwN2XEtjYuOc9CIn4JnplkWPf8uz+A9RkdHK9nK\ntY5ut1ti6rST119/vdiS+ZBzyIxvyZZvjNwAg9Pc3FzRHr3zu/nmm/uOe/0Anuc5zd5XVRelakbq\nyDrDjIyMDA3JDEMIGh0dLUbhlCVIvZ593759xajMiOK5T6uYok9tR0ZGinv27dsnqTeFchbB6MQI\nwjOYWjGKLS4uFqOP6698Gl83NJtNTU1NFbJ19Qbf+rrrrisxLrawCc6zD8tjyks9mpiYKMpllnHd\ndddJWpvKSr36wXTNdc0+W9m7d6/2798vqVdPAM9aXl7elHFeq+h2u6Uc5siHb5zmVnaWBrumndMm\nuY7zyODs2bPF82CLb3/72yVJt912m6Se7Kgv9AHIy3M2p78B+Xt9HQb1rAkZGRkZhqGZ4fj4eDHS\n0sMzih85ckTSGkOkV+daRnB6crbo++j9GWm4/ty5c0X5t99+u6SeroFRx1mcj3SnT5+W1Bu1Xnvt\nteJ5jH5cy3uNjY3VUn8YQhi4WseonC5w8L8vULAPQ3/ttdcGXpfOMJAlsr7pppv6yjh79qykXr3w\n1U3emfq2f/9+HTx4sO/dvV7s3r27lswwxqhut1tamfcV+0ajUciD2RWsnu+MTNlnZoeejvbdbDaL\ncmH/6ApvuOGGvjKAs/1B512P6DO7YeRbv5qQkZGRMQBDM8ORkZGSXRBsjv10WRu9XVUP7vpH2Ea6\nKgVruPPOOyVJd9xxR981jGyMSrA7GAD6jJTJnDx5su/96sgQBqHT6ZRW+CWVTBimpqZKZhS+sgcj\no36wRdZsDx48WLCEG2+8UVJP5pjBgNQ8atAzU52m67HQRaUroHVdTU7hLIrvtWfPnkIO1AlYPm3N\n6wAzLdokMp+amipmWocPH5bUkwNl+uzx2LFjknp1gbK4r9lsFjL1mQL7mRlmZGRkDIlthf3fzPOj\n2+0WIzdbdA3OCNEDMBqxIs1oNTk5WegiWXVCd8gIgT6DFWKeAfNI7coom3tgj27s3e12a6kz7Ha7\nWlhYKEZnwDdMvy0sDPvSKrhtGmwC5nbo0KFCRwgzpExnHrwXcnLbQe47ePBgaeZAHUzfo64zgiqP\nEqnfAwR9Hm2JlWbXDQKYGt8VVsf6glRu4xjloxeGOb7tbW+T1NMx+uxkZGSkxGYdw1iFXFIOFFfA\nptNTOhtMI+gU3XjX9wFljY+PF0pcPgoKVUCHhoAcNBSUufv27SvKOH/+vKReh0pFaLfbte0MFxcX\ni2/pUyjkuLq6WsjOFybY8m3djMqn0VNTU0WjoYNMp0LpM6hrNEKfeiPX1AOF5/M+eWq8hqoOkYGm\n3W4XbcbdHd1ljvNeb5DHvn37imN0huDNN9+UJL3wwguSegQpHdjS96WckZGRop5s1iluBfUcFjMy\nMjIMQzHDGKNWVlaK3hj2Bltg5F1YWCgYoTMuRnJ6cjeJcFc7qcfoGOnZd0bIVJcyGa2chXa7Xb38\n8st9z+G9PNhA3cA0GXaAbAFTzYWFhdLUGQbGNdQHynAmQj1KTWt8yl010sNIXN3C/TMzMwUrQaZu\ntNvpdGrJ/t20xoG8FhYWSu3VFzFczQXYR66zs7NFnWLKzD7tFhM4ns+zaO9ujD0yMlJpjuPmVFtB\nZoYZGRkZ2gYzTF1ggCuhV1ZWCtYGM3TQo1cpsFPzHUYIenlGEso+c+ZM37bKhCM1FndDTh/Z6soM\npX4DWeAybzabhRkFDJCR3pkhjHFQGdJaHXCdj5tiuZmO64GZUaQzC49g4mHJlpeXa8kMJW3IDH2R\nSup9d9qLy8ODcaQRiaT+du46Y2YM1Cc3l0l1mLw7z/YAHR62bRhkZpiRkZGhbTDDdrtdCtXkztmr\nq6slY9iqUQh9juuf3ExGKodzYhXqxIkTkno6B/QUbqwJaxgfHy90S7BGX7avq2kNwThcv8e3SNkf\nzNzd7zDQhRnCFKtmFM1mszTC+zVulgOqmOHo6GhppRGk+tA6zwCcATobX1paKtgaFh2YK9HmPFgK\n39pddhuNRtF+CRHm7RPzKvZhiL4WkDLKQeY26XtknWFGRkbGkNhWcFfgNoKp3sCNmhmFPNyTs8vi\nxZIoyvTyrBq7SxbP8OjMbiOXsoyqMOUeGqqu8ND9g1aCucZDpg3SOUn9Ibuk/pHe9XpVKQK4l+OD\nVoi538vw1cvV1dVasn+pny1XBWpYWloq2jHMEHhketq+pwHgeAihZHVCmViJEIAFO0TaO4beKcuU\n1upZFfvfDjIzzMjIyNCQzLDVaunUqVNFj+02eqkdETo5t1NjFdfZJPdSNts33nijGLkI7nr99ddL\n6jELRhZsG9FRAfQZ6CjOnz9flEHABt6H9x4fH78ka/ZvZXQ6nVLCJeQz6JtwrbtgukdQVb6KZrNZ\nqdejbNdLexkgZYHOWJ25Li8v11pnyLf0oAZpAi++mVtwsEV36MGZfQ1gfHy8+J/n0RegK6Tt4QII\n0DEiK9pxo9EoWZp4XpdWq7Vl9p+ZYUZGRoa2EcIrtUFjtGD1MPX08BGiKqOdp290vc7CwkLBHhmN\nPHMacBs0DySRrjDBXngObJKRsO7eCR5E1XV0e/fuLUZyz5LnnigAuaATQge0e/fu4lrkgp7IZxau\nc+Yd3BMhfbYHdUh1l3UN1CCVvTRoP6mtntv2uU6dEGseFAX2Nigwq6d9IPAKoF7QNvEW410oc3p6\nuqgfrh9O9YqZGWZkZGQMgW0xQ18VYk6fhvT3UF2etMlZnOsMU1s1rkUniG2Zl+Esget4hzTZFGW5\nDzWjkVRfL5ROp1NagfU0DWmILL4vMkuTkEs9OXnSJ0I17d69u7gWGblXi9sbuh0bbIHr5ubmSh4M\n1Ir7w8sAABCWSURBVD2uXVpaqqVeOITQ5/XjfsfIac+ePQXjQ+5s+YbIC/YFI0QnT1ljY2PFjAFZ\nI0sP1UVde/755yX1+hdPITI+Pj4wEHGKYeyFMzPMyMjI0DY8UDqdTjEa4PHhrK7T6ZTC96eJYaSy\nLhG4LeH8/HzBPNAjoXNipGCU8vDyrD77qtnc3Fzhx4yVOyMMo1aj0agtM0zh3yDVt3myeWdiyBCd\nraf1BK1Wq2DmHi3HV5MHJYJPt7zvyspKSe5VoeHriGazWfII4hvCtqempkptzJk47YiyaHO0Ucpc\nWloq6YWRD/aG2Bl6IjePpZm+d1UM09THfavtODPDjIyMDA3JDLvdrpaXlwt9jidiT0dxH2XQ17ie\nwkOywxAIAX7mzJmi97/lllv6nuexED2htK8wMuJcuHChYIKu54LNuA9snZCy9Spf4Y1YlSfoojyX\nccoQ/TnOCD0aiV/vdm6pjZzbQfIei4uLtWb/fH/Xy6a2tt6WmOm5fTB9gaf9TK0DPH0wz3H7Rspi\n5uE+zDwzjbtZ9duGWU0eeprcarWKl6WSeWfU7XZLIZbYcpxr6VhZoidT1qlTpyStfUQ3tOWH8nHc\ntCOdKkn9H49n+jSszlOmrcCntlL5m1Xlr/bpM9+ezmpsbKwU7NfdJX0BhS3n/f3Sd6tKT1FX86lG\no6Fdu3ZVukumxvMMXG7iRB/gGQfvueeevutozxcuXCg6P/Lc0H6/+c1vSpIee+wxST35YELn5jmc\nR6WV4lJUIXmanJGRkaFtBGpot9vFiOILFmmOVDfC9FzGHs7Hw3Ax8kxMTBQmGChn0+V6qTfy+yjm\ngSY9TYFUneGvzhgUjANsJ/GOBwBwc51Op1M5HUeGHqLL00N4Lu/R0dFKNsk1Y2NjtZQ7+c+BL6Sk\nU1/USB4MxbNJekh/vj3te3V1tS85lNRjdo8//riknikNfcd9990nSUV2TDefWl5eLs0IXI2Tja4z\nMjIyhsTQzDDNVZom9JF6Pffk5GSh9GTkZSRhFGKBhJEDnaG7cB04cKBYOMEo0xdGXH/BKOYhyd2Z\nO32/yxE2/FqGM8HUMBv4N3Tzl6pArRMTEyVjfDeVQbmO7FwJT91Lg/aip4Yl+OLY7t27aylngjR7\nMAyA/DqdTmkRyvWv7uLoix2Yw7VarVIKAMxyYIRPP/20pF47x03P1x3ShRRfNL0U1K8mZGRkZAzA\n0KY1i4uLBRPE5ebWW2+VJB07dkzSWkgejC5T9yipxwR91dhZBiNSo9EoRirXHaJzeOmllyT19I4w\nQxgA9/FOu3fvLgw9PUhl6rJXx5XGzTDI7MbNXzzFI3LwAA0kB9+/f3+hB6ZuuWsYx9EpUybnYYSp\n6QfP91XT1NXvcjCKbzV0u11dvHixNFPyYByprKvYPt/YE74jv1SPnxpgSz3WyCyRa6kfXO+ryWkQ\nBnA5GGJmhhkZGRnaRqCGRqNRjMqur4Gx7d27t+jFCYRA8qZXXnlFUo8RMko4q2B02L9/f8E4KZ8R\ngxEf3QOhfigzDfUj9UaWXbt2FYyQ3+ChxaqMOa91eIJxN34eBHeVc0bGPvKDqcMiDh8+XMjbA3p4\nuldPUen6pHTrRrr8JhjJwsJCLQM1dLtdLS0tVaZnoJ1g55deQ3vx70ZbY+UXlsdMsNlsFjMtt/9l\nNsaMztOR8ixmc5SZssBBtqvDIjPDjIyMDG2DGY6MjBQjRjqySz3L8uuvv74YhVklRtcDi0Nvw3U+\nslPmsWPHihHBV4VhgJT96quvSuqNMOg0b775Zkn9bIORC4bqtoucryuqVtdT/aCfq2JtsAnqDQwx\nDeXFMVYjnQkCGIDbDHo6id27dxfy9sARaViqOq4mO9yiAsY1OjpaSuXAN3Q26e6rzLywU4wxllae\nacceDJh27QyS42xHR0dLgZxdz5/tDDMyMjKGxFDMsNFo9NkQMrKzTX0JWT32VWJGIUZn1z96cMh9\n+/aVbM48EIBbxfvI4mHNp6enS+/uIewzY1hDFUMk0G96zlOB8t09nBtb6svevXsLuTPb4JyzujTE\nmjTYZlEazAx99lH3sP/OBN2TrNFoFG3N25T7KnNPVfrebrfbxzg3gj/D7YjZHxRmz72dhkF9a0JG\nRkZGgqGZ4e7du0sBW10X0Ol0SuG9YIIwMUYlX7lKV6SlNRbhdkXO3mAA/h4+8qUMJvWWSd8v1UHU\n1W91dHS0FIh1kI/wID9QqT9EVgpnc2BQSkoYICuH6IOxGPAVbOSX2h3yv68iow9eWFjI0YoSUN9T\n+XgEKPRvyNrTMLj/Odc3Go2STpm6RVtkduD1w+0SU2YIPJWtM9etIDPDjIyMDG1jNdlDvUvliDTd\nbrcUQYbeHp0QOjqYGUzQ/Q+lckDPqq1HJ/GYeCnLcbZYZ91RCmxJ3eOgKmqMVNbrsaU+VLGvlEV4\nSHjuhRH6Frg9YjqjcGaKBQN1s67BXbEldXig5aWlpVJUGtpNaoMo9ewLCe5K+bfddltRpnuSkDz+\nne98p6SeNQplwxQ9+GyaXjhN/5tuU3aZV5MzMjIyhsC2PFCqIhcz8i4uLhbX0HO7ZwGjhKcS9RiF\ny8vLJZ2hJ4r21TBWmd32KGUwnhQbDPLLrBvStA0enWQjfRJ6PuoBW5g5q4FsOX/69OmCBWAzyj46\nw5MnT0rq+aEDj6ieekW5xxKMB91T6p9bJ8QYtbq6WorzSftI03p4rEPaGLa/tBNseWGGyAPW9/rr\nr5cSOvH8u+66q2/rdY/6knqlAX8/xzC6/8wMMzIyMrSNeIapj6FHjkbP02w2Szo5ty1jhKEsz32R\nJodJk/ykzwW+SoXOirLcY2V8fLwUH89HxzoyBqm8msw39HiD3W63ZOeZ5piRegwMwNTxV4cFzszM\nDIxkI/U8hPBkIjIRcGaI7nBqaqpgL7w774lXxPz8fG1Xk4lpmGJQnXfbQPR9HtHa86d4xKjz588X\n9eLFF1+U1JMZsmbLezELoF7xLHSNUi/iTVWisGEw9DS52WwWPxT66a4509PTmyZx8qmvNygazNzc\nnJ599llJ0gMPPCCpFyrMO1qCwCIQjqOYpaHMzc2VOkHeFyEvLi4WwSXqBGRc5WqXws0oqhzwBym1\nU4yMjBTP8xBePhBWBRl1VUir1arMnphmQsxh2vrNX6T+xUx3WPCMdp6+46mnniruTc/Pzc2VVB20\nefIl064ZrJ555hlJPRnTWaZBe33K7XVydHQ0L6BkZGRkDIOhg7uurKwUvb0b16aGsPT69Mqef9V7\ncuAuOIuLi8X/mFU4NWefKRaA5aWufVxPwAh3Dk/diOo6VZbKAVuZBaQh4d2cYTN1hs8g0nBp7owP\nA/FpLOySeuLsM1VzwCD8XOoiVmdm6CG1PNf5zMxM0R5cJYYKBEYIm8MoHhaXpgLmnMua488991zf\ncRZOmNmB1LnDp/HeJ+QFlIyMjIwhMTQzZKSQeno9euF0UcKDpHrgT9cdAkaFVAnPaERgWO5JmZ7U\nG9Fgn5xnm7JRfgfmIBjipq5adWaGYCOnete7Dkq4laIq0Mbo6GjB0NHzOuNzXaGfH5Q2AllyLUhZ\nZV1lPOh3u36Y9ABSjwnSLmFt3m5geczSaHNLS0sFE6V9so9ungU1Zh/oLjHXoUzec35+vuhPPFgI\nGB0dzcwwIyMjYxgMzQyXlpZKTtCMMowic3NzpdD87DPye7ggzlMGOr3Z2dmSqQz3wEDY96TxXO/u\ngouLi8WSPKMRW0a8OrtqDUrqPijRjptYVelynZm5C1XqjoeMPIRXld7P60DKbtBjeRKjNFBpHWUM\nqn57GpyX2Rj6vJTpSb06gNz45jBIrAPS+kP5MDYP90XiMPSOuPQR5CU1g/Pyq9YitoLMDDMyMjI0\nJDOMMWplZaWkp/Hk3Hv37i0ZYcLSWCX0VWXOM/Izwpw7d67kxsM1jCiMIK5XAh7k9fz584Vug5Sl\n6ETSpNl1Xml0uB5wI3fFzQxgXT7tdrvEFpGlb10/6QEE0vthpC7H1BaxjjImUAPtwuWEHu7666/X\nN77xDUnSk08+KamcrMn1cXx/1hNoo3v27CnafvoeKZAtzyD4A3aItPM07D99zkb1MesMMzIyMoZA\nGGZkDCGclvTyzr3OWw63xBgPXe2XuJLIMr72kWU8GEN1hhkZGRnXKvI0OSMjI0O5M8zIyMiQtAOd\nYQjhQAjh8fW/N0IIryX7Y5uXsK1n3hJC+EII4ekQwlMhhJ9Pzn17COGR9ef/ZQjhgZ14h2sdV0mu\ndyfPeDyEMJ/Kdv2aXwwhxBDCjB3/ayGETgjhR3bi3a5FXA0Zrz/3t0MIp0MIj9vxfx5CeDaE8EQI\n4ZMhhL3rx8dCCL+zfvwbIYSPXpYXiTHu2J+kj0n6uwOOB0mNy/icGyXdt/7/HknHJb1tff9PJL13\n/f8flvS5nfzNdfi7UnK1skclnZJ0U3LsmKTPSnpV0kxyfETSn0r6Q0k/crW/17fi35WUsaTvlfRu\nSY/b8e+XNLL+/z+T9I/W//9JSb+z/v+kpFfSerHdvys2TQ4h3B5CeDKE8BuSviLpaAhhLjn/gRDC\nJ9b/vy6E8KkQwmMhhEdDCN+5UdkxxpMxxsfX/78g6RlJRzittQ5SkvZKOnl5f1m9sZNyNbxX0jdi\njGlGqP9F0iBW8N9L+l1JZ4b+QRkl7LSMY4x/Jml2wPE/ijFi4PplSUR1jZImQwhNSbskLUuav5Tf\nKF15neHdkj4RY7xf0msbXPdxSb8WY3xA0vsl8aEfXBdIJUIIt0q6V9Jfrh/67yT9yxDCK5L+iaT/\n8dJ+QsYA7LhcJX1A0v/GTgjhxyS9EGN8Mr0ohHCzpB+U9JtD/4qMjXAlZDwQYc1q+qcl/T/rh35X\nUlvS61ozEfrVGOP57ZSdYuiw/5eI4zHGx7Zw3cOS7kwsx/eFEHbFGB+R9EjVTSGEPZI+KekXYowX\n1w9/WNKHY4y/H0L4L7XWSP7Gtn9BxiDstFwntNbBfWR9f0prjPDhAZf/C0kfjTF2t+p5kLEl7KiM\nN8Hfl3Qxxvi76/t/TWts8Iik/ZK+GEL4XIzxkmwnr3RnuJD839Wa/gFMJP8HSe+OMfZ7+G+AdQXv\npyT9uxjjZ5JTPxFj/ND6//9J0r8e7pUztoAdk+s6flDSIzFGpr23S/o2SV9fb3TXS3oihPAuSQ9I\n+r314wcl/fUQQifG+H8N+cyMfuy0jAcihPC3Jf11Sf95cvi/kvTZGGNL0pshhC9Lepcu0ZD8qpnW\nxBi7ks6FEO4IITQkvS85/TmtMTpJUgjhvo3KWqfRv6U1BezH7fSbIYTvXv//YUnPXuq7Z1Tjcso1\nwd9SMkWOMT4eYzwcYzwWYzwm6Q1J74gxno4x3pwc/7Skn8sd4eXFDsm4hBDCD0r6HyT9cIxxOTl1\nQtL3rV8zJelBra0TXBKutp3hL2ptxe/zWlsRBB+W9J71pfOnJf2stKHe4Xu11mDem5gCfP/6ub8t\n6eMhhK9J+hVJ/80O/ZaMHi6XXBVCmJb0n2mtY8t46+Byyvj3JH1R0t0hhFdDCB9cP/WvtLb4+fn1\nNv2v1o9/XNL+EMJTkh6V9Bsxxqcv9Qdld7yMjIwMXX1mmJGRkfGWQO4MMzIyMpQ7w4yMjAxJuTPM\nyMjIkJQ7w4yMjAxJuTPMyMjIkJQ7w4yMjAxJuTPMyMjIkCT9/xc7e3kzIVi7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e582f520f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    #assert len(images) == len(cls_true) \n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(image_size, image_size), cmap='binary')\n",
    "        \n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "# Get the first images from the test-set.\n",
    "images = train_dataset_norm[0:9]\n",
    "    \n",
    "# Get the true classes for those images.\n",
    "cls_true = [\"{}{}{}{}{}\".format(str(a_).replace('10',''), str(b_).replace('10',''), str(c_).replace('10',''), str(d_).replace('10',''), str(e_).replace('10','')) \n",
    "       for a_, b_, c_, d_, e_ in zip(y1_train[0:9], y2_train[0:9], y3_train[0:9], y4_train[0:9], y5_train[0:9])]\n",
    "\n",
    "print([\"{}{}{}{}{}\".format(str(a_).replace('10',''), str(b_).replace('10',''), str(c_).replace('10',''), str(d_).replace('10',''), str(e_).replace('10','')) \n",
    "       for a_, b_, c_, d_, e_ in zip(y1_train[0:9], y2_train[0:9], y3_train[0:9], y4_train[0:9], y5_train[0:9])])\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "valid_dataset_batch = valid_dataset[:batch_size]\n",
    "\n",
    "num_conv_layers = 3\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36        # There are 36 of these filters.\n",
    "\n",
    "#Convolutional Layer 2.\n",
    "filter_size3 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters3 = 64        # There are 64 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 1024         # Number of neurons in fully-connected hidden layer\n",
    "num_fc_layers = 3\n",
    "drop_rate1 = 0.4 \n",
    "drop_rate2 = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare variables to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    #with tf.device('/gpu:0'):\n",
    "    \n",
    "  def weight_variable(shape, stdev_num):\n",
    "    return (tf.Variable(tf.truncated_normal(shape,stddev=np.sqrt(2.0/(stdev_num)))))\n",
    "\n",
    "  def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels0 = tf.placeholder(tf.float32, shape=(batch_size, num_digits))\n",
    "  tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels5 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset =  tf.constant(valid_dataset_batch) #tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels)) #\n",
    " # tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "  def conv_layers(data, weights, biases, input_size,filter_size, num_filters,valid=False, use_pooling=True):  # Use 2x2 max-pooling.\n",
    "    #########\n",
    "    # Conv\n",
    "    #########\n",
    "    \n",
    "    if not valid:\n",
    "    # filter-weights and bias\n",
    "        shape = [filter_size, filter_size, input_size, num_filters]\n",
    "        stdev_n = (filter_size*filter_size*input_size)\n",
    "        weights.append(weight_variable(shape, stdev_n))\n",
    "        biases.append(bias_variable([num_filters]))\n",
    "    hidden=[]\n",
    "    y0 =  tf.nn.conv2d(input=data,filter=weights[0],strides=[1, 1, 1, 1],padding='SAME')\n",
    "    hidden.append(tf.maximum((y0 + biases[0]), 0.01*(y0+biases[0])))\n",
    "    \n",
    "    for L in range(1,num_conv_layers+1):   \n",
    "        if not valid:\n",
    "            shape = [filter_size, filter_size, num_filters, num_filters]\n",
    "            stdev_n = filter_size*filter_size*num_filters\n",
    "                \n",
    "            weights.append(weight_variable(shape, stdev_n))\n",
    "            biases.append(bias_variable([num_filters]))   \n",
    "            \n",
    "        y = tf.nn.conv2d(input=hidden[L-1],filter=weights[L],strides=[1, 1, 1, 1],padding='SAME')\n",
    "        hidden.append(tf.maximum((y + biases[L]), 0.01*(y+biases[L])))\n",
    "\n",
    "    # Use pooling to down-sample the image resolution\n",
    "    layer = tf.nn.max_pool(value=hidden[num_conv_layers], ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    return layer, weights, biases\n",
    "    \n",
    "  def fc_layers(weights, biases, out_weights, out_biases, data, label_count, valid = False):\n",
    "   #  #####\n",
    "   #  # FC Layers - with leaky relu and dropout\n",
    "   #  #####\n",
    "\n",
    "    out_size = data.get_shape().as_list()[1]\n",
    "    if not valid:\n",
    "        weights.append(weight_variable([out_size, fc_size], fc_size*fc_size)) # w = 1024 depth * 1024 FC hidden node layer\n",
    "        biases.append(bias_variable([fc_size])) #  # b = 1024 FC hidden node layers1024\n",
    "\n",
    "    hidden=[]\n",
    "    y0 = (tf.matmul(data, weights[0]) + biases[0])\n",
    "    hidden.append(tf.nn.dropout(tf.maximum(y0, 0.01*y0), drop_rate1))\n",
    "    \n",
    "    for L in range(1,num_fc_layers+1):   \n",
    "        if not valid:\n",
    "            weights.append(weight_variable([fc_size, fc_size], fc_size*fc_size))\n",
    "            biases.append(bias_variable([fc_size]))   \n",
    "        y = ((tf.matmul(hidden[L-1], weights[L]) + biases[L])) \n",
    "        hidden.append(tf.nn.dropout(tf.maximum(y, 0.01*y), drop_rate2))\n",
    "        \n",
    "      #Definitive output  after relu layer's:  \n",
    "    if not valid:\n",
    "        out_weights = weight_variable([fc_size, label_count], fc_size*label_count)\n",
    "        out_biases = bias_variable([label_count])      \n",
    "    logits = tf.matmul(hidden[num_fc_layers], out_weights) + out_biases\n",
    "        \n",
    "    return logits, weights, biases, out_weights, out_biases\n",
    "    \n",
    "  wc1, wc2, wc3 = [], [], []\n",
    "  bc1, bc2, bc3 = [], [], []\n",
    "  convpool1, wc1, bc1 = conv_layers(tf_train_dataset, wc1, bc1, num_channels, filter_size1, num_filters1)\n",
    "  convpool2, wc2, bc2 = conv_layers(convpool1, wc2, bc2, num_filters1, filter_size2, num_filters2)\n",
    "  convpool3, wc3, bc3 = conv_layers(convpool2, wc3, bc3, num_filters2, filter_size3, num_filters3)\n",
    "  shape = convpool3.get_shape().as_list()\n",
    "  conv_layers_reshape = tf.reshape(convpool3, [shape[0], shape[1] * shape[2] * shape[3]]) #[256, 4, 4, 64]\n",
    "\n",
    "  w0, w1, w2, w3, w4, w5 = [], [], [], [], [], []\n",
    "  b0, b1, b2, b3, b4, b5 = [], [], [], [], [], []\n",
    "  \n",
    " # Training computation.\n",
    "  logits0, w0, b0, out_w0, out_b0 = fc_layers(w0, b0, None, None, conv_layers_reshape, num_digits)  \n",
    "  logits1, w1, b1, out_w1, out_b1 = fc_layers(w1, b1, None, None, conv_layers_reshape, num_labels) \n",
    "  logits2, w2, b2, out_w2, out_b2 = fc_layers(w2, b2, None, None, conv_layers_reshape, num_labels) \n",
    "  logits3, w3, b3, out_w3, out_b3 = fc_layers(w3, b3, None, None, conv_layers_reshape, num_labels) \n",
    "  logits4, w4, b4, out_w4, out_b4 = fc_layers(w4, b4, None, None, conv_layers_reshape, num_labels) \n",
    "  logits5, w5, b5, out_w5, out_b5 = fc_layers(w5, b5, None, None, conv_layers_reshape, num_labels)   \n",
    "\n",
    "  loss0 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels0, logits=logits0) \n",
    "  loss1 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels1, logits=logits1)\n",
    "  loss2 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels2, logits=logits2)\n",
    "  loss3 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels3, logits=logits3)\n",
    "  loss4 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels4, logits=logits4)\n",
    "  loss5 = tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels5, logits=logits5)\n",
    "  loss= tf.reduce_mean(loss0) + tf.reduce_mean(loss1) + tf.reduce_mean(loss2) + tf.reduce_mean(loss3) + tf.reduce_mean(loss4) + tf.reduce_mean(loss5)\n",
    "    \n",
    " # Optimizer.\n",
    " # optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  global_step = tf.Variable(0) #, trainable=False)  # count the number of steps taken.\n",
    " # learning_rate = tf.train.exponential_decay(0.1, global_step, 100000, 0.96, staircase=True)\n",
    "#  learning_rate = tf.train.exponential_decay(0.05, global_step, 100, 0.95) #, staircase=True)\n",
    " # optimizer = tf.train.GradientDescentOptimizer(1e-6).minimize(loss) #, global_step=global_step)0.001\n",
    "  optimizer =tf.train.AdamOptimizer(0.001).minimize(loss) #, global_step=global_step) \n",
    "\n",
    "  # Validation computation.\n",
    "  convpool1v, _, _ = conv_layers(tf_valid_dataset, wc1, bc1, num_channels, filter_size1, num_filters1)\n",
    "  convpool2v, _, _ = conv_layers(convpool1v, wc2, bc2, num_filters1, filter_size2, num_filters2)\n",
    "  convpool3v, _, _ = conv_layers(convpool2v, wc3, bc3, num_filters2, filter_size3, num_filters3)\n",
    "  shapev = convpool3v.get_shape().as_list()\n",
    "  conv_layers_reshape_valid = tf.reshape(convpool3v, [shapev[0], shapev[1] * shapev[2] * shapev[3]]) #[256, 4, 4, 64]\n",
    "\n",
    "  logits0_valid, _, _, _, _ = fc_layers(w0, b0, out_w0, out_b0, conv_layers_reshape_valid, num_digits, True) \n",
    "  logits1_valid, _, _, _, _ = fc_layers(w1, b1, out_w1, out_b1, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits2_valid, _, _, _, _ = fc_layers(w2, b2, out_w2, out_b2, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits3_valid, _, _, _, _ = fc_layers(w3, b3, out_w3, out_b3, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits4_valid, _, _, _, _ = fc_layers(w4, b4, out_w4, out_b4, conv_layers_reshape_valid, num_labels, True) \n",
    "  logits5_valid, _, _, _, _ = fc_layers(w5, b5, out_w5, out_b5, conv_layers_reshape_valid, num_labels, True) \n",
    "\n",
    " # Predictions for the training, validation, and test data.\n",
    "  train_prediction0 = tf.nn.softmax(logits0)\n",
    "  valid_prediction0 = tf.nn.softmax(logits0_valid)\n",
    "  train_prediction1 = tf.nn.softmax(logits1)\n",
    "  valid_prediction1 = tf.nn.softmax(logits1_valid)\n",
    "  train_prediction2 = tf.nn.softmax(logits2)\n",
    "  valid_prediction2 = tf.nn.softmax(logits2_valid)\n",
    "  train_prediction3 = tf.nn.softmax(logits3)\n",
    "  valid_prediction3 = tf.nn.softmax(logits3_valid)\n",
    "  train_prediction4 = tf.nn.softmax(logits4)\n",
    "  valid_prediction4 = tf.nn.softmax(logits4_valid)\n",
    "  train_prediction5 = tf.nn.softmax(logits5)\n",
    "  valid_prediction5 = tf.nn.softmax(logits5_valid)\n",
    "\n",
    "  #test_prediction = tf.nn.softmax(model(tf_test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch training loss at step 0: 13.722773\n",
      "Training accuracy - digit count: 2.7%; digits 1-5: 12.5%, 8.2%, 7.4%, 4.3%, 11.3%\n",
      "Training avg accuracy: 7.6%\n",
      "Validation accuracy - digit count: 2.3%; digits 1-5: 13.3%, 11.3%, 3.5%, 3.9%, 10.5%\n",
      "Validation avg accuracy: 7.5%\n",
      "Minibatch training loss at step 50: 6.794447\n",
      "Training accuracy - digit count: 49.6%; digits 1-5: 25.0%, 27.7%, 72.7%, 96.9%, 100.0%\n",
      "Training avg accuracy: 62.0%\n",
      "Validation accuracy - digit count: 48.8%; digits 1-5: 27.3%, 29.3%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 62.3%\n",
      "Minibatch training loss at step 100: 6.640470\n",
      "Training accuracy - digit count: 53.9%; digits 1-5: 27.7%, 28.5%, 76.6%, 96.5%, 100.0%\n",
      "Training avg accuracy: 63.9%\n",
      "Validation accuracy - digit count: 48.8%; digits 1-5: 27.3%, 29.3%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 62.3%\n",
      "Minibatch training loss at step 150: 6.688948\n",
      "Training accuracy - digit count: 56.2%; digits 1-5: 27.0%, 25.0%, 75.8%, 96.1%, 100.0%\n",
      "Training avg accuracy: 63.3%\n",
      "Validation accuracy - digit count: 49.6%; digits 1-5: 27.3%, 29.3%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 62.4%\n",
      "Minibatch training loss at step 200: 5.775805\n",
      "Training accuracy - digit count: 73.8%; digits 1-5: 26.2%, 27.0%, 75.4%, 97.3%, 100.0%\n",
      "Training avg accuracy: 66.7%\n",
      "Validation accuracy - digit count: 71.5%; digits 1-5: 27.0%, 29.3%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 66.0%\n",
      "Minibatch training loss at step 250: 5.535125\n",
      "Training accuracy - digit count: 75.8%; digits 1-5: 19.5%, 27.0%, 73.8%, 96.5%, 100.0%\n",
      "Training avg accuracy: 69.1%\n",
      "Validation accuracy - digit count: 79.7%; digits 1-5: 41.4%, 28.5%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 69.7%\n",
      "Minibatch training loss at step 300: 4.604531\n",
      "Training accuracy - digit count: 85.9%; digits 1-5: 22.7%, 34.8%, 71.5%, 96.5%, 100.0%\n",
      "Training avg accuracy: 73.4%\n",
      "Validation accuracy - digit count: 85.9%; digits 1-5: 49.2%, 35.9%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 73.2%\n",
      "Minibatch training loss at step 350: 3.860456\n",
      "Training accuracy - digit count: 87.5%; digits 1-5: 16.8%, 42.6%, 78.9%, 96.1%, 100.0%\n",
      "Training avg accuracy: 77.0%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 54.7%, 41.8%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 75.7%\n",
      "Minibatch training loss at step 400: 3.658621\n",
      "Training accuracy - digit count: 89.1%; digits 1-5: 14.1%, 49.2%, 71.9%, 94.5%, 100.0%\n",
      "Training avg accuracy: 78.1%\n",
      "Validation accuracy - digit count: 88.7%; digits 1-5: 64.5%, 48.8%, 73.0%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 78.6%\n",
      "Minibatch training loss at step 450: 3.124586\n",
      "Training accuracy - digit count: 89.5%; digits 1-5: 16.4%, 56.2%, 75.4%, 97.7%, 100.0%\n",
      "Training avg accuracy: 82.6%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 66.8%, 58.6%, 70.7%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 80.3%\n",
      "Minibatch training loss at step 500: 3.020878\n",
      "Training accuracy - digit count: 87.9%; digits 1-5: 17.6%, 62.5%, 77.3%, 94.5%, 100.0%\n",
      "Training avg accuracy: 82.9%\n",
      "Validation accuracy - digit count: 88.3%; digits 1-5: 72.7%, 59.4%, 72.7%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 81.6%\n",
      "Minibatch training loss at step 550: 2.860258\n",
      "Training accuracy - digit count: 92.6%; digits 1-5: 19.1%, 66.0%, 71.1%, 96.1%, 100.0%\n",
      "Training avg accuracy: 83.9%\n",
      "Validation accuracy - digit count: 87.9%; digits 1-5: 75.4%, 67.6%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 83.2%\n",
      "Minibatch training loss at step 600: 2.332458\n",
      "Training accuracy - digit count: 93.4%; digits 1-5: 16.0%, 71.5%, 80.9%, 97.3%, 100.0%\n",
      "Training avg accuracy: 87.6%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 79.3%, 69.9%, 71.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 84.8%\n",
      "Minibatch training loss at step 650: 2.182749\n",
      "Training accuracy - digit count: 91.8%; digits 1-5: 10.2%, 74.2%, 76.2%, 97.3%, 100.0%\n",
      "Training avg accuracy: 87.6%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 80.9%, 75.4%, 71.1%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 85.7%\n",
      "Minibatch training loss at step 700: 2.181142\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 14.8%, 77.7%, 77.0%, 95.3%, 100.0%\n",
      "Training avg accuracy: 88.4%\n",
      "Validation accuracy - digit count: 89.5%; digits 1-5: 77.0%, 73.8%, 74.2%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 85.2%\n",
      "Minibatch training loss at step 750: 2.018813\n",
      "Training accuracy - digit count: 95.3%; digits 1-5: 13.7%, 80.5%, 82.4%, 97.3%, 100.0%\n",
      "Training avg accuracy: 89.6%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 81.6%, 73.0%, 75.4%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 86.2%\n",
      "Minibatch training loss at step 800: 1.939781\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 17.6%, 76.6%, 80.9%, 95.7%, 100.0%\n",
      "Training avg accuracy: 89.8%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 82.8%, 76.2%, 76.2%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.0%\n",
      "Minibatch training loss at step 850: 2.124074\n",
      "Training accuracy - digit count: 89.1%; digits 1-5: 14.8%, 82.0%, 80.1%, 95.7%, 100.0%\n",
      "Training avg accuracy: 89.1%\n",
      "Validation accuracy - digit count: 89.8%; digits 1-5: 81.2%, 75.4%, 74.6%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 86.3%\n",
      "Minibatch training loss at step 900: 1.656444\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 15.2%, 85.5%, 81.2%, 96.1%, 100.0%\n",
      "Training avg accuracy: 91.1%\n",
      "Validation accuracy - digit count: 90.6%; digits 1-5: 82.0%, 80.1%, 78.9%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 88.0%\n",
      "Minibatch training loss at step 950: 1.541069\n",
      "Training accuracy - digit count: 94.5%; digits 1-5: 13.3%, 85.2%, 84.8%, 95.3%, 100.0%\n",
      "Training avg accuracy: 91.7%\n",
      "Validation accuracy - digit count: 88.3%; digits 1-5: 83.6%, 77.3%, 77.3%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.2%\n",
      "Minibatch training loss at step 1000: 1.597122\n",
      "Training accuracy - digit count: 96.1%; digits 1-5: 13.7%, 82.8%, 82.8%, 96.9%, 100.0%\n",
      "Training avg accuracy: 91.1%\n",
      "Validation accuracy - digit count: 91.4%; digits 1-5: 82.0%, 79.3%, 77.3%, 96.5%, 100.0%\n",
      "Validation avg accuracy: 87.8%\n",
      "Time: 10304.83s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "#def eval_accuracy(eval_l_preds, eval_preds, l_labels, labels, masks):\n",
    "#    concatted = np.concatenate((np.reshape((eval_l_preds == l_labels), [-1, 1]), \n",
    "#                                (eval_preds * masks) == labels), axis=1)\n",
    "#    return 100.0 * (np.sum([np.all(row) for row in concatted])) / len(labels)\n",
    "#\n",
    "\n",
    "num_steps = 1001\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run() # sess.run(tf.global_variables_initializer())\n",
    "  print('Initialized')\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (np.asarray(y1_train).shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "    \n",
    "    #normalize data to mean 0 and unit variance\n",
    "   # batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "\n",
    "  #  batch_data_valid = valid_dataset[offset:(offset + batch_size), :] #, :, :]\n",
    "\n",
    "    batch_labels0 =  np.asarray(train_label0)[offset:(offset + batch_size), :]\n",
    "    batch_labels1 =  np.asarray(train_label1)[offset:(offset + batch_size), :]\n",
    "    batch_labels2 =  np.asarray(train_label2)[offset:(offset + batch_size), :]\n",
    "    batch_labels3 =  np.asarray(train_label3)[offset:(offset + batch_size), :]\n",
    "    batch_labels4 =  np.asarray(train_label4)[offset:(offset + batch_size), :]\n",
    "    batch_labels5 =  np.asarray(train_label5)[offset:(offset + batch_size), :]    \n",
    "   # print(batch_labels1.shape)\n",
    "    feed_dict = {tf_train_dataset : batch_data\n",
    "              #  , tf_valid_dataset : batch_data_valid\n",
    "                , tf_train_labels0 : batch_labels0\n",
    "                , tf_train_labels1 : batch_labels1\n",
    "                , tf_train_labels2 : batch_labels2\n",
    "                , tf_train_labels3 : batch_labels3\n",
    "                , tf_train_labels4 : batch_labels4\n",
    "                , tf_train_labels5 : batch_labels5\n",
    "                }\n",
    "        \n",
    "    _, l, pred_train0, pred_train1, pred_train2, pred_train3, pred_train4, pred_train5  \\\n",
    "        , pred_valid0, pred_valid1, pred_valid2, pred_valid3, pred_valid4, pred_valid5  \\\n",
    "        = session.run([optimizer, loss, train_prediction0, train_prediction1, train_prediction2  \\\n",
    "                       , train_prediction3, train_prediction4, train_prediction5, valid_prediction0  \\\n",
    "                       , valid_prediction1, valid_prediction2, valid_prediction3 , valid_prediction4, valid_prediction5]  \\\n",
    "                      , feed_dict=feed_dict)\n",
    "     \n",
    "    #normalize data to mean 0 and unit variance\n",
    "    batch_data = (batch_data - np.mean(batch_data))/np.std(batch_data)\n",
    "    #batch_data = np.reshape(batch_data,(batch_size,image_size*image_size))\n",
    "   # print(batch_data.shape)\n",
    "   # batch_valid_labels0 =  np.asarray(valid_label0)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels1 =  np.asarray(valid_label1)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels2 =  np.asarray(valid_label2)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels3 =  np.asarray(valid_label3)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels4 =  np.asarray(valid_label4)[offset:(offset + batch_size), :]\n",
    "   # batch_valid_labels5 =  np.asarray(valid_label5)[offset:(offset + batch_size), :]  \n",
    "    \n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch training loss at step %d: %f' % (step, l))\n",
    "      print(\"Training accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_train0, batch_labels0),accuracy(pred_valid1, batch_labels1)  \\\n",
    "        ,accuracy(pred_train2, batch_labels2), accuracy(pred_train3, batch_labels3)  \\\n",
    "        ,accuracy(pred_train4, batch_labels4), accuracy(pred_train5, batch_labels5)))\n",
    "        \n",
    "      avg_acc_train = (accuracy(pred_train0, batch_labels0) + accuracy(pred_train1, batch_labels1)\n",
    "        + accuracy(pred_train2, batch_labels2) + accuracy(pred_train3, batch_labels3)\n",
    "        + accuracy(pred_train4, batch_labels4) + accuracy(pred_train5, batch_labels5))/6\n",
    "      print('Training avg accuracy: %.1f%%' % avg_acc_train)\n",
    "        \n",
    "      print(\"Validation accuracy - digit count: {:.1f}%; digits 1-5: {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%, {:.1f}%\".format( \\\n",
    "           accuracy(pred_valid0, valid_label0[:batch_size]),accuracy(pred_valid1, valid_label1[:batch_size])  \\\n",
    "        ,accuracy(pred_valid2, valid_label2[:batch_size]), accuracy(pred_valid3, valid_label3[:batch_size])  \\\n",
    "        ,accuracy(pred_valid4, valid_label4[:batch_size]), accuracy(pred_valid5, valid_label5[:batch_size])))\n",
    "    \n",
    "      avg_acc_valid = (accuracy(pred_valid0, valid_label0[:batch_size]) + accuracy(pred_valid1, valid_label1[:batch_size])\n",
    "        + accuracy(pred_valid2, valid_label2[:batch_size]) + accuracy(pred_valid3, valid_label3[:batch_size])\n",
    "        + accuracy(pred_valid4, valid_label4[:batch_size]) + accuracy(pred_valid5, valid_label5[:batch_size]))/6\n",
    "      print('Validation avg accuracy: %.1f%%' % avg_acc_valid)\n",
    "    \n",
    "     # print(\"w1 mean: {} std: {}\".format(np.mean(w), np.std(w)))\n",
    "     # print(\"wy1 mean: {} std: {}\".format(np.mean(w1), np.std(w1)))\n",
    "      #print(\"label: \", batch_labels1)\n",
    "    #  print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), L_valid))\n",
    "  #print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
